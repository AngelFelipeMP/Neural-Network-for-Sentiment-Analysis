{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KWuNFSk8bPHA"
   },
   "source": [
    "# Imports and Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1238,
     "status": "ok",
     "timestamp": 1557873440283,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "qY6m8_IMNfAU",
    "outputId": "f767a5d7-05cf-4259-f709-bd24114e27d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/xicocaio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/xicocaio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/xicocaio/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "\n",
    "# scikit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras import layers, regularizers, callbacks, utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk import word_tokenize, tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1459,
     "status": "ok",
     "timestamp": 1557873440516,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "l47G7mqPHlBA",
    "outputId": "68af194c-1aa5-4e31-c924-4f1dfa9271e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing if GPU available and if using CUDA\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=True,\n",
    "    min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1450,
     "status": "ok",
     "timestamp": 1557873440520,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "OQbtHrHUbgWQ",
    "outputId": "08bcd2d8-0b71-4bce-c3d6-20174bd6e74e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_available_gpus():\n",
    "   local_device_protos = device_lib.list_local_devices()\n",
    "   return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "num_gpu = len(get_available_gpus())\n",
    "num_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lZweddAbcgq"
   },
   "outputs": [],
   "source": [
    "#folder setup\n",
    "\n",
    "results_cnn = 'results/cnn/raw/emb/'\n",
    "results_svr = 'results/svr/raw/'\n",
    "results_lstm = 'results/lstm/raw/emb/'\n",
    "\n",
    "resources = 'resources'\n",
    "\n",
    "if not os.path.isdir(results_lstm):\n",
    "    ! mkdir -p $results_cnn\n",
    "    ! mkdir -p $results_svr\n",
    "    ! mkdir -p $results_lstm\n",
    "    \n",
    "if not os.path.isdir(resources):\n",
    "    ! mkdir -p $resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OdHkxTFawp7b"
   },
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1880,
     "status": "ok",
     "timestamp": 1557873440965,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "c8ZQ9Xj0wp7c",
    "outputId": "8f35ba61-eed7-47f4-b7cf-6e01360c9cc6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment                                              title\n",
       "0  Morrisons   2      0.430  Morrisons book second consecutive quarter of s...\n",
       "1        IMI   3     -0.344  IMI posts drop in first-quarter organic revenu...\n",
       "2   Glencore   4      0.340  Glencore to refinance its short-term debt earl...\n",
       "3    Ryanair   5      0.259  EasyJet attracts more passengers in June but s...\n",
       "4   Barclays   6     -0.231             Barclays 'bad bank' chief to step down"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading training data\n",
    "df_train = pd.read_json('Headline_Trainingdata.json')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1871,
     "status": "ok",
     "timestamp": 1557873440967,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "vb5O2ouj-BlX",
    "outputId": "9cf98a15-1b0c-4086-f03f-18737ea360f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    131\n",
       "3    129\n",
       "8    128\n",
       "2    127\n",
       "1    127\n",
       "9    126\n",
       "5    126\n",
       "4    125\n",
       "7    123\n",
       "Name: quantile, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bins = 9\n",
    "# bins = df_train['sentiment'].quantile([0.1*q for q in range(0,n_bins)])\n",
    "# df_train['quantile'] = pd.cut(df_train['sentiment'], bins=bins, labels=range(1,n_bins+1))\n",
    "# df_train['quantile'] = pd.cut(df_train['sentiment'], bins=bins, include_lowest=True)\n",
    "\n",
    "df_train['quantile'] = pd.qcut(df_train['sentiment'], q=n_bins, labels=range(1,n_bins+1))\n",
    "df_train['quantile'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1860,
     "status": "ok",
     "timestamp": 1557873440969,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "XKTCXsWaD9RW",
    "outputId": "ad06da7e-62d8-4985-c3a5-eeed21467436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.03104903677758319; std: 0.39360209451145045\n"
     ]
    }
   ],
   "source": [
    "print('mean: {}; std: {}'.format(np.mean(df_train['sentiment']), np.std(df_train['sentiment'])))\n",
    "# df_train['sentiment'].min()\n",
    "# df_train['sentiment'].idxmin()\n",
    "# df_train.iloc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1879,
     "status": "ok",
     "timestamp": 1557873441006,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "w619GiP9clF9",
    "outputId": "5314cfc7-c0d6-4e9b-8b93-c080833e07c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train CV: mean: 0.03412017167381975; std: 0.38683983574619385\n",
      "df_train CV: mean: 0.028765217391304363; std: 0.4037852384500579\n",
      "df_train CV: mean: 0.029614035087719294; std: 0.3849741278336272\n",
      "df_train CV: mean: 0.02813274336283186; std: 0.4028562295301328\n",
      "df_train CV: mean: 0.03458666666666667; std: 0.3891696491534537\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "for fit_index, cv_index in skf.split(df_train, df_train['quantile']):\n",
    "#   print(\"TRAIN:\", train_index.size, \"TEST:\", test_index.size)\n",
    "#   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#   print(\"TRAIN:\", df_train.iloc[train_index], \"TEST:\", df_train.iloc[test_index])\n",
    "#   print('TRAIN: mean: {}; std: {}'.format(np.mean(df_train['sentiment'].iloc[train_index]), np.std(df_train['sentiment'].iloc[train_index])))\n",
    "  print('df_train CV: mean: {}; std: {}'.format(np.mean(df_train['sentiment'].iloc[cv_index]), np.std(df_train['sentiment'].iloc[cv_index])))\n",
    "#   df_train['sentiment'].iloc[test_index]\n",
    "#   df_train.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4413,
     "status": "ok",
     "timestamp": 1557873443548,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "sq_o9rsM08Mg",
    "outputId": "0496ab94-6936-40d5-b8bd-9fb8325512ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashtead</td>\n",
       "      <td>1144</td>\n",
       "      <td>0.588</td>\n",
       "      <td>Ashtead to buy back shares, full-year profit b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shell</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.276</td>\n",
       "      <td>EU regulators clear Shell's takeover of BG Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prudential</td>\n",
       "      <td>1146</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>UK's FTSE has worst day so far in 2015 as BG a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GlaxoSmithKline</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.390</td>\n",
       "      <td>GlaxoSmithKline acquires HIV assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>1148</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>Barclays faces another heavy forex fine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company    id  sentiment  \\\n",
       "0          Ashtead  1144      0.588   \n",
       "1            Shell  1145      0.276   \n",
       "2       Prudential  1146     -0.651   \n",
       "3  GlaxoSmithKline  1147      0.390   \n",
       "4         Barclays  1148     -0.834   \n",
       "\n",
       "                                               title  \n",
       "0  Ashtead to buy back shares, full-year profit b...  \n",
       "1   EU regulators clear Shell's takeover of BG Group  \n",
       "2  UK's FTSE has worst day so far in 2015 as BG a...  \n",
       "3                GlaxoSmithKline acquires HIV assets  \n",
       "4            Barclays faces another heavy forex fine  "
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading testing data, and removing normalizing collumns\n",
    "df_test = pd.read_json(\"Headlines_Testdata_withscores.json\")\n",
    "\n",
    "df_test.drop('UniqueID', axis=1, inplace=True)\n",
    "df_test.rename(columns={'sentiment score': 'sentiment'}, inplace=True)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4403,
     "status": "ok",
     "timestamp": 1557873443550,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "K9ufADTxblRd",
    "outputId": "0fe9c4fa-919b-44e1-e396-ce0076292d32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test: mean: 0.014820773930753563; std: 0.4137897136769093\n"
     ]
    }
   ],
   "source": [
    "print('df_test: mean: {}; std: {}'.format(np.mean(df_test['sentiment']), np.std(df_test['sentiment'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-_1M_B-wp7k"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4396,
     "status": "ok",
     "timestamp": 1557873443551,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "2dpikgLywp7k",
    "outputId": "6f18e179-6e15-434e-8d58-2d3f8b61c6ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashtead</td>\n",
       "      <td>1144</td>\n",
       "      <td>0.588</td>\n",
       "      <td>Ashtead to buy back shares, full-year profit b...</td>\n",
       "      <td>[company, buy, back, shares, ,, full-year, pro...</td>\n",
       "      <td>company buy back shares , full-year profit bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shell</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.276</td>\n",
       "      <td>EU regulators clear Shell's takeover of BG Group</td>\n",
       "      <td>[eu, regulators, clear, company, s, takeover, ...</td>\n",
       "      <td>eu regulators clear company s takeover bg group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prudential</td>\n",
       "      <td>1146</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>UK's FTSE has worst day so far in 2015 as BG a...</td>\n",
       "      <td>[uk, s, ftse, worst, day, far, 2015, bg, compa...</td>\n",
       "      <td>uk s ftse worst day far 2015 bg company fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GlaxoSmithKline</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.390</td>\n",
       "      <td>GlaxoSmithKline acquires HIV assets</td>\n",
       "      <td>[company, acquires, hiv, assets]</td>\n",
       "      <td>company acquires hiv assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>1148</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>Barclays faces another heavy forex fine</td>\n",
       "      <td>[company, faces, another, heavy, forex, fine]</td>\n",
       "      <td>company faces another heavy forex fine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company    id  sentiment  \\\n",
       "0          Ashtead  1144      0.588   \n",
       "1            Shell  1145      0.276   \n",
       "2       Prudential  1146     -0.651   \n",
       "3  GlaxoSmithKline  1147      0.390   \n",
       "4         Barclays  1148     -0.834   \n",
       "\n",
       "                                               title  \\\n",
       "0  Ashtead to buy back shares, full-year profit b...   \n",
       "1   EU regulators clear Shell's takeover of BG Group   \n",
       "2  UK's FTSE has worst day so far in 2015 as BG a...   \n",
       "3                GlaxoSmithKline acquires HIV assets   \n",
       "4            Barclays faces another heavy forex fine   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, buy, back, shares, ,, full-year, pro...   \n",
       "1  [eu, regulators, clear, company, s, takeover, ...   \n",
       "2  [uk, s, ftse, worst, day, far, 2015, bg, compa...   \n",
       "3                   [company, acquires, hiv, assets]   \n",
       "4      [company, faces, another, heavy, forex, fine]   \n",
       "\n",
       "                                           new_title  \n",
       "0  company buy back shares , full-year profit bea...  \n",
       "1    eu regulators clear company s takeover bg group  \n",
       "2       uk s ftse worst day far 2015 bg company fall  \n",
       "3                        company acquires hiv assets  \n",
       "4             company faces another heavy forex fine  "
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop words removal\n",
    "def run_preprocessing(df):\n",
    "  # replace company name by placeholder and remove double quotes that is not preprocessed well by word_tokenize\n",
    "  # also lower casing words for compatilbility with glove, which only has lower casing words\n",
    "  # be aware that some companies namies are not identical\n",
    "  # example: id = 10 Centrica PLC appears as just Centrica on title\n",
    "  title_company_replaced = df['title'].replace(df['company'], 'company', regex = True).replace('\"', '', regex = True).str.lower()\n",
    "#   title_company_replaced = df['title'].replace(df['company'], 'company', regex = True)\n",
    "\n",
    "  # tokenize headlines\n",
    "  tokenized_title = title_company_replaced.apply(word_tokenize)\n",
    "  \n",
    "  # removing stopwords and single quotes\n",
    "  # stop_words: {'does', 'under', 'own', 'at', 'of', 'don', 'hers', 'further', 're', \"you'll\", 'into', 'she', 'such', 'shan', 'you', \"haven't\", 'when', 'me', 'a', 'all', \"shan't\", 'mustn', \"should've\", \"didn't\", \"aren't\", \"weren't\", 'after', 'ain', 's', \"that'll\", 'just', 'am', 'the', 'too', 'before', \"wasn't\", 'what', 'haven', 'm', 'up', 'against', 'how', 'who', 'yourselves', 'nor', 'than', 've', 'between', 'being', 'are', 'and', \"don't\", 'themselves', 'were', 'itself', 'd', 'doesn', 'there', \"wouldn't\", 'both', 'we', 'why', 'needn', 'those', 'out', 'mightn', 'which', 'it', 'here', 'theirs', 'any', 'my', 'that', \"doesn't\", 'should', 'him', 'weren', 'from', 'no', 'wouldn', 'once', 'with', 'will', 'have', 'is', 'most', 'hasn', 'll', 'yours', 'himself', 'was', 'this', 'or', 'over', 'again', 'y', 'do', 'through', \"hasn't\", \"she's\", 'same', 'down', 'has', 'so', 'can', 'shouldn', \"hadn't\", 'while', 'for', 'but', 'whom', \"mustn't\", 'our', 'if', \"couldn't\", \"you've\", 'be', 'been', 'myself', 'did', 'few', 'hadn', 'other', \"you'd\", 'not', 'ma', 'their', 'off', \"shouldn't\", 'had', 'these', 'his', 'yourself', 'very', \"isn't\", 'aren', 'o', 'won', 'because', 'isn', 'wasn', 'herself', 'by', 'where', 'your', 'i', \"it's\", 'above', 'until', \"you're\", 'they', 'only', 'ours', 'below', \"mightn't\", 'some', \"won't\", 'about', 'couldn', 'ourselves', 'them', 'he', 'during', 'more', 't', 'as', 'now', 'didn', \"needn't\", 'an', 'to', 'each', 'its', 'her', 'doing', 'then', 'on', 'in', 'having'}  \n",
    "  # some of these word should probably not be removed like the word: won't\n",
    "  # also maybe consider using TweetTokenizer, that mayy deal better with contactions like: Glencore's \n",
    "  stopwords_english = stopwords.words('english')\n",
    "  stopwords_english.append('\\'')\n",
    "\n",
    "  df['clean_tokens'] = tokenized_title.apply(lambda x: [item.strip('\\'') for item in x if item not in stopwords_english])\n",
    "#   df['clean_tokens'] = tokenized_title.apply(lambda x: [item for item in x if item not in stopwords_english])\n",
    "  df['new_title'] =  df['clean_tokens'].apply(lambda x: ' '.join(x))\n",
    "  \n",
    "run_preprocessing(df_train)\n",
    "run_preprocessing(df_test)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NmyHJxUwp7x"
   },
   "source": [
    "## Tokenizing and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4390,
     "status": "ok",
     "timestamp": 1557873443552,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "iVc6F4_vj7Gx",
    "outputId": "813c6825-0820-42df-ee92-7b5655dd8f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 16 | min: 3 | mean: 8.249562171628721 | std: 2.0743354560287957\n"
     ]
    }
   ],
   "source": [
    "clean_tokens_length = df_train[\"clean_tokens\"].apply(lambda x: len(x))\n",
    "\n",
    "max_sentence_length_train = np.max(clean_tokens_length)\n",
    "min_sentence_length_train = np.min(clean_tokens_length)\n",
    "mean_sentence_length_train = np.mean(clean_tokens_length)\n",
    "std_sentence_length_train = np.std(clean_tokens_length)\n",
    "\n",
    "\n",
    "print(\"max: {} | min: {} | mean: {} | std: {}\".format(max_sentence_length_train, min_sentence_length_train, mean_sentence_length_train, std_sentence_length_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9gLNeUqVnkmc"
   },
   "outputs": [],
   "source": [
    "# giving the max_sentence_length_train, we will use a number a little above\n",
    "# TODO: evaluate if this is too much of a leakage, because each fold may yield different sequence MAX\n",
    "MAX_SEQUENCE_LENGTH = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJXCYNGwowZS"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 10000\n",
    "\n",
    "# receives healines and returns tokenizer with vocab mappings and padded sentences read to use\n",
    "def get_tok_sentences(doc_fit, doc_cv):\n",
    "  tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='', lower=False)\n",
    "  tokenizer.fit_on_texts(doc_fit)\n",
    "\n",
    "  fit_sentences = tokenizer.texts_to_sequences(doc_fit)\n",
    "  cv_sentences = tokenizer.texts_to_sequences(doc_cv)\n",
    "  \n",
    "  fit_sentences_pad = pad_sequences(fit_sentences, padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "  cv_sentences_pad = pad_sequences(cv_sentences, padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "  return fit_sentences_pad, cv_sentences_pad, tokenizer\n",
    "\n",
    "# sentences_seq_train, vocab_size, tokenizer = prepare_tokenizer(df_train)\n",
    "# tokenizer.word_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QS3NZC6Zs0im"
   },
   "outputs": [],
   "source": [
    "# sentences_seq_train = pad_sequences(sentences_seq_train, padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "# print(sentences_seq_train[1134, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N54Xko65BOiq"
   },
   "outputs": [],
   "source": [
    "#TODO: may be a good idea: FROM: https://www.tensorflow.org/tutorials/keras/basic_text_classification\n",
    "\n",
    "# # A dictionary mapping words to an integer index\n",
    "# word_index = imdb.get_word_index()\n",
    "\n",
    "# # The first indices are reserved\n",
    "# word_index = {k:(v+3) for k,v in word_index.items()} \n",
    "# word_index[\"<PAD>\"] = 0\n",
    "# word_index[\"<START>\"] = 1\n",
    "# word_index[\"<UNK>\"] = 2  # unknown\n",
    "# word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "# reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# def decode_review(text):\n",
    "#     return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "# decode_review(train_data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83-K4yu5r9Gv"
   },
   "source": [
    "## Sentiment Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jocsyJfGwp7n"
   },
   "source": [
    "### Loughran McDonald Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXsRVyu6XLy_"
   },
   "outputs": [],
   "source": [
    "LMDDictionary = {}\n",
    "vetor = []\n",
    "\n",
    "# TODO: this can be done directly by converting to pandas and than calling the to_dict function\n",
    "with open('LoughranMcDonald_MasterDictionary_2016.csv', 'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        palavra = line.split(',')[0].lower()\n",
    "        vetor_char = line.split(',')[7:14]\n",
    "        vetor = [1 if x!='0' else 0 for x in vetor_char]\n",
    "\n",
    "        LMDDictionary[palavra] = np.asarray(vetor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4438,
     "status": "ok",
     "timestamp": 1557873443612,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "Ju9zpKQAwp7o",
    "outputId": "44a2a248-c17e-46f1-e89b-1fde8d31052d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>quantile</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "      <th>LMDVector</th>\n",
       "      <th>mean_LMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "      <td>8</td>\n",
       "      <td>[company, book, second, consecutive, quarter, ...</td>\n",
       "      <td>company book second consecutive quarter sales ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[company, posts, drop, first-quarter, organic,...</td>\n",
       "      <td>company posts drop first-quarter organic reven...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[company, refinance, short-term, debt, early, ...</td>\n",
       "      <td>company refinance short-term debt early , shar...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "      <td>6</td>\n",
       "      <td>[easyjet, attracts, passengers, june, still, l...</td>\n",
       "      <td>easyjet attracts passengers june still lags co...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "      <td>3</td>\n",
       "      <td>[company, bad, bank, chief, step]</td>\n",
       "      <td>company bad bank chief step</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment  \\\n",
       "0  Morrisons   2      0.430   \n",
       "1        IMI   3     -0.344   \n",
       "2   Glencore   4      0.340   \n",
       "3    Ryanair   5      0.259   \n",
       "4   Barclays   6     -0.231   \n",
       "\n",
       "                                               title quantile  \\\n",
       "0  Morrisons book second consecutive quarter of s...        8   \n",
       "1  IMI posts drop in first-quarter organic revenu...        2   \n",
       "2  Glencore to refinance its short-term debt earl...        7   \n",
       "3  EasyJet attracts more passengers in June but s...        6   \n",
       "4             Barclays 'bad bank' chief to step down        3   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, book, second, consecutive, quarter, ...   \n",
       "1  [company, posts, drop, first-quarter, organic,...   \n",
       "2  [company, refinance, short-term, debt, early, ...   \n",
       "3  [easyjet, attracts, passengers, june, still, l...   \n",
       "4                  [company, bad, bank, chief, step]   \n",
       "\n",
       "                                           new_title  \\\n",
       "0  company book second consecutive quarter sales ...   \n",
       "1  company posts drop first-quarter organic reven...   \n",
       "2  company refinance short-term debt early , shar...   \n",
       "3  easyjet attracts passengers june still lags co...   \n",
       "4                        company bad bank chief step   \n",
       "\n",
       "                                           LMDVector  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...   \n",
       "\n",
       "                                            mean_LMD  \n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1                [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]  \n",
       "2                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4                [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = [0, 0, 0, 0, 0, 0, 0]\n",
    "nan_list = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "def run_LMD(df):\n",
    "  df['LMDVector'] = df['clean_tokens'].apply(lambda x: [LMDDictionary.get(item, zeros) for item in x])\n",
    "  df['mean_LMD'] = df['LMDVector'].apply(lambda x: np.mean(x, axis=0, dtype=np.float64))\n",
    "  \n",
    "#   df['LMDVector'] = df['new_title'].apply(lambda x: [LMDDictionary.get(item, nan_list) for item in x]) #Taynan\n",
    "#   df['mean_LMD'] = df['LMDVector'].apply(lambda x: np.nanmean(x, axis=0, dtype=np.float64)) #Taynan\n",
    "  \n",
    "run_LMD(df_train)\n",
    "run_LMD(df_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbzybLUewp70"
   },
   "source": [
    "### VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4433,
     "status": "ok",
     "timestamp": 1557873443614,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "Rtd3NaKuznfJ",
    "outputId": "3d1975cb-d656-4e3f-f7d1-f7ab5022bbe3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>quantile</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "      <th>LMDVector</th>\n",
       "      <th>mean_LMD</th>\n",
       "      <th>neu_VADER</th>\n",
       "      <th>pos_VADER</th>\n",
       "      <th>neg_VADER</th>\n",
       "      <th>compound_VADER</th>\n",
       "      <th>mean_VADER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "      <td>8</td>\n",
       "      <td>[company, book, second, consecutive, quarter, ...</td>\n",
       "      <td>company book second consecutive quarter sales ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]</td>\n",
       "      <td>[0.0, 0.698, 0.302, 0.3818]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[company, posts, drop, first-quarter, organic,...</td>\n",
       "      <td>company posts drop first-quarter organic reven...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...</td>\n",
       "      <td>[0.333, 0.667, 0.0, -0.3612]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[company, refinance, short-term, debt, early, ...</td>\n",
       "      <td>company refinance short-term debt early , shar...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]</td>\n",
       "      <td>[0.258, 0.515, 0.227, -0.0772]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "      <td>6</td>\n",
       "      <td>[easyjet, attracts, passengers, june, still, l...</td>\n",
       "      <td>easyjet attracts passengers june still lags co...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]</td>\n",
       "      <td>[0.245, 0.49, 0.265, 0.0516]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "      <td>3</td>\n",
       "      <td>[company, bad, bank, chief, step]</td>\n",
       "      <td>company bad bank chief step</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, -0.5423, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.467, 0.533, 0.0, -0.5423]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment  \\\n",
       "0  Morrisons   2      0.430   \n",
       "1        IMI   3     -0.344   \n",
       "2   Glencore   4      0.340   \n",
       "3    Ryanair   5      0.259   \n",
       "4   Barclays   6     -0.231   \n",
       "\n",
       "                                               title quantile  \\\n",
       "0  Morrisons book second consecutive quarter of s...        8   \n",
       "1  IMI posts drop in first-quarter organic revenu...        2   \n",
       "2  Glencore to refinance its short-term debt earl...        7   \n",
       "3  EasyJet attracts more passengers in June but s...        6   \n",
       "4             Barclays 'bad bank' chief to step down        3   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, book, second, consecutive, quarter, ...   \n",
       "1  [company, posts, drop, first-quarter, organic,...   \n",
       "2  [company, refinance, short-term, debt, early, ...   \n",
       "3  [easyjet, attracts, passengers, june, still, l...   \n",
       "4                  [company, bad, bank, chief, step]   \n",
       "\n",
       "                                           new_title  \\\n",
       "0  company book second consecutive quarter sales ...   \n",
       "1  company posts drop first-quarter organic reven...   \n",
       "2  company refinance short-term debt early , shar...   \n",
       "3  easyjet attracts passengers june still lags co...   \n",
       "4                        company bad bank chief step   \n",
       "\n",
       "                                           LMDVector  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...   \n",
       "\n",
       "                                            mean_LMD  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1                [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]   \n",
       "2                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4                [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neu_VADER  \\\n",
       "0                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]   \n",
       "1  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...   \n",
       "2           [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]   \n",
       "3                [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]   \n",
       "4                          [1.0, 0.0, 1.0, 1.0, 1.0]   \n",
       "\n",
       "                                           pos_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "3                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "4                          [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neg_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "4                          [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                      compound_VADER  \\\n",
       "0             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]   \n",
       "1  [0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...   \n",
       "2     [0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]   \n",
       "3         [0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]   \n",
       "4                      [0.0, -0.5423, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                       mean_VADER  \n",
       "0     [0.0, 0.698, 0.302, 0.3818]  \n",
       "1    [0.333, 0.667, 0.0, -0.3612]  \n",
       "2  [0.258, 0.515, 0.227, -0.0772]  \n",
       "3    [0.245, 0.49, 0.265, 0.0516]  \n",
       "4    [0.467, 0.533, 0.0, -0.5423]  "
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_sid(df):\n",
    "  sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "  df['neu_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['neu'] for item in x])\n",
    "  df['pos_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['pos'] for item in x])\n",
    "  df['neg_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['neg'] for item in x])\n",
    "  df['compound_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['compound'] for item in x])\n",
    "  df['mean_VADER'] = df['new_title'].apply(lambda x: [v for k,v in sid.polarity_scores(x).items()])\n",
    "  \n",
    "#   df['neu_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['neu'] for item in x]))\n",
    "#   df['pos_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['pos'] for item in x]))\n",
    "#   df['neg_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['neg'] for item in x]))\n",
    "#   df['compound_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['compound'] for item in x]))\n",
    "#   df['mean_VADER'] = df[['neu_VADER', 'pos_VADER', 'neg_VADER', 'compound_VADER']].values.tolist()\n",
    "  \n",
    "                                 \n",
    "run_sid(df_train)\n",
    "run_sid(df_test)\n",
    "\n",
    "df_train.head()\n",
    "# np.mean(df_train['neu_VADER'])\n",
    "# [np.mean(item) for item in df_train['neu_VADER']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KwglgETsGV3"
   },
   "source": [
    "### Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4430,
     "status": "ok",
     "timestamp": 1557873443617,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "Cd30mr4hsLGe",
    "outputId": "8d975c06-c0ae-4722-b8af-35e48ce35e79"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>quantile</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "      <th>LMDVector</th>\n",
       "      <th>mean_LMD</th>\n",
       "      <th>neu_VADER</th>\n",
       "      <th>pos_VADER</th>\n",
       "      <th>neg_VADER</th>\n",
       "      <th>compound_VADER</th>\n",
       "      <th>mean_VADER</th>\n",
       "      <th>mean_VADER_LMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "      <td>8</td>\n",
       "      <td>[company, book, second, consecutive, quarter, ...</td>\n",
       "      <td>company book second consecutive quarter sales ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]</td>\n",
       "      <td>[0.0, 0.698, 0.302, 0.3818]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[company, posts, drop, first-quarter, organic,...</td>\n",
       "      <td>company posts drop first-quarter organic reven...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...</td>\n",
       "      <td>[0.333, 0.667, 0.0, -0.3612]</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.333, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[company, refinance, short-term, debt, early, ...</td>\n",
       "      <td>company refinance short-term debt early , shar...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]</td>\n",
       "      <td>[0.258, 0.515, 0.227, -0.0772]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.258, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "      <td>6</td>\n",
       "      <td>[easyjet, attracts, passengers, june, still, l...</td>\n",
       "      <td>easyjet attracts passengers june still lags co...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]</td>\n",
       "      <td>[0.245, 0.49, 0.265, 0.0516]</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "      <td>3</td>\n",
       "      <td>[company, bad, bank, chief, step]</td>\n",
       "      <td>company bad bank chief step</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, -0.5423, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.467, 0.533, 0.0, -0.5423]</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.467, 0.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment  \\\n",
       "0  Morrisons   2      0.430   \n",
       "1        IMI   3     -0.344   \n",
       "2   Glencore   4      0.340   \n",
       "3    Ryanair   5      0.259   \n",
       "4   Barclays   6     -0.231   \n",
       "\n",
       "                                               title quantile  \\\n",
       "0  Morrisons book second consecutive quarter of s...        8   \n",
       "1  IMI posts drop in first-quarter organic revenu...        2   \n",
       "2  Glencore to refinance its short-term debt earl...        7   \n",
       "3  EasyJet attracts more passengers in June but s...        6   \n",
       "4             Barclays 'bad bank' chief to step down        3   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, book, second, consecutive, quarter, ...   \n",
       "1  [company, posts, drop, first-quarter, organic,...   \n",
       "2  [company, refinance, short-term, debt, early, ...   \n",
       "3  [easyjet, attracts, passengers, june, still, l...   \n",
       "4                  [company, bad, bank, chief, step]   \n",
       "\n",
       "                                           new_title  \\\n",
       "0  company book second consecutive quarter sales ...   \n",
       "1  company posts drop first-quarter organic reven...   \n",
       "2  company refinance short-term debt early , shar...   \n",
       "3  easyjet attracts passengers june still lags co...   \n",
       "4                        company bad bank chief step   \n",
       "\n",
       "                                           LMDVector  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...   \n",
       "\n",
       "                                            mean_LMD  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1                [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]   \n",
       "2                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4                [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neu_VADER  \\\n",
       "0                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]   \n",
       "1  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...   \n",
       "2           [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]   \n",
       "3                [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]   \n",
       "4                          [1.0, 0.0, 1.0, 1.0, 1.0]   \n",
       "\n",
       "                                           pos_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "3                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "4                          [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neg_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "4                          [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                      compound_VADER  \\\n",
       "0             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]   \n",
       "1  [0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...   \n",
       "2     [0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]   \n",
       "3         [0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]   \n",
       "4                      [0.0, -0.5423, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                       mean_VADER  \\\n",
       "0     [0.0, 0.698, 0.302, 0.3818]   \n",
       "1    [0.333, 0.667, 0.0, -0.3612]   \n",
       "2  [0.258, 0.515, 0.227, -0.0772]   \n",
       "3    [0.245, 0.49, 0.265, 0.0516]   \n",
       "4    [0.467, 0.533, 0.0, -0.5423]   \n",
       "\n",
       "                                      mean_VADER_LMD  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.698...  \n",
       "1  [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.333, 0.6...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.258, 0.5...  \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4  [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.467, 0.5...  "
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_vader_LMD(df):\n",
    "  df['mean_VADER_LMD'] = [np.hstack([x,y]) for x, y in zip(df['mean_LMD'], df['mean_VADER'])]\n",
    "\n",
    "join_vader_LMD(df_train)\n",
    "join_vader_LMD(df_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKNfykDiwp76"
   },
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsTrK_2z9b-i"
   },
   "outputs": [],
   "source": [
    "# EMBEDDING_DIM = 300\n",
    "\n",
    "# TODO: use: vocab_size = max(MAX_VOCAB_SIZE, len(word_index)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCkEUlw1DL2v"
   },
   "outputs": [],
   "source": [
    "def load_embedding(emb_dim):\n",
    "  \n",
    "  # load the whole embedding into memory\n",
    "  embeddings_index = dict()\n",
    "  \n",
    "  if not os.path.exists('resources/glove.6B.zip'):\n",
    "    ! wget http://nlp.stanford.edu/data/glove.6B.zip -P /resources/\n",
    "  if not os.path.exists('resources/glove.6B.' + str(emb_dim) + 'd.txt'):\n",
    "    ! unzip resources/glove.6B.zip -d resources\n",
    "  \n",
    "  f = open('resources/glove.6B.' + str(emb_dim) + 'd.txt', 'r', encoding=\"utf8\")\n",
    "  for line in f:\n",
    "      values = line.split()\n",
    "      word = values[0]\n",
    "      coefs = np.asarray(values[1:], dtype='float32')\n",
    "      embeddings_index[word] = coefs\n",
    "  f.close()\n",
    "  \n",
    "  return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tcmZ6KVgwp78"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "def get_embedding_matrix(emb_dim, vocab_size, input_length, tokenizer, embeddings_index):\n",
    "  vocab_size = min(MAX_VOCAB_SIZE, len(tokenizer.word_index)) + 1 # Adding 1 because of reserved 0 index\n",
    "  embedding_matrix = np.zeros((vocab_size, emb_dim))\n",
    "  for word, i in tokenizer.word_index.items():\n",
    "      embedding_vector = embeddings_index.get(word)\n",
    "      if (embedding_vector is not None):\n",
    "          embedding_matrix[i] = embedding_vector\n",
    "\n",
    "  return embedding_matrix\n",
    "\n",
    "\n",
    "# banna, maca, tokenizer = get_tok_sentences(df_train['new_title'], df_test['new_title'])\n",
    "# get_embedding_matrix(300, MAX_VOCAB_SIZE, True, MAX_SEQUENCE_LENGTH, tokenizer).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buH-SkpPpdPm"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DAqcBAvnwp8A"
   },
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRqZgB3-hY7t"
   },
   "outputs": [],
   "source": [
    "def cos_sim(y_true, y_pred):\n",
    "#   x = K.l2_normalize(y_true, axis=-1)\n",
    "#   y = K.l2_normalize(y_pred, axis=-1)\n",
    "#   return K.mean(x * y, axis=-1, keepdims=True)\n",
    "  return cosine_similarity(y_true, y_pred)\n",
    "\n",
    "metrics = ['cosine_proximity']\n",
    "# dropout = 0.3\n",
    "# loss = 'mse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2B9necCNwp8D"
   },
   "outputs": [],
   "source": [
    "# callback for time: https://stackoverflow.com/questions/43178668/record-the-computation-time-for-each-epoch-in-keras-during-model-fit\n",
    "# or maybe just use keras LambdaCallback\n",
    "\n",
    "class TimeHistory(callbacks.Callback):  \n",
    "  def on_epoch_begin(self, epoch, logs={}):\n",
    "    self.epoch_time_start = time.time()\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    logs['time_passed'] = time.time() - self.epoch_time_start\n",
    "\n",
    "def callback_functions(nome_log):\n",
    "  time_callback = TimeHistory()\n",
    "  csv_logger = callbacks.CSVLogger(results_lstm + nome_log + '.csv', separator=';', append=True)\n",
    "#     tensorboard_callback = callbacks.TensorBoard(nome_log, histogram_freq=1)\n",
    "#     best_model = callbacks.ModelCheckpoint(results_lstm + nome_log + '.h5', monitor='val_loss', verbose=0, save_best_only=True, mode='auto')\n",
    "\n",
    "  return [time_callback, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeUV9qR9wp8H"
   },
   "outputs": [],
   "source": [
    "def create_model_lstm(lstm_out, num_dense, dropout_value, embedding_matrix, emb_layer_trainable):\n",
    "    \n",
    "    # first input model\n",
    "    visible1 = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), name='Word_Seq')\n",
    "    embedding = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable)(visible1)\n",
    "    lstm = layers.LSTM(lstm_out, activation='relu', dropout=dropout_value, recurrent_dropout=dropout_value)(embedding)\n",
    "    hidden1 = layers.Dense(num_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(lstm)\n",
    "    dropout1 = layers.Dropout(dropout_value)(hidden1)\n",
    "    output = layers.Dense(1, activation='tanh')(dropout1)\n",
    "    model = Model(inputs=[visible1], outputs=output)\n",
    "\n",
    "    return model\n",
    "    \n",
    "#     # interpretation model\n",
    "#     dropout1 = layers.Dropout(dropout_value)(pool1)\n",
    "#     hidden1 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n",
    "#     dropout2 = layers.Dropout(dropout_value)(hidden1)\n",
    "#     output = layers.Dense(1, activation='tanh')(dropout2)\n",
    "#     model = Model(inputs=[visible1], outputs=output)\n",
    "\n",
    "#     return model\n",
    "  \n",
    "# def create_model_lstm(lstm_out, num_dense, dropout, embedding_matrix, emb_layer_trainable):\n",
    "#     lstm = Sequential()\n",
    "#     lstm.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable))\n",
    "#     lstm.add(layers.LSTM(lstm_out, activation='relu', dropout=dropout, recurrent_dropout=dropout))\n",
    "#     lstm.add(layers.Dense(num_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "#     lstm.add(layers.Dropout(dropout))\n",
    "#     lstm.add(layers.Dense(1, activation='tanh'))\n",
    "#     return lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XMj2FWnlwp8K"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X, Y, batch_size, epochs_value, nome_log, X_cv, Y_cv):\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=metrics)\n",
    "    \n",
    "    return model.fit(X, Y, batch_size,\n",
    "                     validation_data=(X_cv, Y_cv),\n",
    "                     epochs=epochs_value,\n",
    "                     verbose=0,\n",
    "                     callbacks=callback_functions(nome_log)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPhI1NJswp8N"
   },
   "outputs": [],
   "source": [
    "def save_model(model, trained_model_history, model_name):\n",
    "    \n",
    "#     model.save(model_name + '.h5')\n",
    "    trained_model = trained_model_history\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.plot([abs(v) for v in trained_model.history['loss']])\n",
    "    plt.plot([abs(v) for v in trained_model.history['val_loss']])\n",
    "    plt.plot([abs(v) for v in trained_model.history['cosine_proximity']])\n",
    "    plt.plot([abs(v) for v in trained_model.history['val_cosine_proximity']])\n",
    "    plt.title('model mean squared error')\n",
    "    plt.ylabel('mean squared error')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['mse_train', 'mse_test', 'cos_sim_train', 'cos_sim_test'], loc='upper left')\n",
    "    plt.savefig(results_lstm + model_name + '_mse.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqcHcjJOwp8R"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, Y_expected):\n",
    "    input = X\n",
    "    output = np.array(model.predict(input))\n",
    "    expected = np.array(Y_expected)\n",
    "\n",
    "    dot = np.dot(expected, output)\n",
    "    output_mod = np.linalg.norm(output)\n",
    "    expected_mod = np.linalg.norm(expected)\n",
    "    cos = dot / output_mod / expected_mod\n",
    "\n",
    "    final_score = cos\n",
    "    \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tP6QpoR77w2y"
   },
   "source": [
    "## K-fold on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3862
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15245042,
     "status": "ok",
     "timestamp": 1557888684245,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "aMRsC6M3wp8T",
    "outputId": "6d26268f-ac8a-4ff8-9451-e76f2f158194"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "ID: 15000, Cos Sim Mean: 0.5183230393848076, Cos Sim Std: 0.030948992086784758, MSE Mean: 0.09085658431228247, MSE Std: 0.0071536680181314306, Training Time: 0:00:17.552069, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15001, Cos Sim Mean: 0.5146970554026986, Cos Sim Std: 0.04531991899619856, MSE Mean: 0.09416086741026826, MSE Std: 0.007330540816561089, Training Time: 0:00:17.680856, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15002, Cos Sim Mean: 0.50982203270203, Cos Sim Std: 0.04060155303401579, MSE Mean: 0.09501407217032182, MSE Std: 0.007941362438163822, Training Time: 0:00:17.764726, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15003, Cos Sim Mean: 0.5184301154094421, Cos Sim Std: 0.02375685930846796, MSE Mean: 0.09058959893013255, MSE Std: 0.008763777394936887, Training Time: 0:00:17.768395, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15004, Cos Sim Mean: 0.5131863330693988, Cos Sim Std: 0.032871388137456846, MSE Mean: 0.09166617783948287, MSE Std: 0.010527238160039636, Training Time: 0:00:17.775735, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15005, Cos Sim Mean: 0.5183749414410785, Cos Sim Std: 0.03173019032687456, MSE Mean: 0.09343112399654765, MSE Std: 0.0077800046182291025, Training Time: 0:00:17.767439, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15006, Cos Sim Mean: 0.5202593375608247, Cos Sim Std: 0.03936161670950978, MSE Mean: 0.09117506242067491, MSE Std: 0.008055777536415575, Training Time: 0:00:17.773576, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15007, Cos Sim Mean: 0.5236935434690521, Cos Sim Std: 0.025447155430653925, MSE Mean: 0.0929313946204382, MSE Std: 0.006450691381202705, Training Time: 0:00:17.807077, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15008, Cos Sim Mean: 0.5362359908175872, Cos Sim Std: 0.03467004004782922, MSE Mean: 0.09309197565421864, MSE Std: 0.007337887548246906, Training Time: 0:00:17.815306, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15009, Cos Sim Mean: 0.513255509398402, Cos Sim Std: 0.03507596202177757, MSE Mean: 0.09086334751069661, MSE Std: 0.008730309888111076, Training Time: 0:00:17.812131, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15010, Cos Sim Mean: 0.4975100556494648, Cos Sim Std: 0.03001444385555697, MSE Mean: 0.09112684397809803, MSE Std: 0.00870196038118204, Training Time: 0:00:17.908411, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15011, Cos Sim Mean: 0.5095269683468161, Cos Sim Std: 0.027796926062268062, MSE Mean: 0.09023804679934584, MSE Std: 0.008206459736187631, Training Time: 0:00:17.740079, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15012, Cos Sim Mean: 0.5080076062999813, Cos Sim Std: 0.03245780954216128, MSE Mean: 0.09001860532611275, MSE Std: 0.00852388235502425, Training Time: 0:00:17.782318, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15013, Cos Sim Mean: 0.5219388856257225, Cos Sim Std: 0.022006822224847386, MSE Mean: 0.09177362541173788, MSE Std: 0.00862726218999068, Training Time: 0:00:17.166252, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15014, Cos Sim Mean: 0.4991423800826878, Cos Sim Std: 0.04126644310300029, MSE Mean: 0.09309023442624556, MSE Std: 0.008565195212380609, Training Time: 0:00:17.656462, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15015, Cos Sim Mean: 0.5166589326416127, Cos Sim Std: 0.026447013463513788, MSE Mean: 0.0927396827864633, MSE Std: 0.011417512606205802, Training Time: 0:00:17.838012, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15016, Cos Sim Mean: 0.5271255436845499, Cos Sim Std: 0.026261301309616798, MSE Mean: 0.0897002785840236, MSE Std: 0.011519623689191575, Training Time: 0:00:17.844593, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15017, Cos Sim Mean: 0.5287957659559127, Cos Sim Std: 0.033333007501581656, MSE Mean: 0.08941346848385093, MSE Std: 0.009051383970430232, Training Time: 0:00:17.837852, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15018, Cos Sim Mean: 0.5411094741209569, Cos Sim Std: 0.024351798155255133, MSE Mean: 0.08847668718039227, MSE Std: 0.00888721051373636, Training Time: 0:00:17.837516, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15019, Cos Sim Mean: 0.5325201857906451, Cos Sim Std: 0.029784132132748074, MSE Mean: 0.09098108660582929, MSE Std: 0.00776401203479349, Training Time: 0:00:17.906552, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15020, Cos Sim Mean: 0.518383536376861, Cos Sim Std: 0.026544439717570263, MSE Mean: 0.09020888133424819, MSE Std: 0.005383567382508866, Training Time: 0:00:17.804757, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15021, Cos Sim Mean: 0.5376674018738383, Cos Sim Std: 0.03867908717417596, MSE Mean: 0.088955709288224, MSE Std: 0.008357661083909946, Training Time: 0:00:17.001580, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15022, Cos Sim Mean: 0.5168581010892803, Cos Sim Std: 0.02612993502764323, MSE Mean: 0.08972324729996113, MSE Std: 0.007222270706857932, Training Time: 0:00:16.991449, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15023, Cos Sim Mean: 0.5254865752114785, Cos Sim Std: 0.02194122051798421, MSE Mean: 0.09025017636173716, MSE Std: 0.008287966585524602, Training Time: 0:00:16.930483, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15024, Cos Sim Mean: 0.5237563117877133, Cos Sim Std: 0.019690874877020904, MSE Mean: 0.09219542984852332, MSE Std: 0.009972161211041174, Training Time: 0:00:16.963432, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15025, Cos Sim Mean: 0.5290032758938178, Cos Sim Std: 0.027270167722353276, MSE Mean: 0.0887364012442994, MSE Std: 0.007471024622676603, Training Time: 0:00:16.947035, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15026, Cos Sim Mean: 0.5430236498334768, Cos Sim Std: 0.03512688020462587, MSE Mean: 0.08984710865926639, MSE Std: 0.006463181166027282, Training Time: 0:00:16.946588, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15027, Cos Sim Mean: 0.513061657647238, Cos Sim Std: 0.02145720154146583, MSE Mean: 0.09225061633843475, MSE Std: 0.00665713383367575, Training Time: 0:00:09.650949, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15028, Cos Sim Mean: 0.5324308868834884, Cos Sim Std: 0.023402564174665463, MSE Mean: 0.09591588724982703, MSE Std: 0.004523661651924549, Training Time: 0:00:09.669262, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15029, Cos Sim Mean: 0.5116320685134024, Cos Sim Std: 0.03812324856580717, MSE Mean: 0.0957909158372333, MSE Std: 0.005624663366460329, Training Time: 0:00:09.601682, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15030, Cos Sim Mean: 0.5343292044421453, Cos Sim Std: 0.016922519202328644, MSE Mean: 0.09232998553930412, MSE Std: 0.005091699350082415, Training Time: 0:00:09.611837, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15031, Cos Sim Mean: 0.529170124042377, Cos Sim Std: 0.03132908261314977, MSE Mean: 0.09448128598830054, MSE Std: 0.00713671726137837, Training Time: 0:00:09.620590, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15032, Cos Sim Mean: 0.5148524380334816, Cos Sim Std: 0.026261883115921366, MSE Mean: 0.09579380457080612, MSE Std: 0.008200620770402425, Training Time: 0:00:09.622340, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15033, Cos Sim Mean: 0.5150623407527684, Cos Sim Std: 0.04702378157112869, MSE Mean: 0.09088163781438496, MSE Std: 0.007940366124310191, Training Time: 0:00:09.600720, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15034, Cos Sim Mean: 0.5237531068016952, Cos Sim Std: 0.03129955229784713, MSE Mean: 0.09477078491653565, MSE Std: 0.007152068256951027, Training Time: 0:00:09.617883, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15035, Cos Sim Mean: 0.5028891739580319, Cos Sim Std: 0.03468153827618732, MSE Mean: 0.09721060409615676, MSE Std: 0.00875926131469482, Training Time: 0:00:09.630109, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15036, Cos Sim Mean: 0.5150104354595012, Cos Sim Std: 0.04284394103944361, MSE Mean: 0.0924089631336964, MSE Std: 0.0073805547279831175, Training Time: 0:00:09.628359, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15037, Cos Sim Mean: 0.5359905816353228, Cos Sim Std: 0.03659903468668874, MSE Mean: 0.09227235353130966, MSE Std: 0.00821125993435264, Training Time: 0:00:09.606433, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15038, Cos Sim Mean: 0.5131738226903008, Cos Sim Std: 0.03200659884157395, MSE Mean: 0.0942828020898971, MSE Std: 0.00836478277872945, Training Time: 0:00:09.653163, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15039, Cos Sim Mean: 0.5255454116046596, Cos Sim Std: 0.037427342330943046, MSE Mean: 0.09166876211089804, MSE Std: 0.010429889228920306, Training Time: 0:00:09.616201, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15040, Cos Sim Mean: 0.5272712856282407, Cos Sim Std: 0.03346144937123411, MSE Mean: 0.09126029194480226, MSE Std: 0.008401986104617747, Training Time: 0:00:09.622833, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15041, Cos Sim Mean: 0.5077461953892748, Cos Sim Std: 0.04527594278677041, MSE Mean: 0.09455104178923826, MSE Std: 0.011389212625819526, Training Time: 0:00:09.594382, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15042, Cos Sim Mean: 0.527207975925828, Cos Sim Std: 0.03805056625049182, MSE Mean: 0.09063153282544723, MSE Std: 0.01033556476150043, Training Time: 0:00:09.627396, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15043, Cos Sim Mean: 0.5308240951252744, Cos Sim Std: 0.03921012597052899, MSE Mean: 0.09076920289236326, MSE Std: 0.008210852336500988, Training Time: 0:00:09.611554, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15044, Cos Sim Mean: 0.5215182708650563, Cos Sim Std: 0.042210188352983256, MSE Mean: 0.09325543485801235, MSE Std: 0.009904934286749658, Training Time: 0:00:09.620253, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15045, Cos Sim Mean: 0.5063376358291036, Cos Sim Std: 0.023950244855041096, MSE Mean: 0.08973395048526797, MSE Std: 0.008460413220902569, Training Time: 0:00:09.596128, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15046, Cos Sim Mean: 0.5151612967651603, Cos Sim Std: 0.05540466308118463, MSE Mean: 0.09123721450683706, MSE Std: 0.007491112884454447, Training Time: 0:00:09.653458, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15047, Cos Sim Mean: 0.5238013684132502, Cos Sim Std: 0.032897409493203765, MSE Mean: 0.09135839851752582, MSE Std: 0.005139624004771744, Training Time: 0:00:09.632098, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15048, Cos Sim Mean: 0.5148313919659004, Cos Sim Std: 0.06040181361057509, MSE Mean: 0.08854203856157554, MSE Std: 0.009569460665231072, Training Time: 0:00:09.635081, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15049, Cos Sim Mean: 0.5185123245647749, Cos Sim Std: 0.02666829770443048, MSE Mean: 0.09008515084290342, MSE Std: 0.007807453707111404, Training Time: 0:00:09.647228, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15050, Cos Sim Mean: 0.5237745010634539, Cos Sim Std: 0.042941031344117156, MSE Mean: 0.09269077437690945, MSE Std: 0.0059231456954717855, Training Time: 0:00:09.618504, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15051, Cos Sim Mean: 0.5062522225074076, Cos Sim Std: 0.03810787794172567, MSE Mean: 0.08960844292522745, MSE Std: 0.009261178452267363, Training Time: 0:00:09.661019, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15052, Cos Sim Mean: 0.5254484526401575, Cos Sim Std: 0.01802353142302582, MSE Mean: 0.08990274503826923, MSE Std: 0.007338799241308489, Training Time: 0:00:09.613615, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15053, Cos Sim Mean: 0.5342354042551374, Cos Sim Std: 0.039069303604499867, MSE Mean: 0.09184236267901613, MSE Std: 0.0062962542654107995, Training Time: 0:00:09.643644, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15054, Cos Sim Mean: 0.527223708218969, Cos Sim Std: 0.03570876189450045, MSE Mean: 0.09294146436692677, MSE Std: 0.00596090151293454, Training Time: 0:00:17.519878, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15055, Cos Sim Mean: 0.5131469565818431, Cos Sim Std: 0.04555475633149932, MSE Mean: 0.09517699060171855, MSE Std: 0.008818948930330093, Training Time: 0:00:17.583972, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15056, Cos Sim Mean: 0.4920250681130529, Cos Sim Std: 0.024707910033177613, MSE Mean: 0.09620078653252724, MSE Std: 0.006239267887920607, Training Time: 0:00:17.581907, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15057, Cos Sim Mean: 0.5201809627541636, Cos Sim Std: 0.041924202564012754, MSE Mean: 0.09147547541294153, MSE Std: 0.008023098362635983, Training Time: 0:00:17.616797, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15058, Cos Sim Mean: 0.5324420812540074, Cos Sim Std: 0.028705936307956547, MSE Mean: 0.09265853846505134, MSE Std: 0.007240920657325987, Training Time: 0:00:17.607467, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15059, Cos Sim Mean: 0.5082062339959805, Cos Sim Std: 0.033107007959415645, MSE Mean: 0.0963317082525269, MSE Std: 0.008353083481049735, Training Time: 0:00:17.659048, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15060, Cos Sim Mean: 0.5113726994016933, Cos Sim Std: 0.025577274099124293, MSE Mean: 0.09580012330388168, MSE Std: 0.008288577707552414, Training Time: 0:00:17.602965, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15061, Cos Sim Mean: 0.519831520374094, Cos Sim Std: 0.038042738263680854, MSE Mean: 0.09453059447211745, MSE Std: 0.009910647270640532, Training Time: 0:00:17.660257, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15062, Cos Sim Mean: 0.502607033297304, Cos Sim Std: 0.020293428375105626, MSE Mean: 0.09988570234138668, MSE Std: 0.009741462081093093, Training Time: 0:00:17.668793, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15063, Cos Sim Mean: 0.5446642368499648, Cos Sim Std: 0.03374109529311521, MSE Mean: 0.09039725361764298, MSE Std: 0.008206234796410982, Training Time: 0:00:17.641419, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15064, Cos Sim Mean: 0.5166126264735625, Cos Sim Std: 0.033608501607455876, MSE Mean: 0.08942366064922602, MSE Std: 0.006168446860301495, Training Time: 0:00:17.691405, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15065, Cos Sim Mean: 0.5166222855177803, Cos Sim Std: 0.020195428075382393, MSE Mean: 0.09358902413955032, MSE Std: 0.006362069356743134, Training Time: 0:00:17.640360, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15066, Cos Sim Mean: 0.5150187594619375, Cos Sim Std: 0.030127415653887435, MSE Mean: 0.09324643212151962, MSE Std: 0.009625327035639614, Training Time: 0:00:17.683408, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15067, Cos Sim Mean: 0.5221294127459563, Cos Sim Std: 0.04461847288548238, MSE Mean: 0.0932507414713296, MSE Std: 0.009013421380813883, Training Time: 0:00:17.633306, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15068, Cos Sim Mean: 0.5341978174222255, Cos Sim Std: 0.04884215726930846, MSE Mean: 0.09294440527152534, MSE Std: 0.008035100490676347, Training Time: 0:00:17.605071, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15069, Cos Sim Mean: 0.5096928344360994, Cos Sim Std: 0.04245509100129899, MSE Mean: 0.09133626866115488, MSE Std: 0.010883454833539143, Training Time: 0:00:17.662301, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15070, Cos Sim Mean: 0.5254629777586447, Cos Sim Std: 0.025400719687331055, MSE Mean: 0.09187797740242676, MSE Std: 0.008398036687522276, Training Time: 0:00:17.653102, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15071, Cos Sim Mean: 0.5062527431109902, Cos Sim Std: 0.0324710460373531, MSE Mean: 0.09115957358712297, MSE Std: 0.006207210355812029, Training Time: 0:00:17.628559, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15072, Cos Sim Mean: 0.5342727798419679, Cos Sim Std: 0.03836058080250441, MSE Mean: 0.08950281906638605, MSE Std: 0.011765919927316766, Training Time: 0:00:17.698961, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15073, Cos Sim Mean: 0.5306465263795195, Cos Sim Std: 0.05304339865375759, MSE Mean: 0.09029390056698924, MSE Std: 0.01060531779170268, Training Time: 0:00:17.728874, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15074, Cos Sim Mean: 0.5237217993369883, Cos Sim Std: 0.041188697372586125, MSE Mean: 0.09015687834740126, MSE Std: 0.008905036438062262, Training Time: 0:00:17.683909, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15075, Cos Sim Mean: 0.5307642605349601, Cos Sim Std: 0.0276163700031038, MSE Mean: 0.09048832230179564, MSE Std: 0.01078883381762351, Training Time: 0:00:17.698020, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15076, Cos Sim Mean: 0.5272542190378463, Cos Sim Std: 0.03219964406207586, MSE Mean: 0.0905224622314875, MSE Std: 0.006966541368219673, Training Time: 0:00:17.686957, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15077, Cos Sim Mean: 0.5218694593459136, Cos Sim Std: 0.029476035259833243, MSE Mean: 0.09190100836390873, MSE Std: 0.008066433843241953, Training Time: 0:00:17.672252, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15078, Cos Sim Mean: 0.5344330294232036, Cos Sim Std: 0.039994165845841805, MSE Mean: 0.09092737623618738, MSE Std: 0.01052061126744724, Training Time: 0:00:17.701361, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15079, Cos Sim Mean: 0.5446783037329025, Cos Sim Std: 0.04555334659426523, MSE Mean: 0.08753212508481718, MSE Std: 0.007631110125600348, Training Time: 0:00:17.628990, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15080, Cos Sim Mean: 0.5270550690471886, Cos Sim Std: 0.04928025900765372, MSE Mean: 0.08949326309930569, MSE Std: 0.0073972686805309365, Training Time: 0:00:17.663815, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15081, Cos Sim Mean: 0.5291243389464583, Cos Sim Std: 0.02808223375972607, MSE Mean: 0.0947249023550721, MSE Std: 0.007300975335757309, Training Time: 0:00:10.216108, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15082, Cos Sim Mean: 0.527331532745313, Cos Sim Std: 0.0385809925402139, MSE Mean: 0.0988509993390916, MSE Std: 0.006459091249452659, Training Time: 0:00:10.207840, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15083, Cos Sim Mean: 0.5187134440806862, Cos Sim Std: 0.03179415373886771, MSE Mean: 0.10117223206786741, MSE Std: 0.006131238361423755, Training Time: 0:00:10.217685, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15084, Cos Sim Mean: 0.5431843748905061, Cos Sim Std: 0.037531005027715954, MSE Mean: 0.09269966701615831, MSE Std: 0.007810567856782616, Training Time: 0:00:10.201441, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15085, Cos Sim Mean: 0.5167793469178422, Cos Sim Std: 0.04851484884567121, MSE Mean: 0.09628865317162826, MSE Std: 0.01339824379357294, Training Time: 0:00:10.188161, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15086, Cos Sim Mean: 0.4976028583927694, Cos Sim Std: 0.027245027767217357, MSE Mean: 0.10328028560907392, MSE Std: 0.012440149583909389, Training Time: 0:00:10.169328, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15087, Cos Sim Mean: 0.5325337112825824, Cos Sim Std: 0.04067649458693086, MSE Mean: 0.09371057243229994, MSE Std: 0.009751715978737465, Training Time: 0:00:10.173637, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15088, Cos Sim Mean: 0.5344037247727574, Cos Sim Std: 0.042029777479633795, MSE Mean: 0.09304690689453222, MSE Std: 0.004857768290747523, Training Time: 0:00:10.202909, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15089, Cos Sim Mean: 0.5028406146575345, Cos Sim Std: 0.05688092200964647, MSE Mean: 0.10002202861461677, MSE Std: 0.006631583478540925, Training Time: 0:00:10.190176, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15090, Cos Sim Mean: 0.5307324974252288, Cos Sim Std: 0.05005774734745577, MSE Mean: 0.09176231863316447, MSE Std: 0.007794846715500259, Training Time: 0:00:10.197631, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15091, Cos Sim Mean: 0.5220449662401502, Cos Sim Std: 0.025169679122586726, MSE Mean: 0.09120553679928331, MSE Std: 0.006247620928865019, Training Time: 0:00:10.202254, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15092, Cos Sim Mean: 0.5219103760049183, Cos Sim Std: 0.02715369850385997, MSE Mean: 0.09682080568936353, MSE Std: 0.007427931632456252, Training Time: 0:00:10.189559, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15093, Cos Sim Mean: 0.5132725119498751, Cos Sim Std: 0.035220107972344275, MSE Mean: 0.09115623055071445, MSE Std: 0.008706423742098632, Training Time: 0:00:10.254802, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15094, Cos Sim Mean: 0.5256013303650527, Cos Sim Std: 0.039659420130094214, MSE Mean: 0.09504393449750802, MSE Std: 0.006827176850449342, Training Time: 0:00:10.203381, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15095, Cos Sim Mean: 0.5360136995234344, Cos Sim Std: 0.031323679100228805, MSE Mean: 0.09659321325290313, MSE Std: 0.008439993009549882, Training Time: 0:00:10.191697, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15096, Cos Sim Mean: 0.5205086167943537, Cos Sim Std: 0.05646796606950965, MSE Mean: 0.09027922827539495, MSE Std: 0.011608204141974155, Training Time: 0:00:10.191781, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15097, Cos Sim Mean: 0.5221592382153565, Cos Sim Std: 0.03908060044005528, MSE Mean: 0.09441765468266475, MSE Std: 0.008033504063879445, Training Time: 0:00:10.192473, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15098, Cos Sim Mean: 0.5291949931518272, Cos Sim Std: 0.03171877338734226, MSE Mean: 0.09574707174502363, MSE Std: 0.007792544770546472, Training Time: 0:00:10.181941, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15099, Cos Sim Mean: 0.5271492058167215, Cos Sim Std: 0.031168688882385057, MSE Mean: 0.09088520849329088, MSE Std: 0.009289221124838444, Training Time: 0:00:10.194806, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15100, Cos Sim Mean: 0.5252035015606688, Cos Sim Std: 0.02382467844977968, MSE Mean: 0.09036084378333607, MSE Std: 0.008445976690675198, Training Time: 0:00:10.220474, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15101, Cos Sim Mean: 0.5376159118110548, Cos Sim Std: 0.038087408864963666, MSE Mean: 0.09200279300209349, MSE Std: 0.007884985384504275, Training Time: 0:00:10.189238, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15102, Cos Sim Mean: 0.5306128773423658, Cos Sim Std: 0.025989834296200446, MSE Mean: 0.08781733422648061, MSE Std: 0.009604575984024333, Training Time: 0:00:10.221513, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15103, Cos Sim Mean: 0.5586701463974528, Cos Sim Std: 0.03436455965033393, MSE Mean: 0.08852534635388805, MSE Std: 0.010026577985313138, Training Time: 0:00:10.222793, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15104, Cos Sim Mean: 0.5394323834041548, Cos Sim Std: 0.01679867868372038, MSE Mean: 0.09038788140232416, MSE Std: 0.005976034634499733, Training Time: 0:00:10.227815, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15105, Cos Sim Mean: 0.5200593602767054, Cos Sim Std: 0.04148087143545387, MSE Mean: 0.08846456419783738, MSE Std: 0.009715802790467656, Training Time: 0:00:10.208124, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15106, Cos Sim Mean: 0.5307805152557169, Cos Sim Std: 0.020102219375270087, MSE Mean: 0.09032170966908715, MSE Std: 0.007942604932563277, Training Time: 0:00:10.207139, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15107, Cos Sim Mean: 0.5184901573906415, Cos Sim Std: 0.030125668001401575, MSE Mean: 0.09118343815540855, MSE Std: 0.004186838224743518, Training Time: 0:00:10.234492, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15108, Cos Sim Mean: 0.5183069729704151, Cos Sim Std: 0.02827214963449171, MSE Mean: 0.0956594388934224, MSE Std: 0.00776331056634241, Training Time: 0:00:17.406901, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15109, Cos Sim Mean: 0.5234343183171595, Cos Sim Std: 0.022016126380837664, MSE Mean: 0.095452711495947, MSE Std: 0.007123009430018481, Training Time: 0:00:17.373046, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15110, Cos Sim Mean: 0.5097036457690598, Cos Sim Std: 0.03612006667366593, MSE Mean: 0.10085225189133715, MSE Std: 0.010944248234543496, Training Time: 0:00:17.431764, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15111, Cos Sim Mean: 0.523654104190882, Cos Sim Std: 0.03549402171501298, MSE Mean: 0.09353863385897968, MSE Std: 0.008023199752321863, Training Time: 0:00:17.454461, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15112, Cos Sim Mean: 0.5149297148480081, Cos Sim Std: 0.004805955190207494, MSE Mean: 0.09630661984448882, MSE Std: 0.00933165523115703, Training Time: 0:00:17.454947, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15113, Cos Sim Mean: 0.5111794503657944, Cos Sim Std: 0.037401983666949426, MSE Mean: 0.09880815026689514, MSE Std: 0.008533075988101312, Training Time: 0:00:17.405312, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15114, Cos Sim Mean: 0.5202218338431089, Cos Sim Std: 0.04219377943477311, MSE Mean: 0.09252666413554049, MSE Std: 0.0071114177194980316, Training Time: 0:00:17.450336, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15115, Cos Sim Mean: 0.4869981233734849, Cos Sim Std: 0.029961191953667442, MSE Mean: 0.0961520450312601, MSE Std: 0.010356661794675696, Training Time: 0:00:17.441958, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15116, Cos Sim Mean: 0.49229058414336635, Cos Sim Std: 0.046056004761255175, MSE Mean: 0.10049358804634907, MSE Std: 0.010817542541092198, Training Time: 0:00:17.431703, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15117, Cos Sim Mean: 0.5324081793889153, Cos Sim Std: 0.024527958859517866, MSE Mean: 0.09082889782748266, MSE Std: 0.006708639638349565, Training Time: 0:00:17.452349, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15118, Cos Sim Mean: 0.5163195635906075, Cos Sim Std: 0.033077904827661604, MSE Mean: 0.09217311454259257, MSE Std: 0.0070789107434657, Training Time: 0:00:17.463326, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15119, Cos Sim Mean: 0.5146646557892566, Cos Sim Std: 0.03001795049429675, MSE Mean: 0.09678219656706528, MSE Std: 0.008849393456435125, Training Time: 0:00:17.423443, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15120, Cos Sim Mean: 0.5342679105433629, Cos Sim Std: 0.023882893256146016, MSE Mean: 0.09108985191645494, MSE Std: 0.008183744809341762, Training Time: 0:00:17.452985, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15121, Cos Sim Mean: 0.5341539685176276, Cos Sim Std: 0.02610505643984923, MSE Mean: 0.09115671030362735, MSE Std: 0.007637953788687768, Training Time: 0:00:17.440365, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15122, Cos Sim Mean: 0.5271260028029785, Cos Sim Std: 0.018057562718433114, MSE Mean: 0.09603616333611872, MSE Std: 0.008166402907687106, Training Time: 0:00:17.446388, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15123, Cos Sim Mean: 0.5131287861538915, Cos Sim Std: 0.03915666372918368, MSE Mean: 0.0927154972530134, MSE Std: 0.010431497723216313, Training Time: 0:00:17.434701, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15124, Cos Sim Mean: 0.5286320643384861, Cos Sim Std: 0.030874712838028444, MSE Mean: 0.09232102186816639, MSE Std: 0.006433472417532577, Training Time: 0:00:17.418331, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15125, Cos Sim Mean: 0.5270573213139746, Cos Sim Std: 0.02658371635445467, MSE Mean: 0.09528182640331137, MSE Std: 0.008910769200963734, Training Time: 0:00:17.414273, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15126, Cos Sim Mean: 0.5235783291911906, Cos Sim Std: 0.027850026689212458, MSE Mean: 0.08997515123470132, MSE Std: 0.007811389912527396, Training Time: 0:00:17.498235, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15127, Cos Sim Mean: 0.5096691727736216, Cos Sim Std: 0.03942212852232506, MSE Mean: 0.09056049629486311, MSE Std: 0.008252448819174179, Training Time: 0:00:17.453790, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15128, Cos Sim Mean: 0.5359656666583291, Cos Sim Std: 0.047812846030194686, MSE Mean: 0.09096089727931497, MSE Std: 0.007531878149548338, Training Time: 0:00:17.481221, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15129, Cos Sim Mean: 0.539523680194686, Cos Sim Std: 0.026979163332953224, MSE Mean: 0.09042222930968445, MSE Std: 0.007447724671505099, Training Time: 0:00:17.466102, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15130, Cos Sim Mean: 0.5357396993655421, Cos Sim Std: 0.02415463119425685, MSE Mean: 0.08985284415705072, MSE Std: 0.008925801925133058, Training Time: 0:00:17.451250, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15131, Cos Sim Mean: 0.5168194067368131, Cos Sim Std: 0.042984187221172844, MSE Mean: 0.09296245162426912, MSE Std: 0.006910839248615987, Training Time: 0:00:17.487795, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15132, Cos Sim Mean: 0.5237149360864682, Cos Sim Std: 0.035625490391541566, MSE Mean: 0.09099895104745179, MSE Std: 0.008997326539560726, Training Time: 0:00:17.507558, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15133, Cos Sim Mean: 0.5272242296497686, Cos Sim Std: 0.029053862797218645, MSE Mean: 0.08973089356159111, MSE Std: 0.008618482762014318, Training Time: 0:00:17.501257, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15134, Cos Sim Mean: 0.5360770113880803, Cos Sim Std: 0.036981608094700254, MSE Mean: 0.0907813286645579, MSE Std: 0.0054449898364983835, Training Time: 0:00:17.449452, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15135, Cos Sim Mean: 0.5219696070407123, Cos Sim Std: 0.02608094641703658, MSE Mean: 0.09863736856451172, MSE Std: 0.008933763893116226, Training Time: 0:00:10.070569, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15136, Cos Sim Mean: 0.5269598412553408, Cos Sim Std: 0.029813954765270826, MSE Mean: 0.10018607272564599, MSE Std: 0.005911474091908393, Training Time: 0:00:10.080718, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15137, Cos Sim Mean: 0.4745900502145175, Cos Sim Std: 0.06924039511219975, MSE Mean: 0.1090280073035272, MSE Std: 0.0032840141994715773, Training Time: 0:00:10.075997, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15138, Cos Sim Mean: 0.5236866776860292, Cos Sim Std: 0.02218693876268424, MSE Mean: 0.09515706345552402, MSE Std: 0.008670716843329415, Training Time: 0:00:10.055259, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15139, Cos Sim Mean: 0.5132499127703518, Cos Sim Std: 0.03128457584799359, MSE Mean: 0.09741117760488546, MSE Std: 0.008467083172812388, Training Time: 0:00:10.089279, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15140, Cos Sim Mean: 0.48533094232638707, Cos Sim Std: 0.03176975476650515, MSE Mean: 0.1083658386576635, MSE Std: 0.01038651596022226, Training Time: 0:00:10.051877, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15141, Cos Sim Mean: 0.5234505763106102, Cos Sim Std: 0.019745237824762424, MSE Mean: 0.09514302134791183, MSE Std: 0.007410947340982728, Training Time: 0:00:10.083549, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15142, Cos Sim Mean: 0.5234109454964008, Cos Sim Std: 0.02998315549001316, MSE Mean: 0.0960775229164567, MSE Std: 0.007659372794143694, Training Time: 0:00:10.064036, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15143, Cos Sim Mean: 0.46595762693295095, Cos Sim Std: 0.053087114983836815, MSE Mean: 0.10893223863252625, MSE Std: 0.003997404202081336, Training Time: 0:00:10.084935, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15144, Cos Sim Mean: 0.5184000639312248, Cos Sim Std: 0.021173317570423046, MSE Mean: 0.0922339951071111, MSE Std: 0.008321097001397456, Training Time: 0:00:10.071982, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15145, Cos Sim Mean: 0.5147699432271089, Cos Sim Std: 0.018281439087989574, MSE Mean: 0.09513874713050273, MSE Std: 0.007984271993016717, Training Time: 0:00:10.083528, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15146, Cos Sim Mean: 0.5219081713132898, Cos Sim Std: 0.033086651631452337, MSE Mean: 0.10166438324179454, MSE Std: 0.00582776617326454, Training Time: 0:00:10.075236, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15147, Cos Sim Mean: 0.5287891254389047, Cos Sim Std: 0.03985039700031151, MSE Mean: 0.09341528097620524, MSE Std: 0.007946968487268787, Training Time: 0:00:10.070826, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15148, Cos Sim Mean: 0.520116551090116, Cos Sim Std: 0.035048142900862084, MSE Mean: 0.0943955674168839, MSE Std: 0.007108964849567655, Training Time: 0:00:10.061500, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15149, Cos Sim Mean: 0.5358069419469882, Cos Sim Std: 0.040473525726321714, MSE Mean: 0.10152051208945216, MSE Std: 0.009604871769025731, Training Time: 0:00:10.063099, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15150, Cos Sim Mean: 0.5164233883961439, Cos Sim Std: 0.03371361650069888, MSE Mean: 0.09221088312299554, MSE Std: 0.007139263996635178, Training Time: 0:00:10.084161, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15151, Cos Sim Mean: 0.5304922767835522, Cos Sim Std: 0.031120992268725486, MSE Mean: 0.0939696714583019, MSE Std: 0.005980915707224608, Training Time: 0:00:10.075479, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15152, Cos Sim Mean: 0.5220009453376283, Cos Sim Std: 0.04206648956794911, MSE Mean: 0.09963011292756338, MSE Std: 0.006704385567950352, Training Time: 0:00:10.056996, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15153, Cos Sim Mean: 0.5326773931426205, Cos Sim Std: 0.05435075159362239, MSE Mean: 0.08831345467759918, MSE Std: 0.00841510207472677, Training Time: 0:00:10.113113, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15154, Cos Sim Mean: 0.5201209870542592, Cos Sim Std: 0.03355948928237216, MSE Mean: 0.09014207962537071, MSE Std: 0.007087939999156588, Training Time: 0:00:10.088770, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15155, Cos Sim Mean: 0.5305953507399872, Cos Sim Std: 0.03883823576897884, MSE Mean: 0.09540029254388518, MSE Std: 0.0058870889280674635, Training Time: 0:00:10.121130, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15156, Cos Sim Mean: 0.5393316985893781, Cos Sim Std: 0.025785762047676852, MSE Mean: 0.08910080457423379, MSE Std: 0.006975759943339498, Training Time: 0:00:10.098078, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15157, Cos Sim Mean: 0.525200249922518, Cos Sim Std: 0.04984541157953306, MSE Mean: 0.08986098358118508, MSE Std: 0.0070850981172351675, Training Time: 0:00:10.080445, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15158, Cos Sim Mean: 0.5359811315748757, Cos Sim Std: 0.04488610203612563, MSE Mean: 0.09498168755215677, MSE Std: 0.005320998762404266, Training Time: 0:00:10.113026, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15159, Cos Sim Mean: 0.5446495682149057, Cos Sim Std: 0.028821065733611352, MSE Mean: 0.09001819301886078, MSE Std: 0.006618630806695927, Training Time: 0:00:10.074166, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15160, Cos Sim Mean: 0.5324431006389422, Cos Sim Std: 0.03416540666330365, MSE Mean: 0.09108274661996345, MSE Std: 0.0054142230223601226, Training Time: 0:00:10.096899, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15161, Cos Sim Mean: 0.5290027558665281, Cos Sim Std: 0.03384876606728107, MSE Mean: 0.09493622393165077, MSE Std: 0.005372531011424179, Training Time: 0:00:10.073049, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15162, Cos Sim Mean: 0.5307118798451853, Cos Sim Std: 0.021434205756031353, MSE Mean: 0.09604638250477222, MSE Std: 0.009188196693609213, Training Time: 0:00:17.453124, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15163, Cos Sim Mean: 0.5342569838543624, Cos Sim Std: 0.04075835221324019, MSE Mean: 0.10325269569163328, MSE Std: 0.00853297915946503, Training Time: 0:00:17.364136, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15164, Cos Sim Mean: 0.47814796149784256, Cos Sim Std: 0.030132647534109706, MSE Mean: 0.11260789771161246, MSE Std: 0.008710022916113471, Training Time: 0:00:17.370976, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15165, Cos Sim Mean: 0.5167665953700693, Cos Sim Std: 0.02615553576001648, MSE Mean: 0.09567675175832954, MSE Std: 0.008245061905836433, Training Time: 0:00:17.364129, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15166, Cos Sim Mean: 0.5289263963836238, Cos Sim Std: 0.034391903193487144, MSE Mean: 0.1002514681867619, MSE Std: 0.007873210250983191, Training Time: 0:00:17.389455, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15167, Cos Sim Mean: 0.4883971699494725, Cos Sim Std: 0.034046634943873076, MSE Mean: 0.110490596347636, MSE Std: 0.012030592146932131, Training Time: 0:00:17.381827, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15168, Cos Sim Mean: 0.5168871515773741, Cos Sim Std: 0.03701592937307014, MSE Mean: 0.09663279127959386, MSE Std: 0.006906796903763281, Training Time: 0:00:17.433825, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15169, Cos Sim Mean: 0.5256458264583438, Cos Sim Std: 0.02965747071284521, MSE Mean: 0.09960886551115126, MSE Std: 0.005193078101183705, Training Time: 0:00:17.389500, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15170, Cos Sim Mean: 0.4836683267511014, Cos Sim Std: 0.05445880701872147, MSE Mean: 0.11000963924949196, MSE Std: 0.011070117813121023, Training Time: 0:00:17.375402, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15171, Cos Sim Mean: 0.5290745112431912, Cos Sim Std: 0.056912324892721876, MSE Mean: 0.09596772654249201, MSE Std: 0.009191110671659418, Training Time: 0:00:17.433358, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15172, Cos Sim Mean: 0.534385705854128, Cos Sim Std: 0.04821400104756229, MSE Mean: 0.0968451812530455, MSE Std: 0.006177035958202338, Training Time: 0:00:17.451364, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15173, Cos Sim Mean: 0.5323201463509614, Cos Sim Std: 0.04605390225451754, MSE Mean: 0.1033143080357489, MSE Std: 0.0086355293211629, Training Time: 0:00:17.450049, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15174, Cos Sim Mean: 0.5324932728311043, Cos Sim Std: 0.05316242870423736, MSE Mean: 0.09443445392585725, MSE Std: 0.008681169454203046, Training Time: 0:00:17.421629, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15175, Cos Sim Mean: 0.541168989029165, Cos Sim Std: 0.04099572099243049, MSE Mean: 0.09709879721095907, MSE Std: 0.006685603866539427, Training Time: 0:00:17.475200, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15176, Cos Sim Mean: 0.5255997891226658, Cos Sim Std: 0.03274654550023802, MSE Mean: 0.1027076907936568, MSE Std: 0.0058550228950903435, Training Time: 0:00:17.470919, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15177, Cos Sim Mean: 0.532455147251176, Cos Sim Std: 0.050920351377555545, MSE Mean: 0.0957564292475705, MSE Std: 0.008943997739679887, Training Time: 0:00:17.481235, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15178, Cos Sim Mean: 0.5116862867963192, Cos Sim Std: 0.030419177270320442, MSE Mean: 0.09760210459805206, MSE Std: 0.005845920058029525, Training Time: 0:00:17.447031, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15179, Cos Sim Mean: 0.530863154946301, Cos Sim Std: 0.03876876204277953, MSE Mean: 0.10261505583645233, MSE Std: 0.004324777395338906, Training Time: 0:00:17.472040, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15180, Cos Sim Mean: 0.5307487520591596, Cos Sim Std: 0.04153698947712471, MSE Mean: 0.09431446684828407, MSE Std: 0.009373755434739553, Training Time: 0:00:17.499284, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15181, Cos Sim Mean: 0.5447319342551981, Cos Sim Std: 0.037330299590825705, MSE Mean: 0.09129920225252805, MSE Std: 0.008661109898471388, Training Time: 0:00:17.566934, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15182, Cos Sim Mean: 0.5167199740831359, Cos Sim Std: 0.028893423869566313, MSE Mean: 0.09830444944908823, MSE Std: 0.0050076943128152295, Training Time: 0:00:17.493329, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15183, Cos Sim Mean: 0.5361935524232385, Cos Sim Std: 0.05322219470816472, MSE Mean: 0.09340123857591642, MSE Std: 0.009848147735515697, Training Time: 0:00:17.528880, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15184, Cos Sim Mean: 0.5484686115129279, Cos Sim Std: 0.05827221227855467, MSE Mean: 0.09427444669269994, MSE Std: 0.009048645145967676, Training Time: 0:00:17.520192, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15185, Cos Sim Mean: 0.5291831271780886, Cos Sim Std: 0.04819477419247386, MSE Mean: 0.09717252811223911, MSE Std: 0.007878239181232843, Training Time: 0:00:17.497711, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15186, Cos Sim Mean: 0.5238374921903984, Cos Sim Std: 0.046215751462573236, MSE Mean: 0.09312397170593524, MSE Std: 0.010313151132958175, Training Time: 0:00:17.509551, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15187, Cos Sim Mean: 0.5188470501033182, Cos Sim Std: 0.053157413691349305, MSE Mean: 0.0912130955582737, MSE Std: 0.007570495714603031, Training Time: 0:00:17.470933, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15188, Cos Sim Mean: 0.5361281224059884, Cos Sim Std: 0.036998132641091565, MSE Mean: 0.096189290257126, MSE Std: 0.005931306487941743, Training Time: 0:00:17.495555, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15189, Cos Sim Mean: 0.5292995934354175, Cos Sim Std: 0.03973829368257642, MSE Mean: 0.09960563359589134, MSE Std: 0.00616994649076285, Training Time: 0:00:10.105352, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15190, Cos Sim Mean: 0.516911004127115, Cos Sim Std: 0.029237116534791975, MSE Mean: 0.1086836735609789, MSE Std: 0.007107669278354357, Training Time: 0:00:10.070584, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15191, Cos Sim Mean: 0.3991506291870606, Cos Sim Std: 0.035757290379699574, MSE Mean: 0.1279001329980213, MSE Std: 0.009418151276248194, Training Time: 0:00:10.058328, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15192, Cos Sim Mean: 0.5274663732236199, Cos Sim Std: 0.04864085734928148, MSE Mean: 0.09707993884926203, MSE Std: 0.0071029405209777855, Training Time: 0:00:10.085733, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15193, Cos Sim Mean: 0.5293229838501265, Cos Sim Std: 0.03967875646268994, MSE Mean: 0.1037327825766278, MSE Std: 0.00622375811960315, Training Time: 0:00:10.066847, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15194, Cos Sim Mean: 0.46939227178724197, Cos Sim Std: 0.014746303391169141, MSE Mean: 0.12023972759546246, MSE Std: 0.006364836993740986, Training Time: 0:00:10.105772, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15195, Cos Sim Mean: 0.5134313306596192, Cos Sim Std: 0.04168638978218674, MSE Mean: 0.09855572521786857, MSE Std: 0.005836375522282724, Training Time: 0:00:10.043316, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15196, Cos Sim Mean: 0.5205881632254253, Cos Sim Std: 0.040100094950540933, MSE Mean: 0.10324799168837018, MSE Std: 0.0045297256741260675, Training Time: 0:00:10.061334, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15197, Cos Sim Mean: 0.45026180342287486, Cos Sim Std: 0.06396512672340676, MSE Mean: 0.12000131330814459, MSE Std: 0.0031425004894126323, Training Time: 0:00:10.099746, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15198, Cos Sim Mean: 0.5185782310791274, Cos Sim Std: 0.047589498785745234, MSE Mean: 0.09750584304167013, MSE Std: 0.008208879501650737, Training Time: 0:00:10.119956, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15199, Cos Sim Mean: 0.5082288978697627, Cos Sim Std: 0.03901540248543835, MSE Mean: 0.10366832219428464, MSE Std: 0.0055893202921054215, Training Time: 0:00:10.080520, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15200, Cos Sim Mean: 0.5202017560841362, Cos Sim Std: 0.015769109032719556, MSE Mean: 0.11065383937727742, MSE Std: 0.004920909399478043, Training Time: 0:00:10.101765, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15201, Cos Sim Mean: 0.5271985245957941, Cos Sim Std: 0.05261308785256039, MSE Mean: 0.097669055199061, MSE Std: 0.009185776956050998, Training Time: 0:00:10.054108, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15202, Cos Sim Mean: 0.5134679329825238, Cos Sim Std: 0.047541032691023825, MSE Mean: 0.10163258022996377, MSE Std: 0.00775778172337138, Training Time: 0:00:10.088278, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15203, Cos Sim Mean: 0.5046516173025645, Cos Sim Std: 0.03350955423876138, MSE Mean: 0.10973822570317608, MSE Std: 0.00573549322230661, Training Time: 0:00:10.070713, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15204, Cos Sim Mean: 0.5112778182407498, Cos Sim Std: 0.04237310073652407, MSE Mean: 0.09930107335209032, MSE Std: 0.0070860355282356775, Training Time: 0:00:10.097202, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15205, Cos Sim Mean: 0.5202285376478101, Cos Sim Std: 0.02821842142509884, MSE Mean: 0.10170209068735717, MSE Std: 0.005891425226555403, Training Time: 0:00:10.078784, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15206, Cos Sim Mean: 0.4908193098327591, Cos Sim Std: 0.05606555790763188, MSE Mean: 0.10702774383894662, MSE Std: 0.0031954331861704416, Training Time: 0:00:10.092812, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 15207, Cos Sim Mean: 0.5150623403977983, Cos Sim Std: 0.04702378232167509, MSE Mean: 0.09527372117248264, MSE Std: 0.0072043902574509934, Training Time: 0:00:10.077942, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 15208, Cos Sim Mean: 0.5396364182509521, Cos Sim Std: 0.033907394338096704, MSE Mean: 0.09518632838521521, MSE Std: 0.006409282121540802, Training Time: 0:00:10.124718, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 15209, Cos Sim Mean: 0.5203658252073395, Cos Sim Std: 0.045840303700542345, MSE Mean: 0.10468120357075839, MSE Std: 0.006295450392759435, Training Time: 0:00:10.132968, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 15210, Cos Sim Mean: 0.5414587105470445, Cos Sim Std: 0.04416451739402738, MSE Mean: 0.0945046500738395, MSE Std: 0.007284967215453262, Training Time: 0:00:10.083054, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 15211, Cos Sim Mean: 0.5310453377185489, Cos Sim Std: 0.0515551145777291, MSE Mean: 0.09781402242288958, MSE Std: 0.0070175996497386615, Training Time: 0:00:10.089570, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 15212, Cos Sim Mean: 0.5239682762882207, Cos Sim Std: 0.03895285123355386, MSE Mean: 0.1037257983008423, MSE Std: 0.005624120179656316, Training Time: 0:00:10.102455, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 15213, Cos Sim Mean: 0.5237918996466098, Cos Sim Std: 0.038265523754429605, MSE Mean: 0.09508315248990293, MSE Std: 0.007734860326447191, Training Time: 0:00:10.118544, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 15214, Cos Sim Mean: 0.522022319339824, Cos Sim Std: 0.03022156870701342, MSE Mean: 0.0977613035425082, MSE Std: 0.006729676662557364, Training Time: 0:00:10.109546, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 15215, Cos Sim Mean: 0.5100674432857835, Cos Sim Std: 0.04314828561157457, MSE Mean: 0.10362620849158147, MSE Std: 0.005382131157761173, Training Time: 0:00:10.123994, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n"
     ]
    }
   ],
   "source": [
    "kfold_id = 15000\n",
    "\n",
    "resumo = pd.DataFrame(columns=['kfold_id','cos_sim_mean','cos_sim_std','mse_mean','mse_std','training_time','batch_size','lstm_out','num_dense','dropout'])\n",
    "\n",
    "number_epochs = 30\n",
    "\n",
    "tokenizer_kfold = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='', lower=False)\n",
    "tokenizer_kfold.fit_on_texts(df_train['new_title'])\n",
    "\n",
    "for emb_dim in [300, 200, 100, 50]:\n",
    "  \n",
    "  embeddings_index_kfold = load_embedding(emb_dim)\n",
    "  \n",
    "  for batch_size in [32, 64]:\n",
    "      for lstm_out in [50, 100, 150]:\n",
    "          for num_dense in [50, 100, 150]:\n",
    "              for dropout in [0.3, 0.4, 0.5]:\n",
    "\n",
    "                      cvscores_mse = []\n",
    "                      cvscores_cos_sim = []\n",
    "                      time_list = []\n",
    "\n",
    "                      seed = 42\n",
    "                      np.random.seed(seed)\n",
    "\n",
    "                      for train, val in skf.split(df_train, df_train['quantile']):\n",
    "  #                         print(train)\n",
    "                          X_train = df_train.iloc[train]\n",
    "                          X_val = df_train.iloc[val]\n",
    "\n",
    "                          Y_train = df_train['sentiment'].iloc[train]\n",
    "                          Y_val = df_train['sentiment'].iloc[val]\n",
    "\n",
    "                          # get sentences ready for usage\n",
    "                          sentences_train_pad, sentences_val_pad, tok_kfold = get_tok_sentences(X_train[\"new_title\"], X_val[\"new_title\"])\n",
    "\n",
    "                          embedding_matrix = get_embedding_matrix(emb_dim, MAX_VOCAB_SIZE, MAX_SEQUENCE_LENGTH, tok_kfold, embeddings_index_kfold)\n",
    "\n",
    "  #                         nn_input_train = {'Word_Seq': sentences_train_pad, 'Lexical': np.array(X_train['mean_VADER_LMD'].tolist())}\n",
    "  #                         nn_input_val = {'Word_Seq': sentences_val_pad, 'Lexical': np.array(X_val['mean_VADER_LMD'].tolist())}\n",
    "  #                         nn_input_train = {'Word_Seq': sentences_train_pad, 'Lexical': np.array(X_train['mean_VADER'].tolist())}\n",
    "  #                         nn_input_val = {'Word_Seq': sentences_val_pad, 'Lexical': np.array(X_val['mean_VADER'].tolist())}\n",
    "                          nn_input_train = {'Word_Seq': sentences_train_pad}\n",
    "                          nn_input_val = {'Word_Seq': sentences_val_pad}\n",
    "\n",
    "                          model_name = 'kfoldid_' + str(kfold_id) + '-dim_' + str(emb_dim) + '-bs_' + str(batch_size) + '-lo_' + str(lstm_out) + '-nd_' + str(num_dense) + '-dv_' + str(10*dropout)\n",
    "\n",
    "                          lstm = create_model_lstm(lstm_out, num_dense, dropout, embedding_matrix, True)\n",
    "\n",
    "                          init = datetime.datetime.now()\n",
    "                          trained = train_model(lstm, nn_input_train, Y_train, batch_size, number_epochs, model_name, nn_input_val, Y_val)\n",
    "                          training_time = (datetime.datetime.now() - init)\n",
    "                          cvscores_mse.append(trained.history['val_loss'][-1])\n",
    "                          cvscores_cos_sim.append(-trained.history['val_cosine_proximity'][-1])\n",
    "                          time_list.append(training_time)\n",
    "                          # save_model(lstm, trained, model_name)\n",
    "\n",
    "                          if K.backend() == 'tensorflow':\n",
    "                            K.clear_session()\n",
    "\n",
    "                      result = [kfold_id, np.mean(cvscores_cos_sim), np.std(cvscores_cos_sim), np.mean(cvscores_mse), np.std(cvscores_mse), np.mean(time_list), batch_size, lstm_out, num_dense, dropout]\n",
    "                      resumo = resumo.append(pd.Series(result, index=resumo.columns), ignore_index=True)\n",
    "\n",
    "                      print('ID: {}, Cos Sim Mean: {}, Cos Sim Std: {}, MSE Mean: {}, MSE Std: {}, Training Time: {}, Batch: {}, LSTM Out: {}, Num Dense: {}, Dropout: {}'.format(*result))\n",
    "\n",
    "                      kfold_id = kfold_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1969
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15245046,
     "status": "ok",
     "timestamp": 1557888684250,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "2uxkO9P3wp8W",
    "outputId": "6115da4a-605b-42ba-ba41-e991b90ed7b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kfold_id</th>\n",
       "      <th>cos_sim_mean</th>\n",
       "      <th>cos_sim_std</th>\n",
       "      <th>mse_mean</th>\n",
       "      <th>mse_std</th>\n",
       "      <th>training_time</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lstm_out</th>\n",
       "      <th>num_dense</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>15079</td>\n",
       "      <td>0.544678</td>\n",
       "      <td>0.045553</td>\n",
       "      <td>0.087532</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>00:00:17.628990</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>15102</td>\n",
       "      <td>0.530613</td>\n",
       "      <td>0.025990</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>00:00:10.221513</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>15153</td>\n",
       "      <td>0.532677</td>\n",
       "      <td>0.054351</td>\n",
       "      <td>0.088313</td>\n",
       "      <td>0.008415</td>\n",
       "      <td>00:00:10.113113</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>15105</td>\n",
       "      <td>0.520059</td>\n",
       "      <td>0.041481</td>\n",
       "      <td>0.088465</td>\n",
       "      <td>0.009716</td>\n",
       "      <td>00:00:10.208124</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15018</td>\n",
       "      <td>0.541109</td>\n",
       "      <td>0.024352</td>\n",
       "      <td>0.088477</td>\n",
       "      <td>0.008887</td>\n",
       "      <td>00:00:17.837516</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>15103</td>\n",
       "      <td>0.558670</td>\n",
       "      <td>0.034365</td>\n",
       "      <td>0.088525</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>00:00:10.222793</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15048</td>\n",
       "      <td>0.514831</td>\n",
       "      <td>0.060402</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>00:00:09.635081</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15025</td>\n",
       "      <td>0.529003</td>\n",
       "      <td>0.027270</td>\n",
       "      <td>0.088736</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>00:00:16.947035</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15021</td>\n",
       "      <td>0.537667</td>\n",
       "      <td>0.038679</td>\n",
       "      <td>0.088956</td>\n",
       "      <td>0.008358</td>\n",
       "      <td>00:00:17.001580</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>15156</td>\n",
       "      <td>0.539332</td>\n",
       "      <td>0.025786</td>\n",
       "      <td>0.089101</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>00:00:10.098078</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15017</td>\n",
       "      <td>0.528796</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.089413</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>00:00:17.837852</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>15064</td>\n",
       "      <td>0.516613</td>\n",
       "      <td>0.033609</td>\n",
       "      <td>0.089424</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>00:00:17.691405</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>15080</td>\n",
       "      <td>0.527055</td>\n",
       "      <td>0.049280</td>\n",
       "      <td>0.089493</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>00:00:17.663815</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>15072</td>\n",
       "      <td>0.534273</td>\n",
       "      <td>0.038361</td>\n",
       "      <td>0.089503</td>\n",
       "      <td>0.011766</td>\n",
       "      <td>00:00:17.698961</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>15051</td>\n",
       "      <td>0.506252</td>\n",
       "      <td>0.038108</td>\n",
       "      <td>0.089608</td>\n",
       "      <td>0.009261</td>\n",
       "      <td>00:00:09.661019</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15016</td>\n",
       "      <td>0.527126</td>\n",
       "      <td>0.026261</td>\n",
       "      <td>0.089700</td>\n",
       "      <td>0.011520</td>\n",
       "      <td>00:00:17.844593</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15022</td>\n",
       "      <td>0.516858</td>\n",
       "      <td>0.026130</td>\n",
       "      <td>0.089723</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>00:00:16.991449</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>15133</td>\n",
       "      <td>0.527224</td>\n",
       "      <td>0.029054</td>\n",
       "      <td>0.089731</td>\n",
       "      <td>0.008618</td>\n",
       "      <td>00:00:17.501257</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>15045</td>\n",
       "      <td>0.506338</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>0.089734</td>\n",
       "      <td>0.008460</td>\n",
       "      <td>00:00:09.596128</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15026</td>\n",
       "      <td>0.543024</td>\n",
       "      <td>0.035127</td>\n",
       "      <td>0.089847</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>00:00:16.946588</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>15130</td>\n",
       "      <td>0.535740</td>\n",
       "      <td>0.024155</td>\n",
       "      <td>0.089853</td>\n",
       "      <td>0.008926</td>\n",
       "      <td>00:00:17.451250</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>15157</td>\n",
       "      <td>0.525200</td>\n",
       "      <td>0.049845</td>\n",
       "      <td>0.089861</td>\n",
       "      <td>0.007085</td>\n",
       "      <td>00:00:10.080445</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>15052</td>\n",
       "      <td>0.525448</td>\n",
       "      <td>0.018024</td>\n",
       "      <td>0.089903</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>00:00:09.613615</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>15126</td>\n",
       "      <td>0.523578</td>\n",
       "      <td>0.027850</td>\n",
       "      <td>0.089975</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>00:00:17.498235</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>15159</td>\n",
       "      <td>0.544650</td>\n",
       "      <td>0.028821</td>\n",
       "      <td>0.090018</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>00:00:10.074166</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15012</td>\n",
       "      <td>0.508008</td>\n",
       "      <td>0.032458</td>\n",
       "      <td>0.090019</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>00:00:17.782318</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>15049</td>\n",
       "      <td>0.518512</td>\n",
       "      <td>0.026668</td>\n",
       "      <td>0.090085</td>\n",
       "      <td>0.007807</td>\n",
       "      <td>00:00:09.647228</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>15154</td>\n",
       "      <td>0.520121</td>\n",
       "      <td>0.033559</td>\n",
       "      <td>0.090142</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>00:00:10.088770</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>15074</td>\n",
       "      <td>0.523722</td>\n",
       "      <td>0.041189</td>\n",
       "      <td>0.090157</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>00:00:17.683909</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15020</td>\n",
       "      <td>0.518384</td>\n",
       "      <td>0.026544</td>\n",
       "      <td>0.090209</td>\n",
       "      <td>0.005384</td>\n",
       "      <td>00:00:17.804757</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>15110</td>\n",
       "      <td>0.509704</td>\n",
       "      <td>0.036120</td>\n",
       "      <td>0.100852</td>\n",
       "      <td>0.010944</td>\n",
       "      <td>00:00:17.431764</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>15083</td>\n",
       "      <td>0.518713</td>\n",
       "      <td>0.031794</td>\n",
       "      <td>0.101172</td>\n",
       "      <td>0.006131</td>\n",
       "      <td>00:00:10.217685</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>15149</td>\n",
       "      <td>0.535807</td>\n",
       "      <td>0.040474</td>\n",
       "      <td>0.101521</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>00:00:10.063099</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>15202</td>\n",
       "      <td>0.513468</td>\n",
       "      <td>0.047541</td>\n",
       "      <td>0.101633</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>00:00:10.088278</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>15146</td>\n",
       "      <td>0.521908</td>\n",
       "      <td>0.033087</td>\n",
       "      <td>0.101664</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>00:00:10.075236</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>15205</td>\n",
       "      <td>0.520229</td>\n",
       "      <td>0.028218</td>\n",
       "      <td>0.101702</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>00:00:10.078784</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>15179</td>\n",
       "      <td>0.530863</td>\n",
       "      <td>0.038769</td>\n",
       "      <td>0.102615</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>00:00:17.472040</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>15176</td>\n",
       "      <td>0.525600</td>\n",
       "      <td>0.032747</td>\n",
       "      <td>0.102708</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>00:00:17.470919</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>15196</td>\n",
       "      <td>0.520588</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.103248</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>00:00:10.061334</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>15163</td>\n",
       "      <td>0.534257</td>\n",
       "      <td>0.040758</td>\n",
       "      <td>0.103253</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>00:00:17.364136</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>15086</td>\n",
       "      <td>0.497603</td>\n",
       "      <td>0.027245</td>\n",
       "      <td>0.103280</td>\n",
       "      <td>0.012440</td>\n",
       "      <td>00:00:10.169328</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>15173</td>\n",
       "      <td>0.532320</td>\n",
       "      <td>0.046054</td>\n",
       "      <td>0.103314</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>00:00:17.450049</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>15215</td>\n",
       "      <td>0.510067</td>\n",
       "      <td>0.043148</td>\n",
       "      <td>0.103626</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>00:00:10.123994</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>15199</td>\n",
       "      <td>0.508229</td>\n",
       "      <td>0.039015</td>\n",
       "      <td>0.103668</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>00:00:10.080520</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>15212</td>\n",
       "      <td>0.523968</td>\n",
       "      <td>0.038953</td>\n",
       "      <td>0.103726</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>00:00:10.102455</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>15193</td>\n",
       "      <td>0.529323</td>\n",
       "      <td>0.039679</td>\n",
       "      <td>0.103733</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>00:00:10.066847</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>15209</td>\n",
       "      <td>0.520366</td>\n",
       "      <td>0.045840</td>\n",
       "      <td>0.104681</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>00:00:10.132968</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>15206</td>\n",
       "      <td>0.490819</td>\n",
       "      <td>0.056066</td>\n",
       "      <td>0.107028</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>00:00:10.092812</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>15140</td>\n",
       "      <td>0.485331</td>\n",
       "      <td>0.031770</td>\n",
       "      <td>0.108366</td>\n",
       "      <td>0.010387</td>\n",
       "      <td>00:00:10.051877</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>15190</td>\n",
       "      <td>0.516911</td>\n",
       "      <td>0.029237</td>\n",
       "      <td>0.108684</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>00:00:10.070584</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>15143</td>\n",
       "      <td>0.465958</td>\n",
       "      <td>0.053087</td>\n",
       "      <td>0.108932</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>00:00:10.084935</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>15137</td>\n",
       "      <td>0.474590</td>\n",
       "      <td>0.069240</td>\n",
       "      <td>0.109028</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>00:00:10.075997</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>15203</td>\n",
       "      <td>0.504652</td>\n",
       "      <td>0.033510</td>\n",
       "      <td>0.109738</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>00:00:10.070713</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>15170</td>\n",
       "      <td>0.483668</td>\n",
       "      <td>0.054459</td>\n",
       "      <td>0.110010</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>00:00:17.375402</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>15167</td>\n",
       "      <td>0.488397</td>\n",
       "      <td>0.034047</td>\n",
       "      <td>0.110491</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>00:00:17.381827</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>15200</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.015769</td>\n",
       "      <td>0.110654</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>00:00:10.101765</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>15164</td>\n",
       "      <td>0.478148</td>\n",
       "      <td>0.030133</td>\n",
       "      <td>0.112608</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>00:00:17.370976</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>15197</td>\n",
       "      <td>0.450262</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.120001</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>00:00:10.099746</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>15194</td>\n",
       "      <td>0.469392</td>\n",
       "      <td>0.014746</td>\n",
       "      <td>0.120240</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>00:00:10.105772</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>15191</td>\n",
       "      <td>0.399151</td>\n",
       "      <td>0.035757</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.009418</td>\n",
       "      <td>00:00:10.058328</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    kfold_id  cos_sim_mean  cos_sim_std  mse_mean   mse_std   training_time  \\\n",
       "79     15079      0.544678     0.045553  0.087532  0.007631 00:00:17.628990   \n",
       "102    15102      0.530613     0.025990  0.087817  0.009605 00:00:10.221513   \n",
       "153    15153      0.532677     0.054351  0.088313  0.008415 00:00:10.113113   \n",
       "105    15105      0.520059     0.041481  0.088465  0.009716 00:00:10.208124   \n",
       "18     15018      0.541109     0.024352  0.088477  0.008887 00:00:17.837516   \n",
       "103    15103      0.558670     0.034365  0.088525  0.010027 00:00:10.222793   \n",
       "48     15048      0.514831     0.060402  0.088542  0.009569 00:00:09.635081   \n",
       "25     15025      0.529003     0.027270  0.088736  0.007471 00:00:16.947035   \n",
       "21     15021      0.537667     0.038679  0.088956  0.008358 00:00:17.001580   \n",
       "156    15156      0.539332     0.025786  0.089101  0.006976 00:00:10.098078   \n",
       "17     15017      0.528796     0.033333  0.089413  0.009051 00:00:17.837852   \n",
       "64     15064      0.516613     0.033609  0.089424  0.006168 00:00:17.691405   \n",
       "80     15080      0.527055     0.049280  0.089493  0.007397 00:00:17.663815   \n",
       "72     15072      0.534273     0.038361  0.089503  0.011766 00:00:17.698961   \n",
       "51     15051      0.506252     0.038108  0.089608  0.009261 00:00:09.661019   \n",
       "16     15016      0.527126     0.026261  0.089700  0.011520 00:00:17.844593   \n",
       "22     15022      0.516858     0.026130  0.089723  0.007222 00:00:16.991449   \n",
       "133    15133      0.527224     0.029054  0.089731  0.008618 00:00:17.501257   \n",
       "45     15045      0.506338     0.023950  0.089734  0.008460 00:00:09.596128   \n",
       "26     15026      0.543024     0.035127  0.089847  0.006463 00:00:16.946588   \n",
       "130    15130      0.535740     0.024155  0.089853  0.008926 00:00:17.451250   \n",
       "157    15157      0.525200     0.049845  0.089861  0.007085 00:00:10.080445   \n",
       "52     15052      0.525448     0.018024  0.089903  0.007339 00:00:09.613615   \n",
       "126    15126      0.523578     0.027850  0.089975  0.007811 00:00:17.498235   \n",
       "159    15159      0.544650     0.028821  0.090018  0.006619 00:00:10.074166   \n",
       "12     15012      0.508008     0.032458  0.090019  0.008524 00:00:17.782318   \n",
       "49     15049      0.518512     0.026668  0.090085  0.007807 00:00:09.647228   \n",
       "154    15154      0.520121     0.033559  0.090142  0.007088 00:00:10.088770   \n",
       "74     15074      0.523722     0.041189  0.090157  0.008905 00:00:17.683909   \n",
       "20     15020      0.518384     0.026544  0.090209  0.005384 00:00:17.804757   \n",
       "..       ...           ...          ...       ...       ...             ...   \n",
       "110    15110      0.509704     0.036120  0.100852  0.010944 00:00:17.431764   \n",
       "83     15083      0.518713     0.031794  0.101172  0.006131 00:00:10.217685   \n",
       "149    15149      0.535807     0.040474  0.101521  0.009605 00:00:10.063099   \n",
       "202    15202      0.513468     0.047541  0.101633  0.007758 00:00:10.088278   \n",
       "146    15146      0.521908     0.033087  0.101664  0.005828 00:00:10.075236   \n",
       "205    15205      0.520229     0.028218  0.101702  0.005891 00:00:10.078784   \n",
       "179    15179      0.530863     0.038769  0.102615  0.004325 00:00:17.472040   \n",
       "176    15176      0.525600     0.032747  0.102708  0.005855 00:00:17.470919   \n",
       "196    15196      0.520588     0.040100  0.103248  0.004530 00:00:10.061334   \n",
       "163    15163      0.534257     0.040758  0.103253  0.008533 00:00:17.364136   \n",
       "86     15086      0.497603     0.027245  0.103280  0.012440 00:00:10.169328   \n",
       "173    15173      0.532320     0.046054  0.103314  0.008636 00:00:17.450049   \n",
       "215    15215      0.510067     0.043148  0.103626  0.005382 00:00:10.123994   \n",
       "199    15199      0.508229     0.039015  0.103668  0.005589 00:00:10.080520   \n",
       "212    15212      0.523968     0.038953  0.103726  0.005624 00:00:10.102455   \n",
       "193    15193      0.529323     0.039679  0.103733  0.006224 00:00:10.066847   \n",
       "209    15209      0.520366     0.045840  0.104681  0.006295 00:00:10.132968   \n",
       "206    15206      0.490819     0.056066  0.107028  0.003195 00:00:10.092812   \n",
       "140    15140      0.485331     0.031770  0.108366  0.010387 00:00:10.051877   \n",
       "190    15190      0.516911     0.029237  0.108684  0.007108 00:00:10.070584   \n",
       "143    15143      0.465958     0.053087  0.108932  0.003997 00:00:10.084935   \n",
       "137    15137      0.474590     0.069240  0.109028  0.003284 00:00:10.075997   \n",
       "203    15203      0.504652     0.033510  0.109738  0.005735 00:00:10.070713   \n",
       "170    15170      0.483668     0.054459  0.110010  0.011070 00:00:17.375402   \n",
       "167    15167      0.488397     0.034047  0.110491  0.012031 00:00:17.381827   \n",
       "200    15200      0.520202     0.015769  0.110654  0.004921 00:00:10.101765   \n",
       "164    15164      0.478148     0.030133  0.112608  0.008710 00:00:17.370976   \n",
       "197    15197      0.450262     0.063965  0.120001  0.003143 00:00:10.099746   \n",
       "194    15194      0.469392     0.014746  0.120240  0.006365 00:00:10.105772   \n",
       "191    15191      0.399151     0.035757  0.127900  0.009418 00:00:10.058328   \n",
       "\n",
       "    batch_size lstm_out num_dense  dropout  \n",
       "79          32      150       150      0.4  \n",
       "102         64      150       100      0.3  \n",
       "153         64      150        50      0.3  \n",
       "105         64      150       150      0.3  \n",
       "18          32      150        50      0.3  \n",
       "103         64      150       100      0.4  \n",
       "48          64      150       100      0.3  \n",
       "25          32      150       150      0.4  \n",
       "21          32      150       100      0.3  \n",
       "156         64      150       100      0.3  \n",
       "17          32      100       150      0.5  \n",
       "64          32      100        50      0.4  \n",
       "80          32      150       150      0.5  \n",
       "72          32      150        50      0.3  \n",
       "51          64      150       150      0.3  \n",
       "16          32      100       150      0.4  \n",
       "22          32      150       100      0.4  \n",
       "133         32      150       150      0.4  \n",
       "45          64      150        50      0.3  \n",
       "26          32      150       150      0.5  \n",
       "130         32      150       100      0.4  \n",
       "157         64      150       100      0.4  \n",
       "52          64      150       150      0.4  \n",
       "126         32      150        50      0.3  \n",
       "159         64      150       150      0.3  \n",
       "12          32      100       100      0.3  \n",
       "49          64      150       100      0.4  \n",
       "154         64      150        50      0.4  \n",
       "74          32      150        50      0.5  \n",
       "20          32      150        50      0.5  \n",
       "..         ...      ...       ...      ...  \n",
       "110         32       50        50      0.5  \n",
       "83          64       50        50      0.5  \n",
       "149         64      100       100      0.5  \n",
       "202         64      100       100      0.4  \n",
       "146         64      100        50      0.5  \n",
       "205         64      100       150      0.4  \n",
       "179         32      100       150      0.5  \n",
       "176         32      100       100      0.5  \n",
       "196         64       50       150      0.4  \n",
       "163         32       50        50      0.4  \n",
       "86          64       50       100      0.5  \n",
       "173         32      100        50      0.5  \n",
       "215         64      150       150      0.5  \n",
       "199         64      100        50      0.4  \n",
       "212         64      150       100      0.5  \n",
       "193         64       50       100      0.4  \n",
       "209         64      150        50      0.5  \n",
       "206         64      100       150      0.5  \n",
       "140         64       50       100      0.5  \n",
       "190         64       50        50      0.4  \n",
       "143         64       50       150      0.5  \n",
       "137         64       50        50      0.5  \n",
       "203         64      100       100      0.5  \n",
       "170         32       50       150      0.5  \n",
       "167         32       50       100      0.5  \n",
       "200         64      100        50      0.5  \n",
       "164         32       50        50      0.5  \n",
       "197         64       50       150      0.5  \n",
       "194         64       50       100      0.5  \n",
       "191         64       50        50      0.5  \n",
       "\n",
       "[216 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melhores = resumo.sort_values('mse_mean', ascending=True)\n",
    "melhores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HIS50lITwp8Y"
   },
   "outputs": [],
   "source": [
    "# melhores.to_csv(results_lstm + 'resumo/' + 'Resultados10.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOYAEG4dwp8c"
   },
   "outputs": [],
   "source": [
    "# melhores = resumo.sort_values('Score Mean', ascending=False)\n",
    "# melhores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3ubm-0ewp8e"
   },
   "outputs": [],
   "source": [
    "# melhores.to_csv('Resultados3.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ICvVLbG2ET2e"
   },
   "source": [
    "### Results Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVQEWgXy9A9H"
   },
   "outputs": [],
   "source": [
    "# specifying results filepath dest file\n",
    "results_filepath = 'results/lstm/lstm-emb-5-fold-v0.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Mgz7mWaEXOI"
   },
   "outputs": [],
   "source": [
    "# this function goes through all csv results process and group them together\n",
    "def process_raw_data(results_filepath):\n",
    "  all_files = glob.glob(results_lstm + \"*.csv\")\n",
    "#   all_files = glob.glob(results_lstm + \"kfoldid_10000-dim_300-bs_32-nf_384-sf_4-nd_150-dv_3.0.csv\")\n",
    "\n",
    "  li = []\n",
    "  \n",
    "  for filename in all_files:\n",
    "    # 1) we process the filename which has info in itself\n",
    "    params_raw = filename.strip(results_lstm).strip('.csv').split('-')\n",
    "    \n",
    "    params_dict = dict()\n",
    "\n",
    "    for param in params_raw:\n",
    "      key, value = param.split('_')\n",
    "      if key == 'dv':\n",
    "        params_dict[key] = float(value) / 10\n",
    "      else:\n",
    "        params_dict[key] = int(value)\n",
    "      \n",
    "    df_params = pd.DataFrame(params_dict, index=[0])\n",
    "    df_params.columns = ['kfold_id','emb_dim','batch_size','lstm_out','num_dense','dropout']\n",
    "\n",
    "    # 2) we process the content inside the file\n",
    "    df_results = pd.read_csv(filename, index_col=None, header=0, sep=';')\n",
    "    df_results = df_results.groupby(['epoch'], as_index=False).mean().join(df_results.groupby(['epoch']).std(), lsuffix='_mean', rsuffix='_std')\n",
    "    \n",
    "    # 2.1) Converting negative values to positives\n",
    "    df_results['cosine_proximity_mean'] = abs(df_results['cosine_proximity_mean'])\n",
    "    df_results['val_cosine_proximity_mean'] = abs(df_results['val_cosine_proximity_mean'])\n",
    "  \n",
    "    # 2.2) Defining row with best value\n",
    "    df_results['best_val_loss_mean'] = False\n",
    "    df_results['best_val_cosine_proximity_mean'] = False\n",
    "  \n",
    "    best_val_loss_mean = df_results['val_loss_mean'].min()\n",
    "    best_val_cosine_proximity_mean = df_results['val_cosine_proximity_mean'].max()\n",
    "  \n",
    "    df_results.loc[df_results['val_loss_mean'] == best_val_loss_mean, 'best_val_loss_mean'] = True\n",
    "    df_results.loc[df_results['val_cosine_proximity_mean'] == best_val_cosine_proximity_mean, 'best_val_cosine_proximity_mean'] = True\n",
    "\n",
    "    # 3) we join all info together\n",
    "    df_processed = df_params.join(df_results, how='right').ffill()\n",
    "    \n",
    "    # 4) changing some of the collumns to int\n",
    "    df_processed[['kfold_id','emb_dim','batch_size','lstm_out','num_dense']] = df_processed[['kfold_id','emb_dim','batch_size','lstm_out','num_dense']].astype('int64')\n",
    "    \n",
    "    li.append(df_processed)\n",
    "    \n",
    "  df_final = pd.concat(li, axis=0, ignore_index=True)\n",
    "  \n",
    "  df_final.to_csv(results_filepath, index=False, sep=',', encoding='utf-8')\n",
    "  \n",
    "process_raw_data(results_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S6T0i-OHwp8i"
   },
   "source": [
    "## Treinando em todo o conjunto de Treino e avaliando no conjunto de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1557925864049,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "uXYPn4A48h0R",
    "outputId": "7af4b20b-fdf7-46af-8546-cece1c7b519e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kfold_id                               15079\n",
       "emb_dim                                  200\n",
       "batch_size                                32\n",
       "lstm_out                                 150\n",
       "num_dense                                150\n",
       "dropout                                  0.4\n",
       "epoch                                     20\n",
       "cosine_proximity_mean               0.844153\n",
       "loss_mean                          0.0278237\n",
       "time_passed_mean                    0.513146\n",
       "val_cosine_proximity_mean           0.550234\n",
       "val_loss_mean                      0.0869323\n",
       "cosine_proximity_std               0.0131682\n",
       "loss_std                          0.00201697\n",
       "time_passed_std                   0.00165079\n",
       "val_cosine_proximity_std           0.0498491\n",
       "val_loss_std                      0.00854549\n",
       "best_val_loss_mean                      True\n",
       "best_val_cosine_proximity_mean          True\n",
       "Name: 3980, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting best models\n",
    "df_results = pd.read_csv(results_filepath)\n",
    "\n",
    "best_mse_model = df_results[df_results['best_val_loss_mean'] == True].sort_values(by=['val_loss_mean']).iloc[0]\n",
    "best_cos_model = df_results[df_results['best_val_cosine_proximity_mean'] == True].sort_values(by=['val_cosine_proximity_mean'], ascending=[False]).iloc[0]\n",
    "\n",
    "# best_cos_model[['emb_dim', 'lstm_out', 'size_filters', 'num_dense', 'dropout', 'epoch', 'batch_size']]\n",
    "best_mse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fsY1wB0xwp8i"
   },
   "outputs": [],
   "source": [
    "def run_final_test(best_model_config, eval_type):\n",
    "\n",
    "  # fix random seed for reproducibility\n",
    "  seed = 42\n",
    "  np.random.seed(seed)\n",
    "\n",
    "  emb_dim, lstm_out, num_dense, dropout, epoch, batch_size = best_model_config[['emb_dim', 'lstm_out', 'num_dense', 'dropout', 'epoch', 'batch_size']]\n",
    "\n",
    "  embeddings_index_final = load_embedding(emb_dim)\n",
    "\n",
    "  sentences_train_final_pad, sentences_test_final_pad, tok_final = get_tok_sentences(df_train[\"new_title\"], df_test[\"new_title\"])\n",
    "\n",
    "  # X = {'Word_Seq': sentences_train_final_pad, 'Lexical': np.array(df_train['mean_VADER_LMD'].tolist())}\n",
    "#   X = {'Word_Seq': sentences_train_final_pad, 'Lexical': np.array(df_train['mean_VADER'].tolist())}\n",
    "  X = {'Word_Seq': sentences_train_final_pad}\n",
    "  Y = df_train['sentiment']\n",
    "\n",
    "  embedding_matrix = get_embedding_matrix(emb_dim, MAX_VOCAB_SIZE, MAX_SEQUENCE_LENGTH, tok_final, embeddings_index_final)\n",
    "\n",
    "  # lstm = create_model_lstm(256, 256, 2, 2, 150, 0.4, embedding_matrix, True)\n",
    "  # lstm = create_model_lstm(128, 128, 3, 3, 50, 0.5, embedding_matrix, True)\n",
    "#   lstm = create_model_lstm(384, 384, 3, 3, 150, 0.3, embedding_matrix, True)\n",
    "  lstm = create_model_lstm(lstm_out, num_dense, dropout, embedding_matrix, True)\n",
    "  trained = train_model(lstm, X, Y, batch_size, epoch, 'main_data_test', X, Y)\n",
    "#   trained = train_model(lstm, X, Y, 32, 15, 'main_data_test', X, Y)\n",
    "  # lstm = True\n",
    "  # trained =  True\n",
    "  \n",
    "  \n",
    "  # X_test = {'Word_Seq': sentences_seq_test, 'Lexical': np.array(df_test['mean_VADER_LMD'].tolist())}\n",
    "#   X_test = {'Word_Seq': sentences_test_final_pad, 'Lexical': np.array(df_test['mean_VADER'].tolist())}\n",
    "  X_test = {'Word_Seq': sentences_test_final_pad}\n",
    "\n",
    "  if eval_type == 'cos_sim':\n",
    "    y_pred = lstm.predict(X_test)\n",
    "    return cosine_similarity(y_pred.reshape(1, -1), df_test['sentiment'].values.reshape(1, -1))\n",
    "  else:\n",
    "    return lstm.evaluate(X_test, df_test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57044,
     "status": "ok",
     "timestamp": 1557926130552,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "7yTRTULqwp8p",
    "outputId": "a63e9053-dbdf-43c3-b9c1-32f2eac11880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 204us/step\n",
      "MSE with best params: 0.11181635608376893 \n",
      "Cos_sim with best params: [[0.63071026]]\n"
     ]
    }
   ],
   "source": [
    "# best_params_testing = np.array([[300, 150, 150, 15, 32]])\n",
    "# best_mse_model = pd.DataFrame(best_params_testing, columns=['emb_dim', 'lstm_out', 'num_dense', 'epoch', 'batch_size'], dtype=np.int64)\n",
    "\n",
    "# best_mse_model['dropout'] = pd.Series([0.5]).astype('float64')\n",
    "# best_mse_model.iloc[0]['dropout'] = pd.Series([0.5]).astype('float64')\n",
    "# best_mse_model.iloc[0]\n",
    "\n",
    "\n",
    "final_mse_score = run_final_test(best_mse_model, 'mse')\n",
    "final_cos_score = run_final_test(best_cos_model, 'cos_sim')\n",
    "# final_cos_score = run_final_test(best_mse_model, 'cos_sim')\n",
    "\n",
    "print('MSE with best params: {} \\nCos_sim with best params: {}'.format(final_mse_score[0], final_cos_score))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[Oficial] LSTM Emb.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
