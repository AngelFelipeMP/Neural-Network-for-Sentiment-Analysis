{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KWuNFSk8bPHA"
   },
   "source": [
    "# Imports and Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1401,
     "status": "ok",
     "timestamp": 1560537799876,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "qY6m8_IMNfAU",
    "outputId": "c10db1c6-db7c-4852-f3c5-7f209125dfad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/xicocaio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/xicocaio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/xicocaio/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "\n",
    "# scikit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras import layers, regularizers, callbacks, utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk import word_tokenize, tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1683,
     "status": "ok",
     "timestamp": 1560537800177,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "l47G7mqPHlBA",
    "outputId": "041c1a00-5b23-4105-cdd2-3d721b276c4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing if GPU available and if using CUDA\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=True,\n",
    "    min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1672,
     "status": "ok",
     "timestamp": 1560537800186,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "OQbtHrHUbgWQ",
    "outputId": "41578a9f-4434-4031-af44-6a1ae0c42d14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_available_gpus():\n",
    "   local_device_protos = device_lib.list_local_devices()\n",
    "   return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "num_gpu = len(get_available_gpus())\n",
    "num_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lZweddAbcgq"
   },
   "outputs": [],
   "source": [
    "#folder setup\n",
    "\n",
    "results_ann = 'results/ann/raw/emb_lmd/'\n",
    "results_cnn = 'results/cnn/raw/'\n",
    "results_svr = 'results/svr/raw/'\n",
    "results_lstm = 'results/lstm/raw/'\n",
    "\n",
    "resources = '../resources/'\n",
    "\n",
    "if not os.path.isdir(results_ann):\n",
    "    ! mkdir -p $results_ann\n",
    "    ! mkdir -p $results_cnn\n",
    "    ! mkdir -p $results_svr\n",
    "    ! mkdir -p $results_lstm\n",
    "    \n",
    "if not os.path.isdir(resources):\n",
    "    ! mkdir -p $resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OdHkxTFawp7b"
   },
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1733,
     "status": "ok",
     "timestamp": 1560537800268,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "c8ZQ9Xj0wp7c",
    "outputId": "eba82f96-a595-411d-8739-08d2659f4a83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment                                              title\n",
       "0  Morrisons   2      0.430  Morrisons book second consecutive quarter of s...\n",
       "1        IMI   3     -0.344  IMI posts drop in first-quarter organic revenu...\n",
       "2   Glencore   4      0.340  Glencore to refinance its short-term debt earl...\n",
       "3    Ryanair   5      0.259  EasyJet attracts more passengers in June but s...\n",
       "4   Barclays   6     -0.231             Barclays 'bad bank' chief to step down"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading training data\n",
    "df_train = pd.read_json('Headline_Trainingdata.json')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1725,
     "status": "ok",
     "timestamp": 1560537800270,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "vb5O2ouj-BlX",
    "outputId": "220c55eb-27d6-4291-db72-e3cbff0b43bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    131\n",
       "3    129\n",
       "8    128\n",
       "2    127\n",
       "1    127\n",
       "9    126\n",
       "5    126\n",
       "4    125\n",
       "7    123\n",
       "Name: quantile, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bins = 9\n",
    "# bins = df_train['sentiment'].quantile([0.1*q for q in range(0,n_bins)])\n",
    "# df_train['quantile'] = pd.cut(df_train['sentiment'], bins=bins, labels=range(1,n_bins+1))\n",
    "# df_train['quantile'] = pd.cut(df_train['sentiment'], bins=bins, include_lowest=True)\n",
    "\n",
    "df_train['quantile'] = pd.qcut(df_train['sentiment'], q=n_bins, labels=range(1,n_bins+1))\n",
    "df_train['quantile'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1719,
     "status": "ok",
     "timestamp": 1560537800272,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "XKTCXsWaD9RW",
    "outputId": "ea9b23b4-4030-4797-efb4-feba39a8c1fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.03104903677758319; std: 0.39360209451145045\n"
     ]
    }
   ],
   "source": [
    "print('mean: {}; std: {}'.format(np.mean(df_train['sentiment']), np.std(df_train['sentiment'])))\n",
    "# df_train['sentiment'].min()\n",
    "# df_train['sentiment'].idxmin()\n",
    "# df_train.iloc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1741,
     "status": "ok",
     "timestamp": 1560537800309,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "w619GiP9clF9",
    "outputId": "e5c43d71-e553-47c0-fd1b-368453b8f631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train CV: mean: 0.03412017167381975; std: 0.38683983574619385\n",
      "df_train CV: mean: 0.028765217391304363; std: 0.4037852384500579\n",
      "df_train CV: mean: 0.029614035087719294; std: 0.3849741278336272\n",
      "df_train CV: mean: 0.02813274336283186; std: 0.4028562295301328\n",
      "df_train CV: mean: 0.03458666666666667; std: 0.3891696491534537\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "for fit_index, cv_index in skf.split(df_train, df_train['quantile']):\n",
    "#   print(\"TRAIN:\", train_index.size, \"TEST:\", test_index.size)\n",
    "#   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#   print(\"TRAIN:\", df_train.iloc[train_index], \"TEST:\", df_train.iloc[test_index])\n",
    "#   print('TRAIN: mean: {}; std: {}'.format(np.mean(df_train['sentiment'].iloc[train_index]), np.std(df_train['sentiment'].iloc[train_index])))\n",
    "  print('df_train CV: mean: {}; std: {}'.format(np.mean(df_train['sentiment'].iloc[cv_index]), np.std(df_train['sentiment'].iloc[cv_index])))\n",
    "#   df_train['sentiment'].iloc[test_index]\n",
    "#   df_train.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4439,
     "status": "ok",
     "timestamp": 1560537803019,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "sq_o9rsM08Mg",
    "outputId": "6c211b4b-fc30-4944-e923-1e93ed9ff0ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashtead</td>\n",
       "      <td>1144</td>\n",
       "      <td>0.588</td>\n",
       "      <td>Ashtead to buy back shares, full-year profit b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shell</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.276</td>\n",
       "      <td>EU regulators clear Shell's takeover of BG Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prudential</td>\n",
       "      <td>1146</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>UK's FTSE has worst day so far in 2015 as BG a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GlaxoSmithKline</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.390</td>\n",
       "      <td>GlaxoSmithKline acquires HIV assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>1148</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>Barclays faces another heavy forex fine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company    id  sentiment  \\\n",
       "0          Ashtead  1144      0.588   \n",
       "1            Shell  1145      0.276   \n",
       "2       Prudential  1146     -0.651   \n",
       "3  GlaxoSmithKline  1147      0.390   \n",
       "4         Barclays  1148     -0.834   \n",
       "\n",
       "                                               title  \n",
       "0  Ashtead to buy back shares, full-year profit b...  \n",
       "1   EU regulators clear Shell's takeover of BG Group  \n",
       "2  UK's FTSE has worst day so far in 2015 as BG a...  \n",
       "3                GlaxoSmithKline acquires HIV assets  \n",
       "4            Barclays faces another heavy forex fine  "
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading testing data, and removing normalizing collumns\n",
    "df_test = pd.read_json(\"Headlines_Testdata_withscores.json\")\n",
    "\n",
    "df_test.drop('UniqueID', axis=1, inplace=True)\n",
    "df_test.rename(columns={'sentiment score': 'sentiment'}, inplace=True)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4462,
     "status": "ok",
     "timestamp": 1560537803056,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "K9ufADTxblRd",
    "outputId": "fdb2f019-9d5f-4cb0-96a6-66f317c3bdac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test: mean: 0.014820773930753563; std: 0.4137897136769093\n"
     ]
    }
   ],
   "source": [
    "print('df_test: mean: {}; std: {}'.format(np.mean(df_test['sentiment']), np.std(df_test['sentiment'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-_1M_B-wp7k"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4469,
     "status": "ok",
     "timestamp": 1560537803071,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "2dpikgLywp7k",
    "outputId": "db573583-b977-4ad0-85b3-a13ff7a87a47"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashtead</td>\n",
       "      <td>1144</td>\n",
       "      <td>0.588</td>\n",
       "      <td>Ashtead to buy back shares, full-year profit b...</td>\n",
       "      <td>[company, buy, back, shares, ,, full-year, pro...</td>\n",
       "      <td>company buy back shares , full-year profit bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shell</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.276</td>\n",
       "      <td>EU regulators clear Shell's takeover of BG Group</td>\n",
       "      <td>[eu, regulators, clear, company, s, takeover, ...</td>\n",
       "      <td>eu regulators clear company s takeover bg group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prudential</td>\n",
       "      <td>1146</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>UK's FTSE has worst day so far in 2015 as BG a...</td>\n",
       "      <td>[uk, s, ftse, worst, day, far, 2015, bg, compa...</td>\n",
       "      <td>uk s ftse worst day far 2015 bg company fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GlaxoSmithKline</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.390</td>\n",
       "      <td>GlaxoSmithKline acquires HIV assets</td>\n",
       "      <td>[company, acquires, hiv, assets]</td>\n",
       "      <td>company acquires hiv assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>1148</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>Barclays faces another heavy forex fine</td>\n",
       "      <td>[company, faces, another, heavy, forex, fine]</td>\n",
       "      <td>company faces another heavy forex fine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company    id  sentiment  \\\n",
       "0          Ashtead  1144      0.588   \n",
       "1            Shell  1145      0.276   \n",
       "2       Prudential  1146     -0.651   \n",
       "3  GlaxoSmithKline  1147      0.390   \n",
       "4         Barclays  1148     -0.834   \n",
       "\n",
       "                                               title  \\\n",
       "0  Ashtead to buy back shares, full-year profit b...   \n",
       "1   EU regulators clear Shell's takeover of BG Group   \n",
       "2  UK's FTSE has worst day so far in 2015 as BG a...   \n",
       "3                GlaxoSmithKline acquires HIV assets   \n",
       "4            Barclays faces another heavy forex fine   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, buy, back, shares, ,, full-year, pro...   \n",
       "1  [eu, regulators, clear, company, s, takeover, ...   \n",
       "2  [uk, s, ftse, worst, day, far, 2015, bg, compa...   \n",
       "3                   [company, acquires, hiv, assets]   \n",
       "4      [company, faces, another, heavy, forex, fine]   \n",
       "\n",
       "                                           new_title  \n",
       "0  company buy back shares , full-year profit bea...  \n",
       "1    eu regulators clear company s takeover bg group  \n",
       "2       uk s ftse worst day far 2015 bg company fall  \n",
       "3                        company acquires hiv assets  \n",
       "4             company faces another heavy forex fine  "
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop words removal\n",
    "def run_preprocessing(df):\n",
    "  # replace company name by placeholder and remove double quotes that is not preprocessed well by word_tokenize\n",
    "  # also lower casing words for compatilbility with glove, which only has lower casing words\n",
    "  # be aware that some companies namies are not identical\n",
    "  # example: id = 10 Centrica PLC appears as just Centrica on title\n",
    "  title_company_replaced = df['title'].replace(df['company'], 'company', regex = True).replace('\"', '', regex = True).str.lower()\n",
    "#   title_company_replaced = df['title'].replace(df['company'], 'company', regex = True)\n",
    "\n",
    "  # tokenize headlines\n",
    "  tokenized_title = title_company_replaced.apply(word_tokenize)\n",
    "  \n",
    "  # removing stopwords and single quotes\n",
    "  # stop_words: {'does', 'under', 'own', 'at', 'of', 'don', 'hers', 'further', 're', \"you'll\", 'into', 'she', 'such', 'shan', 'you', \"haven't\", 'when', 'me', 'a', 'all', \"shan't\", 'mustn', \"should've\", \"didn't\", \"aren't\", \"weren't\", 'after', 'ain', 's', \"that'll\", 'just', 'am', 'the', 'too', 'before', \"wasn't\", 'what', 'haven', 'm', 'up', 'against', 'how', 'who', 'yourselves', 'nor', 'than', 've', 'between', 'being', 'are', 'and', \"don't\", 'themselves', 'were', 'itself', 'd', 'doesn', 'there', \"wouldn't\", 'both', 'we', 'why', 'needn', 'those', 'out', 'mightn', 'which', 'it', 'here', 'theirs', 'any', 'my', 'that', \"doesn't\", 'should', 'him', 'weren', 'from', 'no', 'wouldn', 'once', 'with', 'will', 'have', 'is', 'most', 'hasn', 'll', 'yours', 'himself', 'was', 'this', 'or', 'over', 'again', 'y', 'do', 'through', \"hasn't\", \"she's\", 'same', 'down', 'has', 'so', 'can', 'shouldn', \"hadn't\", 'while', 'for', 'but', 'whom', \"mustn't\", 'our', 'if', \"couldn't\", \"you've\", 'be', 'been', 'myself', 'did', 'few', 'hadn', 'other', \"you'd\", 'not', 'ma', 'their', 'off', \"shouldn't\", 'had', 'these', 'his', 'yourself', 'very', \"isn't\", 'aren', 'o', 'won', 'because', 'isn', 'wasn', 'herself', 'by', 'where', 'your', 'i', \"it's\", 'above', 'until', \"you're\", 'they', 'only', 'ours', 'below', \"mightn't\", 'some', \"won't\", 'about', 'couldn', 'ourselves', 'them', 'he', 'during', 'more', 't', 'as', 'now', 'didn', \"needn't\", 'an', 'to', 'each', 'its', 'her', 'doing', 'then', 'on', 'in', 'having'}  \n",
    "  # some of these word should probably not be removed like the word: won't\n",
    "  # also maybe consider using TweetTokenizer, that mayy deal better with contactions like: Glencore's \n",
    "  stopwords_english = stopwords.words('english')\n",
    "  stopwords_english.append('\\'')\n",
    "\n",
    "  df['clean_tokens'] = tokenized_title.apply(lambda x: [item.strip('\\'') for item in x if item not in stopwords_english])\n",
    "#   df['clean_tokens'] = tokenized_title.apply(lambda x: [item for item in x if item not in stopwords_english])\n",
    "  df['new_title'] =  df['clean_tokens'].apply(lambda x: ' '.join(x))\n",
    "  \n",
    "run_preprocessing(df_train)\n",
    "run_preprocessing(df_test)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NmyHJxUwp7x"
   },
   "source": [
    "## Tokenizing and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4463,
     "status": "ok",
     "timestamp": 1560537803073,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "iVc6F4_vj7Gx",
    "outputId": "e6db4057-0522-4ab6-aea2-37104a3092e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 16 | min: 3 | mean: 8.249562171628721 | std: 2.0743354560287957\n"
     ]
    }
   ],
   "source": [
    "clean_tokens_length = df_train[\"clean_tokens\"].apply(lambda x: len(x))\n",
    "\n",
    "max_sentence_length_train = np.max(clean_tokens_length)\n",
    "min_sentence_length_train = np.min(clean_tokens_length)\n",
    "mean_sentence_length_train = np.mean(clean_tokens_length)\n",
    "std_sentence_length_train = np.std(clean_tokens_length)\n",
    "\n",
    "\n",
    "print(\"max: {} | min: {} | mean: {} | std: {}\".format(max_sentence_length_train, min_sentence_length_train, mean_sentence_length_train, std_sentence_length_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9gLNeUqVnkmc"
   },
   "outputs": [],
   "source": [
    "# giving the max_sentence_length_train, we will use a number a little above\n",
    "# TODO: evaluate if this is too much of a leakage, because each fold may yield different sequence MAX\n",
    "MAX_SEQUENCE_LENGTH = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJXCYNGwowZS"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 10000\n",
    "\n",
    "# receives healines and returns tokenizer with vocab mappings and padded sentences read to use\n",
    "def get_tok_sentences(doc_fit, doc_cv):\n",
    "  tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='', lower=False)\n",
    "  tokenizer.fit_on_texts(doc_fit)\n",
    "\n",
    "  fit_sentences = tokenizer.texts_to_sequences(doc_fit)\n",
    "  cv_sentences = tokenizer.texts_to_sequences(doc_cv)\n",
    "  \n",
    "  fit_sentences_pad = pad_sequences(fit_sentences, padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "  cv_sentences_pad = pad_sequences(cv_sentences, padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "  return fit_sentences_pad, cv_sentences_pad, tokenizer\n",
    "\n",
    "# sentences_seq_train, vocab_size, tokenizer = prepare_tokenizer(df_train)\n",
    "# tokenizer.word_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83-K4yu5r9Gv"
   },
   "source": [
    "## Sentiment Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jocsyJfGwp7n"
   },
   "source": [
    "### Loughran McDonald Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXsRVyu6XLy_"
   },
   "outputs": [],
   "source": [
    "LMDDictionary = {}\n",
    "vetor = []\n",
    "\n",
    "# TODO: this can be done directly by converting to pandas and than calling the to_dict function\n",
    "with open('LoughranMcDonald_MasterDictionary_2016.csv', 'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        palavra = line.split(',')[0].lower()\n",
    "        vetor_char = line.split(',')[7:14]\n",
    "        vetor = [1 if x!='0' else 0 for x in vetor_char]\n",
    "\n",
    "        LMDDictionary[palavra] = np.asarray(vetor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4556,
     "status": "ok",
     "timestamp": 1560537803179,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "Ju9zpKQAwp7o",
    "outputId": "cd2d6738-c627-4ccb-debc-84a369aaaa15"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>quantile</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "      <th>LMDVector</th>\n",
       "      <th>mean_LMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "      <td>8</td>\n",
       "      <td>[company, book, second, consecutive, quarter, ...</td>\n",
       "      <td>company book second consecutive quarter sales ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[company, posts, drop, first-quarter, organic,...</td>\n",
       "      <td>company posts drop first-quarter organic reven...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[company, refinance, short-term, debt, early, ...</td>\n",
       "      <td>company refinance short-term debt early , shar...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "      <td>6</td>\n",
       "      <td>[easyjet, attracts, passengers, june, still, l...</td>\n",
       "      <td>easyjet attracts passengers june still lags co...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "      <td>3</td>\n",
       "      <td>[company, bad, bank, chief, step]</td>\n",
       "      <td>company bad bank chief step</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment  \\\n",
       "0  Morrisons   2      0.430   \n",
       "1        IMI   3     -0.344   \n",
       "2   Glencore   4      0.340   \n",
       "3    Ryanair   5      0.259   \n",
       "4   Barclays   6     -0.231   \n",
       "\n",
       "                                               title quantile  \\\n",
       "0  Morrisons book second consecutive quarter of s...        8   \n",
       "1  IMI posts drop in first-quarter organic revenu...        2   \n",
       "2  Glencore to refinance its short-term debt earl...        7   \n",
       "3  EasyJet attracts more passengers in June but s...        6   \n",
       "4             Barclays 'bad bank' chief to step down        3   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, book, second, consecutive, quarter, ...   \n",
       "1  [company, posts, drop, first-quarter, organic,...   \n",
       "2  [company, refinance, short-term, debt, early, ...   \n",
       "3  [easyjet, attracts, passengers, june, still, l...   \n",
       "4                  [company, bad, bank, chief, step]   \n",
       "\n",
       "                                           new_title  \\\n",
       "0  company book second consecutive quarter sales ...   \n",
       "1  company posts drop first-quarter organic reven...   \n",
       "2  company refinance short-term debt early , shar...   \n",
       "3  easyjet attracts passengers june still lags co...   \n",
       "4                        company bad bank chief step   \n",
       "\n",
       "                                           LMDVector  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...   \n",
       "\n",
       "                                            mean_LMD  \n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1                [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]  \n",
       "2                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4                [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = [0, 0, 0, 0, 0, 0, 0]\n",
    "nan_list = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "def run_LMD(df):\n",
    "  df['LMDVector'] = df['clean_tokens'].apply(lambda x: [LMDDictionary.get(item, zeros) for item in x])\n",
    "  df['mean_LMD'] = df['LMDVector'].apply(lambda x: np.mean(x, axis=0, dtype=np.float64))\n",
    "  \n",
    "#   df['LMDVector'] = df['new_title'].apply(lambda x: [LMDDictionary.get(item, nan_list) for item in x]) #Taynan\n",
    "#   df['mean_LMD'] = df['LMDVector'].apply(lambda x: np.nanmean(x, axis=0, dtype=np.float64)) #Taynan\n",
    "  \n",
    "run_LMD(df_train)\n",
    "run_LMD(df_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbzybLUewp70"
   },
   "source": [
    "### VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4551,
     "status": "ok",
     "timestamp": 1560537803181,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "Rtd3NaKuznfJ",
    "outputId": "2f63c683-0d99-4e70-a245-d5ceae98e84b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>quantile</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "      <th>LMDVector</th>\n",
       "      <th>mean_LMD</th>\n",
       "      <th>neu_VADER</th>\n",
       "      <th>pos_VADER</th>\n",
       "      <th>neg_VADER</th>\n",
       "      <th>compound_VADER</th>\n",
       "      <th>mean_VADER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "      <td>8</td>\n",
       "      <td>[company, book, second, consecutive, quarter, ...</td>\n",
       "      <td>company book second consecutive quarter sales ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]</td>\n",
       "      <td>[0.0, 0.698, 0.302, 0.3818]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[company, posts, drop, first-quarter, organic,...</td>\n",
       "      <td>company posts drop first-quarter organic reven...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...</td>\n",
       "      <td>[0.333, 0.667, 0.0, -0.3612]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[company, refinance, short-term, debt, early, ...</td>\n",
       "      <td>company refinance short-term debt early , shar...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]</td>\n",
       "      <td>[0.258, 0.515, 0.227, -0.0772]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "      <td>6</td>\n",
       "      <td>[easyjet, attracts, passengers, june, still, l...</td>\n",
       "      <td>easyjet attracts passengers june still lags co...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]</td>\n",
       "      <td>[0.245, 0.49, 0.265, 0.0516]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "      <td>3</td>\n",
       "      <td>[company, bad, bank, chief, step]</td>\n",
       "      <td>company bad bank chief step</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, -0.5423, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.467, 0.533, 0.0, -0.5423]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment  \\\n",
       "0  Morrisons   2      0.430   \n",
       "1        IMI   3     -0.344   \n",
       "2   Glencore   4      0.340   \n",
       "3    Ryanair   5      0.259   \n",
       "4   Barclays   6     -0.231   \n",
       "\n",
       "                                               title quantile  \\\n",
       "0  Morrisons book second consecutive quarter of s...        8   \n",
       "1  IMI posts drop in first-quarter organic revenu...        2   \n",
       "2  Glencore to refinance its short-term debt earl...        7   \n",
       "3  EasyJet attracts more passengers in June but s...        6   \n",
       "4             Barclays 'bad bank' chief to step down        3   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, book, second, consecutive, quarter, ...   \n",
       "1  [company, posts, drop, first-quarter, organic,...   \n",
       "2  [company, refinance, short-term, debt, early, ...   \n",
       "3  [easyjet, attracts, passengers, june, still, l...   \n",
       "4                  [company, bad, bank, chief, step]   \n",
       "\n",
       "                                           new_title  \\\n",
       "0  company book second consecutive quarter sales ...   \n",
       "1  company posts drop first-quarter organic reven...   \n",
       "2  company refinance short-term debt early , shar...   \n",
       "3  easyjet attracts passengers june still lags co...   \n",
       "4                        company bad bank chief step   \n",
       "\n",
       "                                           LMDVector  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...   \n",
       "\n",
       "                                            mean_LMD  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1                [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]   \n",
       "2                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4                [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neu_VADER  \\\n",
       "0                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]   \n",
       "1  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...   \n",
       "2           [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]   \n",
       "3                [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]   \n",
       "4                          [1.0, 0.0, 1.0, 1.0, 1.0]   \n",
       "\n",
       "                                           pos_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "3                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "4                          [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neg_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "4                          [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                      compound_VADER  \\\n",
       "0             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]   \n",
       "1  [0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...   \n",
       "2     [0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]   \n",
       "3         [0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]   \n",
       "4                      [0.0, -0.5423, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                       mean_VADER  \n",
       "0     [0.0, 0.698, 0.302, 0.3818]  \n",
       "1    [0.333, 0.667, 0.0, -0.3612]  \n",
       "2  [0.258, 0.515, 0.227, -0.0772]  \n",
       "3    [0.245, 0.49, 0.265, 0.0516]  \n",
       "4    [0.467, 0.533, 0.0, -0.5423]  "
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_sid(df):\n",
    "  sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "  df['neu_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['neu'] for item in x])\n",
    "  df['pos_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['pos'] for item in x])\n",
    "  df['neg_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['neg'] for item in x])\n",
    "  df['compound_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['compound'] for item in x])\n",
    "  df['mean_VADER'] = df['new_title'].apply(lambda x: [v for k,v in sid.polarity_scores(x).items()])\n",
    "  \n",
    "#   df['neu_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['neu'] for item in x]))\n",
    "#   df['pos_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['pos'] for item in x]))\n",
    "#   df['neg_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['neg'] for item in x]))\n",
    "#   df['compound_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['compound'] for item in x]))\n",
    "#   df['mean_VADER'] = df[['neu_VADER', 'pos_VADER', 'neg_VADER', 'compound_VADER']].values.tolist()\n",
    "  \n",
    "                                 \n",
    "run_sid(df_train)\n",
    "run_sid(df_test)\n",
    "\n",
    "df_train.head()\n",
    "# np.mean(df_train['neu_VADER'])\n",
    "# [np.mean(item) for item in df_train['neu_VADER']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KwglgETsGV3"
   },
   "source": [
    "### Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4543,
     "status": "ok",
     "timestamp": 1560537803183,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "Cd30mr4hsLGe",
    "outputId": "42f955b7-7836-49ea-8947-2ab57a149ff8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>quantile</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "      <th>LMDVector</th>\n",
       "      <th>mean_LMD</th>\n",
       "      <th>neu_VADER</th>\n",
       "      <th>pos_VADER</th>\n",
       "      <th>neg_VADER</th>\n",
       "      <th>compound_VADER</th>\n",
       "      <th>mean_VADER</th>\n",
       "      <th>mean_VADER_LMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "      <td>8</td>\n",
       "      <td>[company, book, second, consecutive, quarter, ...</td>\n",
       "      <td>company book second consecutive quarter sales ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]</td>\n",
       "      <td>[0.0, 0.698, 0.302, 0.3818]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[company, posts, drop, first-quarter, organic,...</td>\n",
       "      <td>company posts drop first-quarter organic reven...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...</td>\n",
       "      <td>[0.333, 0.667, 0.0, -0.3612]</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.333, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[company, refinance, short-term, debt, early, ...</td>\n",
       "      <td>company refinance short-term debt early , shar...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]</td>\n",
       "      <td>[0.258, 0.515, 0.227, -0.0772]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.258, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "      <td>6</td>\n",
       "      <td>[easyjet, attracts, passengers, june, still, l...</td>\n",
       "      <td>easyjet attracts passengers june still lags co...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]</td>\n",
       "      <td>[0.245, 0.49, 0.265, 0.0516]</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "      <td>3</td>\n",
       "      <td>[company, bad, bank, chief, step]</td>\n",
       "      <td>company bad bank chief step</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, -0.5423, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.467, 0.533, 0.0, -0.5423]</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.467, 0.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment  \\\n",
       "0  Morrisons   2      0.430   \n",
       "1        IMI   3     -0.344   \n",
       "2   Glencore   4      0.340   \n",
       "3    Ryanair   5      0.259   \n",
       "4   Barclays   6     -0.231   \n",
       "\n",
       "                                               title quantile  \\\n",
       "0  Morrisons book second consecutive quarter of s...        8   \n",
       "1  IMI posts drop in first-quarter organic revenu...        2   \n",
       "2  Glencore to refinance its short-term debt earl...        7   \n",
       "3  EasyJet attracts more passengers in June but s...        6   \n",
       "4             Barclays 'bad bank' chief to step down        3   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, book, second, consecutive, quarter, ...   \n",
       "1  [company, posts, drop, first-quarter, organic,...   \n",
       "2  [company, refinance, short-term, debt, early, ...   \n",
       "3  [easyjet, attracts, passengers, june, still, l...   \n",
       "4                  [company, bad, bank, chief, step]   \n",
       "\n",
       "                                           new_title  \\\n",
       "0  company book second consecutive quarter sales ...   \n",
       "1  company posts drop first-quarter organic reven...   \n",
       "2  company refinance short-term debt early , shar...   \n",
       "3  easyjet attracts passengers june still lags co...   \n",
       "4                        company bad bank chief step   \n",
       "\n",
       "                                           LMDVector  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...   \n",
       "\n",
       "                                            mean_LMD  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1                [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]   \n",
       "2                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4                [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neu_VADER  \\\n",
       "0                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]   \n",
       "1  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...   \n",
       "2           [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]   \n",
       "3                [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]   \n",
       "4                          [1.0, 0.0, 1.0, 1.0, 1.0]   \n",
       "\n",
       "                                           pos_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "3                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "4                          [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neg_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "4                          [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                      compound_VADER  \\\n",
       "0             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]   \n",
       "1  [0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...   \n",
       "2     [0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]   \n",
       "3         [0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]   \n",
       "4                      [0.0, -0.5423, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                       mean_VADER  \\\n",
       "0     [0.0, 0.698, 0.302, 0.3818]   \n",
       "1    [0.333, 0.667, 0.0, -0.3612]   \n",
       "2  [0.258, 0.515, 0.227, -0.0772]   \n",
       "3    [0.245, 0.49, 0.265, 0.0516]   \n",
       "4    [0.467, 0.533, 0.0, -0.5423]   \n",
       "\n",
       "                                      mean_VADER_LMD  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.698...  \n",
       "1  [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.333, 0.6...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.258, 0.5...  \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4  [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.467, 0.5...  "
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_vader_LMD(df):\n",
    "  df['mean_VADER_LMD'] = [np.hstack([x,y]) for x, y in zip(df['mean_LMD'], df['mean_VADER'])]\n",
    "\n",
    "join_vader_LMD(df_train)\n",
    "join_vader_LMD(df_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKNfykDiwp76"
   },
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsTrK_2z9b-i"
   },
   "outputs": [],
   "source": [
    "# EMBEDDING_DIM = 300\n",
    "\n",
    "# TODO: use: vocab_size = max(MAX_VOCAB_SIZE, len(word_index)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCkEUlw1DL2v"
   },
   "outputs": [],
   "source": [
    "def load_embedding(emb_dim):\n",
    "  \n",
    "  # load the whole embedding into memory\n",
    "  embeddings_index = dict()\n",
    "  \n",
    "  if not os.path.exists(resources + 'glove.6B.zip'):\n",
    "    ! wget http://nlp.stanford.edu/data/glove.6B.zip -P /resources/\n",
    "  if not os.path.exists(resources + 'glove.6B.' + str(emb_dim) + 'd.txt'):\n",
    "    ! unzip resources/glove.6B.zip -d resources\n",
    "  \n",
    "  f = open(resources + 'glove.6B.' + str(emb_dim) + 'd.txt', 'r', encoding=\"utf8\")\n",
    "  for line in f:\n",
    "      values = line.split()\n",
    "      word = values[0]\n",
    "      coefs = np.asarray(values[1:], dtype='float32')\n",
    "      embeddings_index[word] = coefs\n",
    "  f.close()\n",
    "  \n",
    "  return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tcmZ6KVgwp78"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "def get_embedding_matrix(emb_dim, vocab_size, input_length, tokenizer, embeddings_index):\n",
    "  vocab_size = min(MAX_VOCAB_SIZE, len(tokenizer.word_index)) + 1 # Adding 1 because of reserved 0 index\n",
    "  embedding_matrix = np.zeros((vocab_size, emb_dim))\n",
    "  for word, i in tokenizer.word_index.items():\n",
    "      embedding_vector = embeddings_index.get(word)\n",
    "      if (embedding_vector is not None):\n",
    "          embedding_matrix[i] = embedding_vector\n",
    "\n",
    "  return embedding_matrix\n",
    "\n",
    "\n",
    "# banna, maca, tokenizer = get_tok_sentences(df_train['new_title'], df_test['new_title'])\n",
    "# get_embedding_matrix(300, MAX_VOCAB_SIZE, True, MAX_SEQUENCE_LENGTH, tokenizer).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buH-SkpPpdPm"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DAqcBAvnwp8A"
   },
   "source": [
    "## ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRqZgB3-hY7t"
   },
   "outputs": [],
   "source": [
    "def cos_sim(y_true, y_pred):\n",
    "#   x = K.l2_normalize(y_true, axis=-1)\n",
    "#   y = K.l2_normalize(y_pred, axis=-1)\n",
    "#   return K.mean(x * y, axis=-1, keepdims=True)\n",
    "  return cosine_similarity(y_true, y_pred)\n",
    "\n",
    "metrics = ['cosine_proximity']\n",
    "# dropout = 0.3\n",
    "# loss = 'mse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2B9necCNwp8D"
   },
   "outputs": [],
   "source": [
    "# callback for time: https://stackoverflow.com/questions/43178668/record-the-computation-time-for-each-epoch-in-keras-during-model-fit\n",
    "# or maybe just use keras LambdaCallback\n",
    "\n",
    "class TimeHistory(callbacks.Callback):  \n",
    "  def on_epoch_begin(self, epoch, logs={}):\n",
    "    self.epoch_time_start = time.time()\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    logs['time_passed'] = time.time() - self.epoch_time_start\n",
    "\n",
    "def callback_functions(nome_log):\n",
    "  time_callback = TimeHistory()\n",
    "  csv_logger = callbacks.CSVLogger(results_ann + nome_log + '.csv', separator=';', append=True)\n",
    "#     tensorboard_callback = callbacks.TensorBoard(nome_log, histogram_freq=1)\n",
    "#     best_model = callbacks.ModelCheckpoint(results_ann + nome_log + '.h5', monitor='val_loss', verbose=0, save_best_only=True, mode='auto')\n",
    "\n",
    "  return [time_callback, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeUV9qR9wp8H"
   },
   "outputs": [],
   "source": [
    "def create_ANN_model_hidden_1(number_dense, dropout_value, embedding_matrix, emb_layer_trainable):\n",
    "    \n",
    "    # first input model\n",
    "    visible1 = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), name='Word_Seq')\n",
    "    embedding = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable)(visible1)\n",
    "#     conv1 = layers.Conv1D(num_filters_1, size_filters_1, padding='same', activation='relu')(embedding)\n",
    "#     conv2 = layers.Conv1D(num_filters_2, size_filters_2, padding='same', activation='relu')(conv1)\n",
    "    pool1 = layers.GlobalMaxPooling1D()(embedding)\n",
    "    flat1 = pool1\n",
    "    \n",
    "    # second input model\n",
    "#     visible2 = layers.Input(shape=(np.array(df_train['mean_VADER_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    visible2 = layers.Input(shape=(np.array(df_train['mean_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    flat2 = visible2\n",
    "\n",
    "    # merge input models\n",
    "    merge = layers.concatenate([flat1, flat2])\n",
    "#     merge = flat1\n",
    "    \n",
    "    # interpretation model\n",
    "    dropout1 = layers.Dropout(dropout_value)(merge)    \n",
    "    hidden1 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n",
    "    dropout2 = layers.Dropout(dropout_value)(hidden1)\n",
    "    output = layers.Dense(1, activation='tanh')(dropout2)\n",
    "    model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "\n",
    "    return model\n",
    "  \n",
    "def create_ANN_model_hidden_2(number_dense, dropout_value, embedding_matrix, emb_layer_trainable):\n",
    "    \n",
    "    # first input model\n",
    "    visible1 = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), name='Word_Seq')\n",
    "    embedding = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable)(visible1)\n",
    "#     conv1 = layers.Conv1D(num_filters_1, size_filters_1, padding='same', activation='relu')(embedding)\n",
    "#     conv2 = layers.Conv1D(num_filters_2, size_filters_2, padding='same', activation='relu')(conv1)\n",
    "    pool1 = layers.GlobalMaxPooling1D()(embedding)\n",
    "    flat1 = pool1\n",
    "    \n",
    "    # second input model\n",
    "#     visible2 = layers.Input(shape=(np.array(df_train['mean_VADER_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    visible2 = layers.Input(shape=(np.array(df_train['mean_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    flat2 = visible2\n",
    "\n",
    "    # merge input models\n",
    "    merge = layers.concatenate([flat1, flat2])\n",
    "#     merge = flat1\n",
    "    \n",
    "    # interpretation model\n",
    "    dropout1 = layers.Dropout(dropout_value)(merge)  \n",
    "    hidden1 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n",
    "    dropout2 = layers.Dropout(dropout_value)(hidden1)\n",
    "    hidden2 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout2)\n",
    "    dropout3 = layers.Dropout(dropout_value)(hidden2)\n",
    "    output = layers.Dense(1, activation='tanh')(dropout3)\n",
    "    model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "\n",
    "    return model\n",
    "  \n",
    "def create_ANN_model_hidden_3(number_dense, dropout_value, embedding_matrix, emb_layer_trainable):\n",
    "    \n",
    "    # first input model\n",
    "    visible1 = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), name='Word_Seq')\n",
    "    embedding = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable)(visible1)\n",
    "#     conv1 = layers.Conv1D(num_filters_1, size_filters_1, padding='same', activation='relu')(embedding)\n",
    "#     conv2 = layers.Conv1D(num_filters_2, size_filters_2, padding='same', activation='relu')(conv1)\n",
    "    pool1 = layers.GlobalMaxPooling1D()(embedding)\n",
    "    flat1 = pool1\n",
    "    \n",
    "    # second input model\n",
    "#     visible2 = layers.Input(shape=(np.array(df_train['mean_VADER_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    visible2 = layers.Input(shape=(np.array(df_train['mean_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    flat2 = visible2\n",
    "\n",
    "    # merge input models\n",
    "    merge = layers.concatenate([flat1, flat2])\n",
    "#     merge = flat1\n",
    "    \n",
    "    # interpretation model\n",
    "    dropout1 = layers.Dropout(dropout_value)(merge)  \n",
    "    hidden1 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n",
    "    dropout2 = layers.Dropout(dropout_value)(hidden1)\n",
    "    hidden2 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout2)\n",
    "    dropout3 = layers.Dropout(dropout_value)(hidden2)\n",
    "    hidden3 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout3)\n",
    "    dropout4 = layers.Dropout(dropout_value)(hidden3)\n",
    "    output = layers.Dense(1, activation='tanh')(dropout4)\n",
    "    model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "\n",
    "    return model\n",
    "  \n",
    "def create_ANN_model_hidden_5(number_dense, dropout_value, embedding_matrix, emb_layer_trainable):\n",
    "    \n",
    "    # first input model\n",
    "    visible1 = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), name='Word_Seq')\n",
    "    embedding = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable)(visible1)\n",
    "#     conv1 = layers.Conv1D(num_filters_1, size_filters_1, padding='same', activation='relu')(embedding)\n",
    "#     conv2 = layers.Conv1D(num_filters_2, size_filters_2, padding='same', activation='relu')(conv1)\n",
    "    pool1 = layers.GlobalMaxPooling1D()(embedding)\n",
    "    flat1 = pool1\n",
    "    \n",
    "    # second input model\n",
    "#     visible2 = layers.Input(shape=(np.array(df_train['mean_VADER_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    visible2 = layers.Input(shape=(np.array(df_train['mean_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    flat2 = visible2\n",
    "\n",
    "    # merge input models\n",
    "    merge = layers.concatenate([flat1, flat2])\n",
    "#     merge = flat1\n",
    "    \n",
    "    # interpretation model\n",
    "    dropout1 = layers.Dropout(dropout_value)(merge)  \n",
    "    hidden1 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n",
    "    dropout2 = layers.Dropout(dropout_value)(hidden1)\n",
    "    hidden2 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout2)\n",
    "    dropout3 = layers.Dropout(dropout_value)(hidden2)\n",
    "    hidden3 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout3)\n",
    "    dropout4 = layers.Dropout(dropout_value)(hidden3)\n",
    "    hidden4 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout4)\n",
    "    dropout5 = layers.Dropout(dropout_value)(hidden4)\n",
    "    hidden5 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout5)\n",
    "    dropout6 = layers.Dropout(dropout_value)(hidden5)\n",
    "    output = layers.Dense(1, activation='tanh')(dropout6)\n",
    "    model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "\n",
    "    return model\n",
    "  \n",
    "def create_ANN_model_hidden_10(number_dense, dropout_value, embedding_matrix, emb_layer_trainable):\n",
    "    \n",
    "    # first input model\n",
    "    visible1 = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), name='Word_Seq')\n",
    "    embedding = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable)(visible1)\n",
    "#     conv1 = layers.Conv1D(num_filters_1, size_filters_1, padding='same', activation='relu')(embedding)\n",
    "#     conv2 = layers.Conv1D(num_filters_2, size_filters_2, padding='same', activation='relu')(conv1)\n",
    "    pool1 = layers.GlobalMaxPooling1D()(embedding)\n",
    "    flat1 = pool1\n",
    "    \n",
    "    # second input model\n",
    "#     visible2 = layers.Input(shape=(np.array(df_train['mean_VADER_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    visible2 = layers.Input(shape=(np.array(df_train['mean_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    flat2 = visible2\n",
    "\n",
    "    # merge input models\n",
    "    merge = layers.concatenate([flat1, flat2])\n",
    "#     merge = flat1\n",
    "    \n",
    "    # interpretation model\n",
    "    dropout1 = layers.Dropout(dropout_value)(merge)  \n",
    "    hidden1 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n",
    "    dropout2 = layers.Dropout(dropout_value)(hidden1)\n",
    "    hidden2 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout2)\n",
    "    dropout3 = layers.Dropout(dropout_value)(hidden2)\n",
    "    hidden3 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout3)\n",
    "    dropout4 = layers.Dropout(dropout_value)(hidden3)\n",
    "    hidden4 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout4)\n",
    "    dropout5 = layers.Dropout(dropout_value)(hidden4)\n",
    "    hidden5 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout5)\n",
    "    dropout6 = layers.Dropout(dropout_value)(hidden5)\n",
    "    hidden6 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout6)\n",
    "    dropout7 = layers.Dropout(dropout_value)(hidden6)\n",
    "    hidden7 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout7)\n",
    "    dropout8 = layers.Dropout(dropout_value)(hidden7)\n",
    "    hidden8 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout8)\n",
    "    dropout9 = layers.Dropout(dropout_value)(hidden8)\n",
    "    hidden9 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout9)\n",
    "    dropout10 = layers.Dropout(dropout_value)(hidden9)\n",
    "    hidden10 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout10)\n",
    "    dropout11 = layers.Dropout(dropout_value)(hidden10)\n",
    "    output = layers.Dense(1, activation='tanh')(dropout11)\n",
    "    model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XMj2FWnlwp8K"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X, Y, batch_size, epochs_value, nome_log, X_cv, Y_cv):\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=metrics)\n",
    "    \n",
    "    return model.fit(X, Y, batch_size,\n",
    "                     validation_data=(X_cv, Y_cv),\n",
    "                     epochs=epochs_value,\n",
    "                     verbose=0,\n",
    "                     callbacks=callback_functions(nome_log)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPhI1NJswp8N"
   },
   "outputs": [],
   "source": [
    "def save_model(model, trained_model_history, model_name):\n",
    "    \n",
    "#     model.save(model_name + '.h5')\n",
    "    trained_model = trained_model_history\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.plot([abs(v) for v in trained_model.history['loss']])\n",
    "    plt.plot([abs(v) for v in trained_model.history['val_loss']])\n",
    "    plt.plot([abs(v) for v in trained_model.history['cosine_proximity']])\n",
    "    plt.plot([abs(v) for v in trained_model.history['val_cosine_proximity']])\n",
    "    plt.title('model mean squared error')\n",
    "    plt.ylabel('mean squared error')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['mse_train', 'mse_test', 'cos_sim_train', 'cos_sim_test'], loc='upper left')\n",
    "    plt.savefig(results_ann + model_name + '_mse.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqcHcjJOwp8R"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, Y_expected):\n",
    "    input = X\n",
    "    output = np.array(model.predict(input))\n",
    "    expected = np.array(Y_expected)\n",
    "\n",
    "    dot = np.dot(expected, output)\n",
    "    output_mod = np.linalg.norm(output)\n",
    "    expected_mod = np.linalg.norm(expected)\n",
    "    cos = dot / output_mod / expected_mod\n",
    "\n",
    "    final_score = cos\n",
    "    \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tP6QpoR77w2y"
   },
   "source": [
    "## K-fold on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6414
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5723121,
     "status": "ok",
     "timestamp": 1560543521781,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "aMRsC6M3wp8T",
    "outputId": "d992e0e8-575e-40ba-b405-86da522d27f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "ID: 10000, Cos Sim Mean: 0.4588351703329594, Cos Sim Std: 0.026611284707796938, MSE Mean: 0.1240746408451872, MSE Std: 0.003958576960968199, Training Time: 0:00:02.265769, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10001, Cos Sim Mean: 0.4590043507976806, Cos Sim Std: 0.04611543494159703, MSE Mean: 0.1314130044414477, MSE Std: 0.006215659330370485, Training Time: 0:00:02.270613, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10002, Cos Sim Mean: 0.4294060819146127, Cos Sim Std: 0.05709638576152163, MSE Mean: 0.14879352554290887, MSE Std: 0.008561259206458892, Training Time: 0:00:02.302235, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10003, Cos Sim Mean: 0.47847027003755355, Cos Sim Std: 0.05176009364919262, MSE Mean: 0.12543671887181299, MSE Std: 0.0053949386744574085, Training Time: 0:00:02.312797, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10004, Cos Sim Mean: 0.4644137092850956, Cos Sim Std: 0.03984045831128527, MSE Mean: 0.12878622624725053, MSE Std: 0.0066451419169884325, Training Time: 0:00:02.343638, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10005, Cos Sim Mean: 0.43610353750587266, Cos Sim Std: 0.03645444477365125, MSE Mean: 0.15143480595867018, MSE Std: 0.012177992754218304, Training Time: 0:00:02.320796, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10006, Cos Sim Mean: 0.4709492972947854, Cos Sim Std: 0.03292484720306714, MSE Mean: 0.12440390290868657, MSE Std: 0.013881148786931299, Training Time: 0:00:02.320909, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10007, Cos Sim Mean: 0.4800975184429642, Cos Sim Std: 0.029482691015424715, MSE Mean: 0.12806246432012364, MSE Std: 0.00608746819415141, Training Time: 0:00:02.355577, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10008, Cos Sim Mean: 0.4204009644149441, Cos Sim Std: 0.06944112021380834, MSE Mean: 0.1477739262206471, MSE Std: 0.011494014451184174, Training Time: 0:00:02.270143, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10009, Cos Sim Mean: 0.46585546237923214, Cos Sim Std: 0.03147663895978986, MSE Mean: 0.1223335997898968, MSE Std: 0.00461873674786534, Training Time: 0:00:02.728585, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10010, Cos Sim Mean: 0.47458580843475734, Cos Sim Std: 0.037380578632625484, MSE Mean: 0.13102671878309907, MSE Std: 0.006300375359444505, Training Time: 0:00:02.714949, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10011, Cos Sim Mean: 0.3764086079965206, Cos Sim Std: 0.04571214341039883, MSE Mean: 0.14994745032538348, MSE Std: 0.007179439520731646, Training Time: 0:00:02.768385, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10012, Cos Sim Mean: 0.4483155339262475, Cos Sim Std: 0.07009399720555842, MSE Mean: 0.12460334835264386, MSE Std: 0.005143370845656631, Training Time: 0:00:02.771600, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10013, Cos Sim Mean: 0.4290131286008543, Cos Sim Std: 0.027974756494065348, MSE Mean: 0.13047234414662717, MSE Std: 0.005636117766845796, Training Time: 0:00:02.725112, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10014, Cos Sim Mean: 0.382037622487606, Cos Sim Std: 0.049399889136360696, MSE Mean: 0.15302797029459486, MSE Std: 0.005876208221015835, Training Time: 0:00:02.764396, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10015, Cos Sim Mean: 0.4430533389941026, Cos Sim Std: 0.04778004253118402, MSE Mean: 0.12643232671216326, MSE Std: 0.004865452576276167, Training Time: 0:00:02.739130, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10016, Cos Sim Mean: 0.43216624766165446, Cos Sim Std: 0.0763466927596114, MSE Mean: 0.13382223890404643, MSE Std: 0.005731671166494119, Training Time: 0:00:02.689050, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10017, Cos Sim Mean: 0.23351276466914395, Cos Sim Std: 0.09080677315371107, MSE Mean: 0.15956710220557374, MSE Std: 0.006619624612326093, Training Time: 0:00:02.757815, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10018, Cos Sim Mean: 0.4820730223062526, Cos Sim Std: 0.05104787863276075, MSE Mean: 0.1298018999873776, MSE Std: 0.006247383315288651, Training Time: 0:00:03.125727, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10019, Cos Sim Mean: 0.42214715699949357, Cos Sim Std: 0.010259276265123048, MSE Mean: 0.1485718776938648, MSE Std: 0.0063555145939757345, Training Time: 0:00:03.131043, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10020, Cos Sim Mean: 0.17692518356977532, Cos Sim Std: 0.01173531125750074, MSE Mean: 0.15970356478999617, MSE Std: 0.006243716786918756, Training Time: 0:00:03.111731, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10021, Cos Sim Mean: 0.47134510821668485, Cos Sim Std: 0.04390402169942539, MSE Mean: 0.130540426796731, MSE Std: 0.004320211846471965, Training Time: 0:00:03.122371, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10022, Cos Sim Mean: 0.2613460341823012, Cos Sim Std: 0.09046807477073972, MSE Mean: 0.1552445178916227, MSE Std: 0.004970374111173343, Training Time: 0:00:03.113889, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10023, Cos Sim Mean: 0.17692518584999478, Cos Sim Std: 0.0117353099964943, MSE Mean: 0.16123550968839045, MSE Std: 0.006140620755455729, Training Time: 0:00:03.131355, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10024, Cos Sim Mean: 0.4642270691533154, Cos Sim Std: 0.028531522321394522, MSE Mean: 0.13698889288133906, MSE Std: 0.006825363928522577, Training Time: 0:00:03.032002, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10025, Cos Sim Mean: 0.17866431827992238, Cos Sim Std: 0.009693821672650977, MSE Mean: 0.15819986486589563, MSE Std: 0.00597732278016482, Training Time: 0:00:02.699070, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10026, Cos Sim Mean: 0.1769251881703205, Cos Sim Std: 0.01173531163295849, MSE Mean: 0.16377403066430388, MSE Std: 0.005771911765551764, Training Time: 0:00:02.637793, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10027, Cos Sim Mean: 0.17692518143066283, Cos Sim Std: 0.011735317742432326, MSE Mean: 0.15497101006579006, MSE Std: 0.006383760621560363, Training Time: 0:00:03.286050, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10028, Cos Sim Mean: 0.17692518869169654, Cos Sim Std: 0.011735310750018133, MSE Mean: 0.15505690560904944, MSE Std: 0.006378097905534228, Training Time: 0:00:03.443057, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10029, Cos Sim Mean: 0.17692517797986762, Cos Sim Std: 0.011735313020757514, MSE Mean: 0.15684764435210583, MSE Std: 0.0062552098782563135, Training Time: 0:00:03.756036, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10030, Cos Sim Mean: 0.17692518915816766, Cos Sim Std: 0.01173531011181725, MSE Mean: 0.1549940562180513, MSE Std: 0.006393358222177443, Training Time: 0:00:03.856900, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10031, Cos Sim Mean: 0.17692517987554154, Cos Sim Std: 0.011735318690893299, MSE Mean: 0.15521868763307103, MSE Std: 0.006368400581008353, Training Time: 0:00:03.846676, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10032, Cos Sim Mean: 0.17692518193938292, Cos Sim Std: 0.011735310670793921, MSE Mean: 0.15879110470485702, MSE Std: 0.005706372652252901, Training Time: 0:00:03.809534, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10033, Cos Sim Mean: 0.1769251872592586, Cos Sim Std: 0.011735311533105384, MSE Mean: 0.15520563439973986, MSE Std: 0.006331527770117967, Training Time: 0:00:03.818025, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10034, Cos Sim Mean: 0.17692518491961515, Cos Sim Std: 0.01173530659339857, MSE Mean: 0.15642331566289747, MSE Std: 0.006061672077506085, Training Time: 0:00:03.838097, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10035, Cos Sim Mean: 0.17692518915816766, Cos Sim Std: 0.01173531011181725, MSE Mean: 0.16455835857401874, MSE Std: 0.0065697762017763684, Training Time: 0:00:03.824140, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10036, Cos Sim Mean: 0.17692518152180187, Cos Sim Std: 0.011735301915700538, MSE Mean: 0.15494871742711167, MSE Std: 0.006399968096970297, Training Time: 0:00:05.963144, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10037, Cos Sim Mean: 0.17692518869169654, Cos Sim Std: 0.011735310750018133, MSE Mean: 0.15495299767982412, MSE Std: 0.00639449084176941, Training Time: 0:00:05.953650, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10038, Cos Sim Mean: 0.17692519283731198, Cos Sim Std: 0.011735309859310724, MSE Mean: 0.1556572982548554, MSE Std: 0.006376125816682734, Training Time: 0:00:05.996055, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10039, Cos Sim Mean: 0.17692518246380146, Cos Sim Std: 0.011735306794195561, MSE Mean: 0.15495512127173763, MSE Std: 0.006397170981932406, Training Time: 0:00:06.032047, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10040, Cos Sim Mean: 0.1769251836645636, Cos Sim Std: 0.011735314394715785, MSE Mean: 0.15497396851740264, MSE Std: 0.0063970726787910106, Training Time: 0:00:05.976782, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10041, Cos Sim Mean: 0.17692518143066283, Cos Sim Std: 0.011735317742432326, MSE Mean: 0.15682801987426026, MSE Std: 0.006811579363418647, Training Time: 0:00:06.080256, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10042, Cos Sim Mean: 0.17692518497259707, Cos Sim Std: 0.011735306637378776, MSE Mean: 0.15494778541011814, MSE Std: 0.00639880876358172, Training Time: 0:00:06.172330, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10043, Cos Sim Mean: 0.17692517771195265, Cos Sim Std: 0.011735310396102573, MSE Mean: 0.15510264210429847, MSE Std: 0.006330381637857929, Training Time: 0:00:06.169859, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10044, Cos Sim Mean: 0.1769251786193148, Cos Sim Std: 0.011735305886729773, MSE Mean: 0.1639913906912105, MSE Std: 0.003943303713609189, Training Time: 0:00:06.303240, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10045, Cos Sim Mean: 0.44656928443183475, Cos Sim Std: 0.048544166246340156, MSE Mean: 0.18053748731159863, MSE Std: 0.011690791272348846, Training Time: 0:00:01.312358, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10046, Cos Sim Mean: 0.4148526756280887, Cos Sim Std: 0.02851014788369916, MSE Mean: 0.18250867055982284, MSE Std: 0.0074364940202760145, Training Time: 0:00:01.293770, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10047, Cos Sim Mean: 0.36503742731053535, Cos Sim Std: 0.08809038380464211, MSE Mean: 0.19654849735848265, MSE Std: 0.007831098863416278, Training Time: 0:00:01.302274, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10048, Cos Sim Mean: 0.44151980155201853, Cos Sim Std: 0.03814156812875877, MSE Mean: 0.17285997715113435, MSE Std: 0.01860442452213158, Training Time: 0:00:01.285347, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10049, Cos Sim Mean: 0.40839158965872197, Cos Sim Std: 0.027945009953438293, MSE Mean: 0.17121779550903568, MSE Std: 0.01136027851412865, Training Time: 0:00:01.296971, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10050, Cos Sim Mean: 0.35933992017596744, Cos Sim Std: 0.03152545733028472, MSE Mean: 0.19041511140611955, MSE Std: 0.008979887893203845, Training Time: 0:00:01.277619, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10051, Cos Sim Mean: 0.4466478731650866, Cos Sim Std: 0.03255517350833444, MSE Mean: 0.15986452020589711, MSE Std: 0.020796399845957794, Training Time: 0:00:01.309173, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10052, Cos Sim Mean: 0.3977933062204649, Cos Sim Std: 0.030619591221291084, MSE Mean: 0.16352422821745305, MSE Std: 0.012979410886379645, Training Time: 0:00:01.295360, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10053, Cos Sim Mean: 0.3388553175821599, Cos Sim Std: 0.06794330399045899, MSE Mean: 0.18037169781431878, MSE Std: 0.012829112084991592, Training Time: 0:00:01.265186, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10054, Cos Sim Mean: 0.46083740910175, Cos Sim Std: 0.0471769541463979, MSE Mean: 0.1447213395127334, MSE Std: 0.004290168745987039, Training Time: 0:00:01.543075, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10055, Cos Sim Mean: 0.41678414023339394, Cos Sim Std: 0.04929635001594452, MSE Mean: 0.15764688106176955, MSE Std: 0.00447011659945162, Training Time: 0:00:01.545520, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10056, Cos Sim Mean: 0.35519761830025254, Cos Sim Std: 0.08237987317479978, MSE Mean: 0.19322390775272807, MSE Std: 0.006389903760569495, Training Time: 0:00:01.523678, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10057, Cos Sim Mean: 0.45348577336507984, Cos Sim Std: 0.0137235671731518, MSE Mean: 0.1456710684036042, MSE Std: 0.0035116372960598535, Training Time: 0:00:01.557739, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10058, Cos Sim Mean: 0.4009544284061118, Cos Sim Std: 0.02781747731846855, MSE Mean: 0.15962773657169418, MSE Std: 0.006545259943882597, Training Time: 0:00:01.546684, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10059, Cos Sim Mean: 0.34012675367797, Cos Sim Std: 0.08390991880129643, MSE Mean: 0.19535026226558153, MSE Std: 0.006658177516265695, Training Time: 0:00:01.515167, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10060, Cos Sim Mean: 0.44321809753497377, Cos Sim Std: 0.04069207850084284, MSE Mean: 0.14739188990934152, MSE Std: 0.0019669616492447054, Training Time: 0:00:01.559265, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10061, Cos Sim Mean: 0.3267967945950466, Cos Sim Std: 0.09630663980827776, MSE Mean: 0.16693860217213402, MSE Std: 0.007279395900263005, Training Time: 0:00:01.536640, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10062, Cos Sim Mean: 0.17692518957768602, Cos Sim Std: 0.01173531119897653, MSE Mean: 0.19564196404131043, MSE Std: 0.005411940818314961, Training Time: 0:00:01.515013, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10063, Cos Sim Mean: 0.4258957775492336, Cos Sim Std: 0.05638767945525533, MSE Mean: 0.14771523263133998, MSE Std: 0.004367965774711832, Training Time: 0:00:01.770053, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10064, Cos Sim Mean: 0.3412722799984572, Cos Sim Std: 0.04646496486145901, MSE Mean: 0.16461491311841883, MSE Std: 0.004576678907387134, Training Time: 0:00:01.766309, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10065, Cos Sim Mean: 0.1769251888724344, Cos Sim Std: 0.011735311362870034, MSE Mean: 0.20006010848912403, MSE Std: 0.005933901466857746, Training Time: 0:00:01.784702, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10066, Cos Sim Mean: 0.4481392184762621, Cos Sim Std: 0.053539804513665586, MSE Mean: 0.14695844316579526, MSE Std: 0.007271450084545863, Training Time: 0:00:01.759765, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10067, Cos Sim Mean: 0.21422457900746356, Cos Sim Std: 0.07379616396232848, MSE Mean: 0.17416891780157578, MSE Std: 0.0063230069699315855, Training Time: 0:00:01.783400, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10068, Cos Sim Mean: 0.17692518936466492, Cos Sim Std: 0.011735310768861505, MSE Mean: 0.206941102463113, MSE Std: 0.010228366579250015, Training Time: 0:00:01.758247, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10069, Cos Sim Mean: 0.3329672877741493, Cos Sim Std: 0.062348787644878126, MSE Mean: 0.15650126161810965, MSE Std: 0.007255145260935431, Training Time: 0:00:01.753514, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10070, Cos Sim Mean: 0.17692519009060775, Cos Sim Std: 0.011735310418866152, MSE Mean: 0.18148686765357333, MSE Std: 0.005640449290920049, Training Time: 0:00:01.765547, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10071, Cos Sim Mean: 0.176925185848024, Cos Sim Std: 0.011735314359867615, MSE Mean: 0.21075660699803422, MSE Std: 0.010483097590064765, Training Time: 0:00:01.747608, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10072, Cos Sim Mean: 0.17692518300790114, Cos Sim Std: 0.011735308798953226, MSE Mean: 0.15565223564908895, MSE Std: 0.006191672768477589, Training Time: 0:00:02.290567, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10073, Cos Sim Mean: 0.1769251800581285, Cos Sim Std: 0.011735305444520996, MSE Mean: 0.1581842969249609, MSE Std: 0.005805241874437898, Training Time: 0:00:02.172697, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10074, Cos Sim Mean: 0.17692518873185098, Cos Sim Std: 0.011735311162976053, MSE Mean: 0.1803607497953773, MSE Std: 0.005606791546057335, Training Time: 0:00:02.209196, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10075, Cos Sim Mean: 0.17692518488128545, Cos Sim Std: 0.011735314045033975, MSE Mean: 0.15700773896307058, MSE Std: 0.006874264264330585, Training Time: 0:00:02.187999, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10076, Cos Sim Mean: 0.1769251889501796, Cos Sim Std: 0.011735311256503215, MSE Mean: 0.16257401645275732, MSE Std: 0.006624226246418659, Training Time: 0:00:02.179814, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10077, Cos Sim Mean: 0.1769251880798463, Cos Sim Std: 0.011735311907926664, MSE Mean: 0.19810703302588806, MSE Std: 0.002957270175396263, Training Time: 0:00:02.177540, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10078, Cos Sim Mean: 0.17692518676446073, Cos Sim Std: 0.01173531127108715, MSE Mean: 0.16262200773892213, MSE Std: 0.0068458472267563285, Training Time: 0:00:02.238416, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10079, Cos Sim Mean: 0.1769251825394176, Cos Sim Std: 0.011735315278150709, MSE Mean: 0.17578092626426506, MSE Std: 0.0064566447520528324, Training Time: 0:00:02.362253, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10080, Cos Sim Mean: 0.17692518466646517, Cos Sim Std: 0.011735306529793547, MSE Mean: 0.23177641975681434, MSE Std: 0.013366293815697872, Training Time: 0:00:02.364510, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10081, Cos Sim Mean: 0.17692518445930563, Cos Sim Std: 0.01173531436087621, MSE Mean: 0.15495686247362683, MSE Std: 0.006394998262303472, Training Time: 0:00:04.050261, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10082, Cos Sim Mean: 0.17692518970915608, Cos Sim Std: 0.011735308587542292, MSE Mean: 0.15515146724008838, MSE Std: 0.006338071068327577, Training Time: 0:00:04.146516, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10083, Cos Sim Mean: 0.1769251824127942, Cos Sim Std: 0.011735314528206822, MSE Mean: 0.17274592805113062, MSE Std: 0.006549809066586461, Training Time: 0:00:04.152559, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10084, Cos Sim Mean: 0.17692518197145957, Cos Sim Std: 0.011735317764612722, MSE Mean: 0.15501672567995733, MSE Std: 0.006396404431322757, Training Time: 0:00:04.066314, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10085, Cos Sim Mean: 0.17692517956407722, Cos Sim Std: 0.011735305940235113, MSE Mean: 0.1559898155888014, MSE Std: 0.006512256740190498, Training Time: 0:00:04.208823, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10086, Cos Sim Mean: 0.17692518936482066, Cos Sim Std: 0.011735310689213518, MSE Mean: 0.18605210915509157, MSE Std: 0.014704143896670806, Training Time: 0:00:04.183263, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10087, Cos Sim Mean: 0.1769251809760673, Cos Sim Std: 0.011735307622416235, MSE Mean: 0.15770494248672617, MSE Std: 0.006114548214827172, Training Time: 0:00:04.161422, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10088, Cos Sim Mean: 0.17692517714640826, Cos Sim Std: 0.011735306208157863, MSE Mean: 0.16522985404128482, MSE Std: 0.004355024746836653, Training Time: 0:00:04.160789, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10089, Cos Sim Mean: 0.17692518096138973, Cos Sim Std: 0.011735308966283668, MSE Mean: 0.23326504022865396, MSE Std: 0.007499363211160345, Training Time: 0:00:04.165411, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10090, Cos Sim Mean: 0.4470643787558144, Cos Sim Std: 0.04948598843760719, MSE Mean: 0.13342523262707232, MSE Std: 0.006665137656366854, Training Time: 0:00:02.458024, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10091, Cos Sim Mean: 0.4714348667842588, Cos Sim Std: 0.03954470282376605, MSE Mean: 0.1389087681599703, MSE Std: 0.004344530279562867, Training Time: 0:00:02.413041, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10092, Cos Sim Mean: 0.4047766437803985, Cos Sim Std: 0.050340112163007676, MSE Mean: 0.16082449701803364, MSE Std: 0.009875939834636476, Training Time: 0:00:02.402700, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10093, Cos Sim Mean: 0.4710759103346094, Cos Sim Std: 0.029289515103679734, MSE Mean: 0.13480343141678708, MSE Std: 0.010069684874435476, Training Time: 0:00:02.431273, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10094, Cos Sim Mean: 0.45187531848828727, Cos Sim Std: 0.016963643969774178, MSE Mean: 0.14159071787461713, MSE Std: 0.006442165863700985, Training Time: 0:00:02.439529, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10095, Cos Sim Mean: 0.37835247133967576, Cos Sim Std: 0.05360687021614188, MSE Mean: 0.1628735571921976, MSE Std: 0.009751729376518305, Training Time: 0:00:02.427436, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10096, Cos Sim Mean: 0.4800414108991583, Cos Sim Std: 0.019065850215819986, MSE Mean: 0.13069395768386008, MSE Std: 0.008896980214657513, Training Time: 0:00:02.419242, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10097, Cos Sim Mean: 0.4468863523786572, Cos Sim Std: 0.0290766309802871, MSE Mean: 0.1414822496950622, MSE Std: 0.009231942067869446, Training Time: 0:00:02.476617, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10098, Cos Sim Mean: 0.41865403863942996, Cos Sim Std: 0.03184800470464252, MSE Mean: 0.15657233453076908, MSE Std: 0.012079951492531011, Training Time: 0:00:02.417718, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10099, Cos Sim Mean: 0.45577279879640276, Cos Sim Std: 0.05090360563874632, MSE Mean: 0.12726738325320106, MSE Std: 0.006828145726661021, Training Time: 0:00:02.943165, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10100, Cos Sim Mean: 0.469559483320417, Cos Sim Std: 0.06368429779302397, MSE Mean: 0.136018998450462, MSE Std: 0.004488973325058325, Training Time: 0:00:02.948569, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10101, Cos Sim Mean: 0.3714432232523347, Cos Sim Std: 0.028815058327354728, MSE Mean: 0.1594822194863264, MSE Std: 0.004369635703836691, Training Time: 0:00:02.978996, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10102, Cos Sim Mean: 0.44866341731439724, Cos Sim Std: 0.036385782381138904, MSE Mean: 0.13126385639232233, MSE Std: 0.0066085566848526345, Training Time: 0:00:02.937108, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10103, Cos Sim Mean: 0.47132398108077594, Cos Sim Std: 0.056171097567171, MSE Mean: 0.14028148303628063, MSE Std: 0.0033277984747487406, Training Time: 0:00:02.907910, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10104, Cos Sim Mean: 0.32711474294076187, Cos Sim Std: 0.0449827260214088, MSE Mean: 0.16852439568357166, MSE Std: 0.005183584763821284, Training Time: 0:00:02.978758, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10105, Cos Sim Mean: 0.4467456446256799, Cos Sim Std: 0.032720968028780384, MSE Mean: 0.13553980927065062, MSE Std: 0.005078894106462139, Training Time: 0:00:02.945388, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10106, Cos Sim Mean: 0.4344030263908715, Cos Sim Std: 0.04002526388524141, MSE Mean: 0.14441925570890873, MSE Std: 0.006393827631170925, Training Time: 0:00:02.902157, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10107, Cos Sim Mean: 0.17692518832157905, Cos Sim Std: 0.011735309981058512, MSE Mean: 0.1726645064808289, MSE Std: 0.006100277482007636, Training Time: 0:00:02.956664, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10108, Cos Sim Mean: 0.49399907690881806, Cos Sim Std: 0.049999675063746356, MSE Mean: 0.12863474642205602, MSE Std: 0.007434807976873886, Training Time: 0:00:03.429914, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10109, Cos Sim Mean: 0.3078939135160444, Cos Sim Std: 0.16053529727151805, MSE Mean: 0.15105095535683394, MSE Std: 0.009350556035797037, Training Time: 0:00:03.439627, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10110, Cos Sim Mean: 0.1769251858865649, Cos Sim Std: 0.01173531276385417, MSE Mean: 0.16550807153921734, MSE Std: 0.0062350798968741124, Training Time: 0:00:03.423221, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10111, Cos Sim Mean: 0.4570806383576359, Cos Sim Std: 0.05604021514806995, MSE Mean: 0.13610269929591137, MSE Std: 0.012125722892626952, Training Time: 0:00:03.402033, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10112, Cos Sim Mean: 0.25548600180943876, Cos Sim Std: 0.1098690270543959, MSE Mean: 0.15728721458811262, MSE Std: 0.0038321342806934638, Training Time: 0:00:03.392604, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10113, Cos Sim Mean: 0.17692518599088586, Cos Sim Std: 0.0117353099511363, MSE Mean: 0.1706312480433449, MSE Std: 0.005787656231193569, Training Time: 0:00:03.402859, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10114, Cos Sim Mean: 0.42678265530945475, Cos Sim Std: 0.1287089964372555, MSE Mean: 0.14124901255015285, MSE Std: 0.008617372915553296, Training Time: 0:00:03.390486, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10115, Cos Sim Mean: 0.1769251884964267, Cos Sim Std: 0.011735311465625323, MSE Mean: 0.16353148494383463, MSE Std: 0.0053462681030856255, Training Time: 0:00:03.389634, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10116, Cos Sim Mean: 0.17692518619312542, Cos Sim Std: 0.011735308122376633, MSE Mean: 0.1780619967972203, MSE Std: 0.007678087303789743, Training Time: 0:00:03.429121, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10117, Cos Sim Mean: 0.17692518272714022, Cos Sim Std: 0.011735309467537609, MSE Mean: 0.15498493198172483, MSE Std: 0.006380460274166545, Training Time: 0:00:03.950959, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10118, Cos Sim Mean: 0.17692518146881994, Cos Sim Std: 0.0117353018717203, MSE Mean: 0.15525758115934052, MSE Std: 0.006369617961154413, Training Time: 0:00:03.516433, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10119, Cos Sim Mean: 0.1769251828541566, Cos Sim Std: 0.011735315729512903, MSE Mean: 0.1589838299682657, MSE Std: 0.006541608167924177, Training Time: 0:00:03.557454, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10120, Cos Sim Mean: 0.1769251862556806, Cos Sim Std: 0.011735314082845602, MSE Mean: 0.1550944294413042, MSE Std: 0.006370546402262204, Training Time: 0:00:03.552500, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10121, Cos Sim Mean: 0.17692518923591286, Cos Sim Std: 0.011735310005450443, MSE Mean: 0.15595684573449226, MSE Std: 0.006269986847728917, Training Time: 0:00:03.532225, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10122, Cos Sim Mean: 0.17692518219262632, Cos Sim Std: 0.011735311542265535, MSE Mean: 0.1660757459470268, MSE Std: 0.005194858322191358, Training Time: 0:00:03.528894, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10123, Cos Sim Mean: 0.17692519278433008, Cos Sim Std: 0.011735309815330476, MSE Mean: 0.1559783105805736, MSE Std: 0.006428420920980607, Training Time: 0:00:03.487971, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10124, Cos Sim Mean: 0.17692517992711207, Cos Sim Std: 0.011735308654471692, MSE Mean: 0.15952031264306687, MSE Std: 0.006718398072267405, Training Time: 0:00:03.485044, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10125, Cos Sim Mean: 0.17692518866809667, Cos Sim Std: 0.01173531126018017, MSE Mean: 0.17771853846002766, MSE Std: 0.010178768779639769, Training Time: 0:00:03.548162, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10126, Cos Sim Mean: 0.17692518146881994, Cos Sim Std: 0.0117353018717203, MSE Mean: 0.1549594479704997, MSE Std: 0.006393025979938967, Training Time: 0:00:06.471833, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10127, Cos Sim Mean: 0.17692518441089505, Cos Sim Std: 0.011735313665039564, MSE Mean: 0.1549577285796418, MSE Std: 0.006398525836455635, Training Time: 0:00:06.281827, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10128, Cos Sim Mean: 0.17692518016776632, Cos Sim Std: 0.011735310195306577, MSE Mean: 0.15613932060344324, MSE Std: 0.006264624947758676, Training Time: 0:00:06.904959, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10129, Cos Sim Mean: 0.17692518884718691, Cos Sim Std: 0.011735310537284497, MSE Mean: 0.1549557332048141, MSE Std: 0.0063955794037028535, Training Time: 0:00:06.512715, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10130, Cos Sim Mean: 0.17692518441089505, Cos Sim Std: 0.011735313665039564, MSE Mean: 0.1549929065908766, MSE Std: 0.006396248045167343, Training Time: 0:00:06.592751, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10131, Cos Sim Mean: 0.17692518884718691, Cos Sim Std: 0.011735310537284497, MSE Mean: 0.1592405096143354, MSE Std: 0.0067129128624402274, Training Time: 0:00:06.676216, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10132, Cos Sim Mean: 0.17692519088542102, Cos Sim Std: 0.011735311236619233, MSE Mean: 0.15495521819342745, MSE Std: 0.006394124892699435, Training Time: 0:00:06.577048, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10133, Cos Sim Mean: 0.17692518497259707, Cos Sim Std: 0.011735306637378776, MSE Mean: 0.15563206915672614, MSE Std: 0.006200657795904116, Training Time: 0:00:06.558536, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10134, Cos Sim Mean: 0.17692518915816766, Cos Sim Std: 0.01173531011181725, MSE Mean: 0.17345544064972146, MSE Std: 0.004405982038243314, Training Time: 0:00:06.759646, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10135, Cos Sim Mean: 0.4273782824829073, Cos Sim Std: 0.02705104090646604, MSE Mean: 0.19287755093577422, MSE Std: 0.01279881488780586, Training Time: 0:00:01.463043, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10136, Cos Sim Mean: 0.3925794904914806, Cos Sim Std: 0.06476922262251213, MSE Mean: 0.20202754392131048, MSE Std: 0.0022513341591968977, Training Time: 0:00:01.386540, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10137, Cos Sim Mean: 0.3124616767470424, Cos Sim Std: 0.10380963214639066, MSE Mean: 0.22148750995186547, MSE Std: 0.005970859537003747, Training Time: 0:00:01.381672, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10138, Cos Sim Mean: 0.39418526124282643, Cos Sim Std: 0.03914992737170645, MSE Mean: 0.1988670864531434, MSE Std: 0.011678207709626466, Training Time: 0:00:01.409777, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10139, Cos Sim Mean: 0.3701604232112548, Cos Sim Std: 0.059972538360103744, MSE Mean: 0.2039912423180307, MSE Std: 0.0114991980100294, Training Time: 0:00:01.351400, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10140, Cos Sim Mean: 0.34099420881484127, Cos Sim Std: 0.11774764132327784, MSE Mean: 0.2236971092536907, MSE Std: 0.011620969157905716, Training Time: 0:00:01.381978, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10141, Cos Sim Mean: 0.3944976598235999, Cos Sim Std: 0.05873883346055502, MSE Mean: 0.18093682296994246, MSE Std: 0.013117591993042667, Training Time: 0:00:01.386841, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10142, Cos Sim Mean: 0.3978118290256701, Cos Sim Std: 0.023429991940252266, MSE Mean: 0.1862820643231669, MSE Std: 0.012692300198008028, Training Time: 0:00:01.374283, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10143, Cos Sim Mean: 0.33238832167627574, Cos Sim Std: 0.05780071460690887, MSE Mean: 0.21237227871031278, MSE Std: 0.015166176501895732, Training Time: 0:00:01.387117, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10144, Cos Sim Mean: 0.47292909327783184, Cos Sim Std: 0.03575514746055254, MSE Mean: 0.1537182985639161, MSE Std: 0.003902483812440568, Training Time: 0:00:01.661042, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10145, Cos Sim Mean: 0.4049464423516297, Cos Sim Std: 0.04475576996400012, MSE Mean: 0.18039838457094393, MSE Std: 0.0026294370495848624, Training Time: 0:00:01.688649, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10146, Cos Sim Mean: 0.3174472470959272, Cos Sim Std: 0.06662237283398054, MSE Mean: 0.22883156591689718, MSE Std: 0.005437095780971663, Training Time: 0:00:01.693897, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10147, Cos Sim Mean: 0.4715983877425597, Cos Sim Std: 0.04751380908243173, MSE Mean: 0.16434669797187534, MSE Std: 0.0062364277572230205, Training Time: 0:00:01.698840, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10148, Cos Sim Mean: 0.324074309949962, Cos Sim Std: 0.07135721834214753, MSE Mean: 0.19191410794882022, MSE Std: 0.008578523542158272, Training Time: 0:00:01.671438, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10149, Cos Sim Mean: 0.22235804747373072, Cos Sim Std: 0.05496999083413568, MSE Mean: 0.238983374187037, MSE Std: 0.005652225242236697, Training Time: 0:00:01.716878, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10150, Cos Sim Mean: 0.39452528449203983, Cos Sim Std: 0.08446204920664982, MSE Mean: 0.17150326068637084, MSE Std: 0.010610053227718888, Training Time: 0:00:01.695666, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10151, Cos Sim Mean: 0.3155766531588029, Cos Sim Std: 0.04935741936010029, MSE Mean: 0.1937269978813187, MSE Std: 0.010970834618020751, Training Time: 0:00:01.664374, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10152, Cos Sim Mean: 0.1769251880871851, Cos Sim Std: 0.011735312159374652, MSE Mean: 0.23424180276801926, MSE Std: 0.013078329384208763, Training Time: 0:00:01.713841, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10153, Cos Sim Mean: 0.450444736405, Cos Sim Std: 0.04943428214730758, MSE Mean: 0.15215974538780852, MSE Std: 0.005172214202702385, Training Time: 0:00:01.998130, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10154, Cos Sim Mean: 0.29033797282610485, Cos Sim Std: 0.10123578146531333, MSE Mean: 0.17843479125194017, MSE Std: 0.005254159303799298, Training Time: 0:00:01.975119, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10155, Cos Sim Mean: 0.17692518772765736, Cos Sim Std: 0.011735310484509154, MSE Mean: 0.2306702374059851, MSE Std: 0.011864605961916918, Training Time: 0:00:01.966409, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10156, Cos Sim Mean: 0.43814888392150514, Cos Sim Std: 0.04918976456160547, MSE Mean: 0.16128566595304364, MSE Std: 0.008853645805095333, Training Time: 0:00:01.972502, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10157, Cos Sim Mean: 0.2034601803022355, Cos Sim Std: 0.03645899396584898, MSE Mean: 0.19425867155305393, MSE Std: 0.00628492801051125, Training Time: 0:00:01.961873, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10158, Cos Sim Mean: 0.1769251881145486, Cos Sim Std: 0.011735309889812957, MSE Mean: 0.2538994072098743, MSE Std: 0.012817410562012615, Training Time: 0:00:01.961844, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10159, Cos Sim Mean: 0.37857260366268697, Cos Sim Std: 0.06563888390907215, MSE Mean: 0.17463648663512815, MSE Std: 0.007992089307419542, Training Time: 0:00:01.958882, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10160, Cos Sim Mean: 0.1769251868165135, Cos Sim Std: 0.011735311531272134, MSE Mean: 0.2062473005283476, MSE Std: 0.008099303441535253, Training Time: 0:00:01.963746, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10161, Cos Sim Mean: 0.17692518734158327, Cos Sim Std: 0.011735312042432904, MSE Mean: 0.26037435469241027, MSE Std: 0.014483168012901912, Training Time: 0:00:01.960030, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10162, Cos Sim Mean: 0.1769251835141337, Cos Sim Std: 0.01173531170098049, MSE Mean: 0.15616653839976316, MSE Std: 0.0062186164735297325, Training Time: 0:00:02.480625, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10163, Cos Sim Mean: 0.17692517915278144, Cos Sim Std: 0.011735308273356395, MSE Mean: 0.16082775934180304, MSE Std: 0.006196182116950091, Training Time: 0:00:02.474143, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10164, Cos Sim Mean: 0.17692518912745703, Cos Sim Std: 0.011735310866874453, MSE Mean: 0.19888299423771844, MSE Std: 0.00914354878021035, Training Time: 0:00:02.466609, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10165, Cos Sim Mean: 0.17692519106024168, Cos Sim Std: 0.011735312096582521, MSE Mean: 0.15928463932551745, MSE Std: 0.00650537470881276, Training Time: 0:00:02.477184, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10166, Cos Sim Mean: 0.17692518678366398, Cos Sim Std: 0.011735309937265714, MSE Mean: 0.17115543175242792, MSE Std: 0.005290836155393646, Training Time: 0:00:02.491670, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10167, Cos Sim Mean: 0.17692518883299696, Cos Sim Std: 0.01173530936801753, MSE Mean: 0.24169560206594182, MSE Std: 0.01615938493307076, Training Time: 0:00:02.483080, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10168, Cos Sim Mean: 0.17692518847040242, Cos Sim Std: 0.011735309693506396, MSE Mean: 0.17162051601307782, MSE Std: 0.009827541161616654, Training Time: 0:00:02.728627, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10169, Cos Sim Mean: 0.17692518862564427, Cos Sim Std: 0.01173531066555244, MSE Mean: 0.19904302592553363, MSE Std: 0.011907670976507698, Training Time: 0:00:02.922933, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10170, Cos Sim Mean: 0.17692518632956794, Cos Sim Std: 0.011735309788894598, MSE Mean: 0.28286601669050937, MSE Std: 0.030538904519094124, Training Time: 0:00:02.998222, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10171, Cos Sim Mean: 0.17692518604769256, Cos Sim Std: 0.011735315227531929, MSE Mean: 0.15496470643056032, MSE Std: 0.006391394491872741, Training Time: 0:00:04.359646, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10172, Cos Sim Mean: 0.17692518483046318, Cos Sim Std: 0.011735314260283177, MSE Mean: 0.15538140810449286, MSE Std: 0.006295873377293634, Training Time: 0:00:04.431251, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10173, Cos Sim Mean: 0.17692518059023218, Cos Sim Std: 0.011735309066876622, MSE Mean: 0.1815126649748205, MSE Std: 0.006339304425641939, Training Time: 0:00:04.407775, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10174, Cos Sim Mean: 0.17692518300790114, Cos Sim Std: 0.011735308798953226, MSE Mean: 0.1550846163436384, MSE Std: 0.006380773041697171, Training Time: 0:00:04.213802, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10175, Cos Sim Mean: 0.1769251868769746, Cos Sim Std: 0.011735314092952137, MSE Mean: 0.15748752401582303, MSE Std: 0.00645867231691339, Training Time: 0:00:04.393345, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10176, Cos Sim Mean: 0.17692518300790114, Cos Sim Std: 0.011735308798953226, MSE Mean: 0.21866237729950724, MSE Std: 0.014979433319111663, Training Time: 0:00:04.347545, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10177, Cos Sim Mean: 0.17692518722854797, Cos Sim Std: 0.011735312288162533, MSE Mean: 0.15863578808017034, MSE Std: 0.0060440441992102405, Training Time: 0:00:04.870369, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10178, Cos Sim Mean: 0.17692519011318858, Cos Sim Std: 0.011735305017678733, MSE Mean: 0.17507041058501643, MSE Std: 0.002347926588349233, Training Time: 0:00:04.849733, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10179, Cos Sim Mean: 0.17692517810238612, Cos Sim Std: 0.011735312470613851, MSE Mean: 0.2996022058125579, MSE Std: 0.02736904648047412, Training Time: 0:00:04.903259, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10180, Cos Sim Mean: 0.4101173545906992, Cos Sim Std: 0.051045627674876894, MSE Mean: 0.15129936103593838, MSE Std: 0.00939133003897786, Training Time: 0:00:02.347888, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10181, Cos Sim Mean: 0.356016959119247, Cos Sim Std: 0.0679427970281883, MSE Mean: 0.16410684827151253, MSE Std: 0.008367840791337709, Training Time: 0:00:02.288044, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10182, Cos Sim Mean: 0.31355649459904644, Cos Sim Std: 0.10324112845173228, MSE Mean: 0.17470151777628223, MSE Std: 0.0066601255074266105, Training Time: 0:00:02.293940, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10183, Cos Sim Mean: 0.3800955061894872, Cos Sim Std: 0.02080058684516844, MSE Mean: 0.15766015959175253, MSE Std: 0.010357728784043653, Training Time: 0:00:02.367242, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10184, Cos Sim Mean: 0.3506740012745556, Cos Sim Std: 0.044964979246047136, MSE Mean: 0.1640026869558629, MSE Std: 0.006043470796841654, Training Time: 0:00:02.245320, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10185, Cos Sim Mean: 0.27785377909036263, Cos Sim Std: 0.11599661634098492, MSE Mean: 0.17949095668785048, MSE Std: 0.004833846440476726, Training Time: 0:00:02.274226, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10186, Cos Sim Mean: 0.3679924788635493, Cos Sim Std: 0.05125632529233173, MSE Mean: 0.15246242197612409, MSE Std: 0.013681913536908643, Training Time: 0:00:02.285918, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10187, Cos Sim Mean: 0.34688332584121506, Cos Sim Std: 0.06295590972023057, MSE Mean: 0.16091588743688184, MSE Std: 0.012869472717104879, Training Time: 0:00:02.280762, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10188, Cos Sim Mean: 0.2703873256128354, Cos Sim Std: 0.07818264007729211, MSE Mean: 0.17742487255766165, MSE Std: 0.01287955512201619, Training Time: 0:00:02.289376, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10189, Cos Sim Mean: 0.38069884502867113, Cos Sim Std: 0.06781187311955336, MSE Mean: 0.14254439677428746, MSE Std: 0.007066624823543643, Training Time: 0:00:02.742463, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10190, Cos Sim Mean: 0.3502897521902163, Cos Sim Std: 0.05520916725092246, MSE Mean: 0.15124976076990787, MSE Std: 0.003879418619486559, Training Time: 0:00:02.767297, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10191, Cos Sim Mean: 0.2888879713952256, Cos Sim Std: 0.04391964772999094, MSE Mean: 0.17081970926373127, MSE Std: 0.006080525805835021, Training Time: 0:00:02.798223, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10192, Cos Sim Mean: 0.39096801773227685, Cos Sim Std: 0.046134361749120396, MSE Mean: 0.14523037863034852, MSE Std: 0.004180617463579685, Training Time: 0:00:02.799782, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10193, Cos Sim Mean: 0.33407079428593295, Cos Sim Std: 0.07110520575448578, MSE Mean: 0.1571469326142847, MSE Std: 0.002948659918379357, Training Time: 0:00:02.725444, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10194, Cos Sim Mean: 0.2310301937582518, Cos Sim Std: 0.02928815118883585, MSE Mean: 0.1790128700416696, MSE Std: 0.004212764279096271, Training Time: 0:00:02.816372, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10195, Cos Sim Mean: 0.40312938588100344, Cos Sim Std: 0.04007432673086214, MSE Mean: 0.1479657686818219, MSE Std: 0.005606443976951296, Training Time: 0:00:02.795958, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10196, Cos Sim Mean: 0.2680029331236984, Cos Sim Std: 0.03671849284894485, MSE Mean: 0.16687175841949276, MSE Std: 0.007967503901805624, Training Time: 0:00:02.735802, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10197, Cos Sim Mean: 0.176925186311166, Cos Sim Std: 0.011735311046327093, MSE Mean: 0.1830339258902136, MSE Std: 0.007830690560622355, Training Time: 0:00:02.632608, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10198, Cos Sim Mean: 0.41879061505403825, Cos Sim Std: 0.052851247167952475, MSE Mean: 0.14576583780381908, MSE Std: 0.005241688531120326, Training Time: 0:00:02.710653, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10199, Cos Sim Mean: 0.1994443134162577, Cos Sim Std: 0.023990529523554103, MSE Mean: 0.15995357378757416, MSE Std: 0.005995867978666373, Training Time: 0:00:02.696170, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10200, Cos Sim Mean: 0.17692518532280774, Cos Sim Std: 0.011735312928172011, MSE Mean: 0.17079910758576802, MSE Std: 0.00798955351655704, Training Time: 0:00:02.678959, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10201, Cos Sim Mean: 0.3798984172518828, Cos Sim Std: 0.03457662679499494, MSE Mean: 0.1509187247458737, MSE Std: 0.0032843320928981935, Training Time: 0:00:02.692150, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10202, Cos Sim Mean: 0.17692518533472998, Cos Sim Std: 0.011735310611996841, MSE Mean: 0.16223223233078898, MSE Std: 0.006200236090949143, Training Time: 0:00:02.681616, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10203, Cos Sim Mean: 0.17692518705822083, Cos Sim Std: 0.011735311013253813, MSE Mean: 0.17884016711916237, MSE Std: 0.006796703718948134, Training Time: 0:00:02.682568, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10204, Cos Sim Mean: 0.24888653984039583, Cos Sim Std: 0.08651873986598926, MSE Mean: 0.15823215622641215, MSE Std: 0.006649702469831367, Training Time: 0:00:02.671209, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10205, Cos Sim Mean: 0.17692518743588997, Cos Sim Std: 0.011735309833254335, MSE Mean: 0.1676795521977472, MSE Std: 0.008074139162665674, Training Time: 0:00:02.668767, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10206, Cos Sim Mean: 0.17692518809195973, Cos Sim Std: 0.011735310477530889, MSE Mean: 0.1903331981602184, MSE Std: 0.012565696934310937, Training Time: 0:00:02.673715, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10207, Cos Sim Mean: 0.17692518152180187, Cos Sim Std: 0.011735301915700538, MSE Mean: 0.1550067293780776, MSE Std: 0.006367730671365293, Training Time: 0:00:03.382225, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10208, Cos Sim Mean: 0.17692517719249962, Cos Sim Std: 0.011735310990322765, MSE Mean: 0.15528625061362233, MSE Std: 0.006418945350576046, Training Time: 0:00:03.343356, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10209, Cos Sim Mean: 0.17692518480486624, Cos Sim Std: 0.01173530889277528, MSE Mean: 0.16046233721209108, MSE Std: 0.006954879946748703, Training Time: 0:00:03.352424, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10210, Cos Sim Mean: 0.17692518915816766, Cos Sim Std: 0.01173531011181725, MSE Mean: 0.1551395117524787, MSE Std: 0.0063171677457988795, Training Time: 0:00:03.357520, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10211, Cos Sim Mean: 0.17692518664479584, Cos Sim Std: 0.011735310317321291, MSE Mean: 0.15619027817415904, MSE Std: 0.00606451346624367, Training Time: 0:00:03.373432, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10212, Cos Sim Mean: 0.1769251874212026, Cos Sim Std: 0.011735310526498358, MSE Mean: 0.16903054750531407, MSE Std: 0.004559500546182659, Training Time: 0:00:03.355517, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10213, Cos Sim Mean: 0.1769251879994764, Cos Sim Std: 0.011735309833600355, MSE Mean: 0.15609581048129756, MSE Std: 0.006510286729995882, Training Time: 0:00:03.664739, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10214, Cos Sim Mean: 0.17692518633293897, Cos Sim Std: 0.011735306692710935, MSE Mean: 0.16101388379123965, MSE Std: 0.007113509702082074, Training Time: 0:00:03.340165, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10215, Cos Sim Mean: 0.1769251875489977, Cos Sim Std: 0.011735313508876032, MSE Mean: 0.18916548631139704, MSE Std: 0.017400691346946797, Training Time: 0:00:03.331470, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10216, Cos Sim Mean: 0.17692518497259707, Cos Sim Std: 0.011735306637378776, MSE Mean: 0.15494920975845194, MSE Std: 0.006402681430795098, Training Time: 0:00:06.212637, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10217, Cos Sim Mean: 0.17692518150840802, Cos Sim Std: 0.011735317636065539, MSE Mean: 0.15495746278846004, MSE Std: 0.006393312290748737, Training Time: 0:00:06.006222, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10218, Cos Sim Mean: 0.17692517905259433, Cos Sim Std: 0.011735317836861625, MSE Mean: 0.15629667011576603, MSE Std: 0.006529161112109777, Training Time: 0:00:06.037637, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10219, Cos Sim Mean: 0.17692518664479584, Cos Sim Std: 0.011735310317321291, MSE Mean: 0.1549544247617022, MSE Std: 0.006398111367696722, Training Time: 0:00:06.095919, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10220, Cos Sim Mean: 0.17692518933353485, Cos Sim Std: 0.011735305093655815, MSE Mean: 0.1549910118557136, MSE Std: 0.006391599543564396, Training Time: 0:00:05.982108, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10221, Cos Sim Mean: 0.17692518441089505, Cos Sim Std: 0.011735313665039564, MSE Mean: 0.16024983917135036, MSE Std: 0.006176490750560542, Training Time: 0:00:05.891133, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10222, Cos Sim Mean: 0.17692519000587817, Cos Sim Std: 0.011735310815501594, MSE Mean: 0.154960478529927, MSE Std: 0.006391156870917886, Training Time: 0:00:06.294282, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10223, Cos Sim Mean: 0.17692518189752324, Cos Sim Std: 0.011735313870542524, MSE Mean: 0.15549711394080595, MSE Std: 0.006302470677165632, Training Time: 0:00:06.232384, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10224, Cos Sim Mean: 0.17692518570737245, Cos Sim Std: 0.011735305390141643, MSE Mean: 0.1773972871966551, MSE Std: 0.00736336555638494, Training Time: 0:00:05.929117, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10225, Cos Sim Mean: 0.3067497087698584, Cos Sim Std: 0.07531441661249055, MSE Mean: 0.21775898313395384, MSE Std: 0.01274389354419169, Training Time: 0:00:01.249959, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10226, Cos Sim Mean: 0.3170708924932731, Cos Sim Std: 0.039179547871394556, MSE Mean: 0.22977430577606142, MSE Std: 0.00661610574638337, Training Time: 0:00:01.298902, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10227, Cos Sim Mean: 0.2475238487377978, Cos Sim Std: 0.06993494294826628, MSE Mean: 0.24343624061356972, MSE Std: 0.007577630761002038, Training Time: 0:00:01.302095, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10228, Cos Sim Mean: 0.3451042507391829, Cos Sim Std: 0.036947057211234376, MSE Mean: 0.2169668671274713, MSE Std: 0.00945522131351721, Training Time: 0:00:01.292744, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10229, Cos Sim Mean: 0.28617491782094, Cos Sim Std: 0.0618462100662101, MSE Mean: 0.22267278155739795, MSE Std: 0.009535024796687995, Training Time: 0:00:01.300711, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10230, Cos Sim Mean: 0.30474361421230556, Cos Sim Std: 0.035864935255105555, MSE Mean: 0.24492574065367606, MSE Std: 0.010244741479391056, Training Time: 0:00:01.268859, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10231, Cos Sim Mean: 0.32759120127476554, Cos Sim Std: 0.04991740571536069, MSE Mean: 0.20131507280223498, MSE Std: 0.01811728696137267, Training Time: 0:00:01.315748, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10232, Cos Sim Mean: 0.2923644133960538, Cos Sim Std: 0.03181008315797256, MSE Mean: 0.2161052302170836, MSE Std: 0.01567391146528077, Training Time: 0:00:01.302470, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10233, Cos Sim Mean: 0.24890117103858075, Cos Sim Std: 0.06278801990689299, MSE Mean: 0.23650801567741642, MSE Std: 0.018137233756739216, Training Time: 0:00:01.292836, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10234, Cos Sim Mean: 0.3650087086315782, Cos Sim Std: 0.07374675504548657, MSE Mean: 0.17241656117515855, MSE Std: 0.006080397008020113, Training Time: 0:00:01.597967, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10235, Cos Sim Mean: 0.27536976169863053, Cos Sim Std: 0.0728140891366119, MSE Mean: 0.19958589225988868, MSE Std: 0.0060636247030627505, Training Time: 0:00:01.593384, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10236, Cos Sim Mean: 0.20824190514808533, Cos Sim Std: 0.020481908364595056, MSE Mean: 0.24827160488725736, MSE Std: 0.006029765725468878, Training Time: 0:00:01.591847, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10237, Cos Sim Mean: 0.34533005679671325, Cos Sim Std: 0.03537171553440231, MSE Mean: 0.18452721738106453, MSE Std: 0.0019097998266832412, Training Time: 0:00:01.607822, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10238, Cos Sim Mean: 0.2816195173612001, Cos Sim Std: 0.04257091719595951, MSE Mean: 0.21477609535808248, MSE Std: 0.0073013696773080155, Training Time: 0:00:01.595564, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10239, Cos Sim Mean: 0.17692518799110377, Cos Sim Std: 0.011735311897598903, MSE Mean: 0.263510892872293, MSE Std: 0.008591845505392215, Training Time: 0:00:01.596264, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10240, Cos Sim Mean: 0.2930041585281872, Cos Sim Std: 0.04999179976150794, MSE Mean: 0.1969591272121661, MSE Std: 0.012864930686893417, Training Time: 0:00:01.592235, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10241, Cos Sim Mean: 0.20173603348093572, Cos Sim Std: 0.04172347781093082, MSE Mean: 0.22462525776386602, MSE Std: 0.014618026462774969, Training Time: 0:00:01.601300, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10242, Cos Sim Mean: 0.1769251878861405, Cos Sim Std: 0.011735311244563474, MSE Mean: 0.25764590498637036, MSE Std: 0.015838240203067077, Training Time: 0:00:01.600386, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10243, Cos Sim Mean: 0.36969457872498873, Cos Sim Std: 0.03862360015734755, MSE Mean: 0.1681658953606494, MSE Std: 0.006804640207489595, Training Time: 0:00:01.908652, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10244, Cos Sim Mean: 0.1942269252140596, Cos Sim Std: 0.01644123397021028, MSE Mean: 0.19360165152075495, MSE Std: 0.010659509175195534, Training Time: 0:00:01.855791, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10245, Cos Sim Mean: 0.17692518740320687, Cos Sim Std: 0.011735313150693535, MSE Mean: 0.25948172360021815, MSE Std: 0.02060281018780076, Training Time: 0:00:01.864718, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10246, Cos Sim Mean: 0.32031746208883666, Cos Sim Std: 0.02574272952969264, MSE Mean: 0.1783288754731947, MSE Std: 0.009529556796077938, Training Time: 0:00:01.893353, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10247, Cos Sim Mean: 0.1769251884190677, Cos Sim Std: 0.01173531051169121, MSE Mean: 0.2115081255580325, MSE Std: 0.011824594266626087, Training Time: 0:00:01.879387, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10248, Cos Sim Mean: 0.17692518845415622, Cos Sim Std: 0.011735310790545638, MSE Mean: 0.2862651803318903, MSE Std: 0.014303806761118622, Training Time: 0:00:01.868382, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10249, Cos Sim Mean: 0.22776269947528646, Cos Sim Std: 0.05726202580379189, MSE Mean: 0.19501409300783307, MSE Std: 0.012726025216277546, Training Time: 0:00:01.883540, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10250, Cos Sim Mean: 0.1769251883098712, Cos Sim Std: 0.011735311478817803, MSE Mean: 0.22980140338823976, MSE Std: 0.017912536183241925, Training Time: 0:00:01.883641, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10251, Cos Sim Mean: 0.1769251890403906, Cos Sim Std: 0.011735312784098647, MSE Mean: 0.2990474291410118, MSE Std: 0.02592071090139162, Training Time: 0:00:01.874793, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10252, Cos Sim Mean: 0.17692518445930563, Cos Sim Std: 0.01173531436087621, MSE Mean: 0.15689849320731214, MSE Std: 0.006048445225261106, Training Time: 0:00:02.350408, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10253, Cos Sim Mean: 0.17692518807063212, Cos Sim Std: 0.011735310988794894, MSE Mean: 0.16322167284537942, MSE Std: 0.006423655317606875, Training Time: 0:00:02.339540, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10254, Cos Sim Mean: 0.17692518852819983, Cos Sim Std: 0.011735311572344859, MSE Mean: 0.21498509003308852, MSE Std: 0.013566580129634373, Training Time: 0:00:02.346241, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10255, Cos Sim Mean: 0.17692518727784065, Cos Sim Std: 0.011735308537029695, MSE Mean: 0.16099550061149934, MSE Std: 0.0054501462144374724, Training Time: 0:00:02.347219, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10256, Cos Sim Mean: 0.17692518826627357, Cos Sim Std: 0.011735314465210034, MSE Mean: 0.17680347686301057, MSE Std: 0.0030565532336693925, Training Time: 0:00:02.346794, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10257, Cos Sim Mean: 0.17692518570948754, Cos Sim Std: 0.011735312333783863, MSE Mean: 0.263978081489425, MSE Std: 0.012611461702232409, Training Time: 0:00:02.409068, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10258, Cos Sim Mean: 0.17692518762045245, Cos Sim Std: 0.0117353128802271, MSE Mean: 0.17526476634821558, MSE Std: 0.011436519497752064, Training Time: 0:00:02.325422, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10259, Cos Sim Mean: 0.1769251870422453, Cos Sim Std: 0.011735309848466553, MSE Mean: 0.21170292663303458, MSE Std: 0.019735866567126958, Training Time: 0:00:02.350182, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10260, Cos Sim Mean: 0.17692518957768602, Cos Sim Std: 0.01173531119897653, MSE Mean: 0.3226171462284675, MSE Std: 0.041392187292219884, Training Time: 0:00:02.352770, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10261, Cos Sim Mean: 0.17692518344923577, Cos Sim Std: 0.011735305562544814, MSE Mean: 0.15496116763732032, MSE Std: 0.006394641258493545, Training Time: 0:00:03.961754, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10262, Cos Sim Mean: 0.1769251890279248, Cos Sim Std: 0.011735311150136396, MSE Mean: 0.1553944523018418, MSE Std: 0.006281677449287564, Training Time: 0:00:04.006274, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10263, Cos Sim Mean: 0.17692518936482066, Cos Sim Std: 0.011735310689213518, MSE Mean: 0.1861603578175331, MSE Std: 0.010502420480832731, Training Time: 0:00:03.994391, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10264, Cos Sim Mean: 0.17692518007995367, Cos Sim Std: 0.011735304792685588, MSE Mean: 0.1550764211282035, MSE Std: 0.006374776543529578, Training Time: 0:00:04.024603, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10265, Cos Sim Mean: 0.1769251838744853, Cos Sim Std: 0.011735307997828693, MSE Mean: 0.15724450942371743, MSE Std: 0.0065763996648194566, Training Time: 0:00:04.199651, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10266, Cos Sim Mean: 0.17692519063080936, Cos Sim Std: 0.011735311965222307, MSE Mean: 0.2282660512172284, MSE Std: 0.01834587207421521, Training Time: 0:00:04.000903, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10267, Cos Sim Mean: 0.17692517465856222, Cos Sim Std: 0.011735309611895194, MSE Mean: 0.15898136212121727, MSE Std: 0.006154676180080197, Training Time: 0:00:04.180256, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10268, Cos Sim Mean: 0.17692518378472405, Cos Sim Std: 0.011735309429446507, MSE Mean: 0.17669535811830606, MSE Std: 0.0054064789537865065, Training Time: 0:00:03.919907, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10269, Cos Sim Mean: 0.17692518936482066, Cos Sim Std: 0.011735310689213518, MSE Mean: 0.3154294305448774, MSE Std: 0.026904731513917354, Training Time: 0:00:04.321180, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10270, Cos Sim Mean: 0.33089470774373597, Cos Sim Std: 0.0553593313594824, MSE Mean: 0.15927573482652088, MSE Std: 0.007559484780254168, Training Time: 0:00:01.936664, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10271, Cos Sim Mean: 0.2614115168865445, Cos Sim Std: 0.04686028316939309, MSE Mean: 0.17020241964677404, MSE Std: 0.004211740877063123, Training Time: 0:00:01.914308, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10272, Cos Sim Mean: 0.1904081985816768, Cos Sim Std: 0.12321859884410827, MSE Mean: 0.18485012863701303, MSE Std: 0.005719373066378413, Training Time: 0:00:01.887074, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10273, Cos Sim Mean: 0.3182762724133574, Cos Sim Std: 0.0774542090802513, MSE Mean: 0.16328418758857452, MSE Std: 0.010480399639670715, Training Time: 0:00:01.881269, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10274, Cos Sim Mean: 0.24373291642302922, Cos Sim Std: 0.08773703509431144, MSE Mean: 0.17462172110920612, MSE Std: 0.008261023084155035, Training Time: 0:00:01.882872, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10275, Cos Sim Mean: 0.20557302244522918, Cos Sim Std: 0.11561613911746348, MSE Mean: 0.19006621104499338, MSE Std: 0.010439833994375213, Training Time: 0:00:01.904348, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10276, Cos Sim Mean: 0.2940827772425514, Cos Sim Std: 0.07085725220002626, MSE Mean: 0.17025146818132697, MSE Std: 0.01356341451869355, Training Time: 0:00:01.874480, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10277, Cos Sim Mean: 0.2787056535806812, Cos Sim Std: 0.08122288672872763, MSE Mean: 0.18119786850363614, MSE Std: 0.01205535247537851, Training Time: 0:00:01.879869, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10278, Cos Sim Mean: 0.22566684338627968, Cos Sim Std: 0.09015410905209455, MSE Mean: 0.1953315909836441, MSE Std: 0.013028809309537669, Training Time: 0:00:01.901381, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10279, Cos Sim Mean: 0.3515389738666649, Cos Sim Std: 0.06732319692547684, MSE Mean: 0.14537381175591, MSE Std: 0.007842986388108018, Training Time: 0:00:02.270430, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10280, Cos Sim Mean: 0.35674309107331525, Cos Sim Std: 0.0739256027374992, MSE Mean: 0.15968194944985728, MSE Std: 0.005216032652513927, Training Time: 0:00:02.309376, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10281, Cos Sim Mean: 0.22749771433121765, Cos Sim Std: 0.02160151333449251, MSE Mean: 0.18267302199771712, MSE Std: 0.006137634951009345, Training Time: 0:00:02.296312, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10282, Cos Sim Mean: 0.341201167389524, Cos Sim Std: 0.052389981380637184, MSE Mean: 0.14950782174923355, MSE Std: 0.005346579711148971, Training Time: 0:00:02.264751, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10283, Cos Sim Mean: 0.29575968271416675, Cos Sim Std: 0.05721594714897776, MSE Mean: 0.16822007462954874, MSE Std: 0.005566993723587177, Training Time: 0:00:02.277864, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10284, Cos Sim Mean: 0.18404416599980325, Cos Sim Std: 0.026495970687805286, MSE Mean: 0.19241551305549637, MSE Std: 0.00607857710698353, Training Time: 0:00:02.287730, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10285, Cos Sim Mean: 0.3288704984829174, Cos Sim Std: 0.043906859757455764, MSE Mean: 0.16325504935251542, MSE Std: 0.007658983237962613, Training Time: 0:00:02.236508, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10286, Cos Sim Mean: 0.1928543901329734, Cos Sim Std: 0.02954393659562412, MSE Mean: 0.1810267586773884, MSE Std: 0.007553560223243021, Training Time: 0:00:02.284084, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10287, Cos Sim Mean: 0.17692518620303702, Cos Sim Std: 0.011735308980481918, MSE Mean: 0.2013593461646467, MSE Std: 0.010843408879370686, Training Time: 0:00:02.278759, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10288, Cos Sim Mean: 0.3621337987518342, Cos Sim Std: 0.05997665450729755, MSE Mean: 0.1464986243185888, MSE Std: 0.006294346340384226, Training Time: 0:00:02.629780, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10289, Cos Sim Mean: 0.1769251868689355, Cos Sim Std: 0.011735312654123304, MSE Mean: 0.1630106436553102, MSE Std: 0.006803156638297291, Training Time: 0:00:02.628205, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10290, Cos Sim Mean: 0.17692518652339495, Cos Sim Std: 0.011735311580510737, MSE Mean: 0.1800545207866075, MSE Std: 0.008813223896310169, Training Time: 0:00:02.629714, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10291, Cos Sim Mean: 0.31284040957824333, Cos Sim Std: 0.07862074403674353, MSE Mean: 0.155215851205106, MSE Std: 0.008588675941855755, Training Time: 0:00:02.622898, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10292, Cos Sim Mean: 0.1769251893656943, Cos Sim Std: 0.011735311155403811, MSE Mean: 0.16807612883182457, MSE Std: 0.007470508534038048, Training Time: 0:00:02.633499, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10293, Cos Sim Mean: 0.1769251876788976, Cos Sim Std: 0.011735314167579032, MSE Mean: 0.19255514511627203, MSE Std: 0.01088710543336558, Training Time: 0:00:02.623296, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10294, Cos Sim Mean: 0.17514740783517307, Cos Sim Std: 0.010757471153314902, MSE Mean: 0.16819419555489115, MSE Std: 0.0070519677585682596, Training Time: 0:00:02.622337, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10295, Cos Sim Mean: 0.17692518796842469, Cos Sim Std: 0.011735311864593418, MSE Mean: 0.1815727209479735, MSE Std: 0.010643577645162602, Training Time: 0:00:02.605971, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10296, Cos Sim Mean: 0.17692518722208195, Cos Sim Std: 0.011735312867329662, MSE Mean: 0.21476371846073947, MSE Std: 0.015727806476467255, Training Time: 0:00:02.641464, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10297, Cos Sim Mean: 0.17692517805761282, Cos Sim Std: 0.011735312914390708, MSE Mean: 0.1550944275147421, MSE Std: 0.006369303333507703, Training Time: 0:00:03.345416, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10298, Cos Sim Mean: 0.17692518143066283, Cos Sim Std: 0.011735317742432326, MSE Mean: 0.15595998041799158, MSE Std: 0.006401410534663963, Training Time: 0:00:03.294512, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10299, Cos Sim Mean: 0.17692518905035826, Cos Sim Std: 0.011735309175678157, MSE Mean: 0.1651974860997883, MSE Std: 0.0071775533907234255, Training Time: 0:00:03.283290, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10300, Cos Sim Mean: 0.1769251828048854, Cos Sim Std: 0.011735309361170737, MSE Mean: 0.15549711267508376, MSE Std: 0.006305378428963038, Training Time: 0:00:03.278812, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10301, Cos Sim Mean: 0.17692518857794545, Cos Sim Std: 0.011735310546099626, MSE Mean: 0.15824780111851303, MSE Std: 0.006255403176374596, Training Time: 0:00:03.299857, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10302, Cos Sim Mean: 0.17692518738128946, Cos Sim Std: 0.011735309387300415, MSE Mean: 0.17643215613305419, MSE Std: 0.007739635929157998, Training Time: 0:00:03.294523, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10303, Cos Sim Mean: 0.17692518549902897, Cos Sim Std: 0.011735311688781636, MSE Mean: 0.15805136723844138, MSE Std: 0.0073930607695257165, Training Time: 0:00:03.252679, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10304, Cos Sim Mean: 0.17692518366385515, Cos Sim Std: 0.011735305098465992, MSE Mean: 0.16818208243845975, MSE Std: 0.008821929071788625, Training Time: 0:00:03.282150, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10305, Cos Sim Mean: 0.1769251863870662, Cos Sim Std: 0.011735308559473379, MSE Mean: 0.2151789777972465, MSE Std: 0.021023253752801185, Training Time: 0:00:03.276957, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10306, Cos Sim Mean: 0.17692518619812247, Cos Sim Std: 0.011735314087551761, MSE Mean: 0.15495151941897653, MSE Std: 0.006396038448585956, Training Time: 0:00:05.969910, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10307, Cos Sim Mean: 0.17692518245922523, Cos Sim Std: 0.01173530684288198, MSE Mean: 0.15498262483723546, MSE Std: 0.006387145771078235, Training Time: 0:00:06.101017, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10308, Cos Sim Mean: 0.17692519272677193, Cos Sim Std: 0.011735309820036581, MSE Mean: 0.15806390948893784, MSE Std: 0.005969251187778018, Training Time: 0:00:05.883547, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10309, Cos Sim Mean: 0.17692518617793543, Cos Sim Std: 0.011735314189212453, MSE Mean: 0.15495139408292072, MSE Std: 0.006397561340792553, Training Time: 0:00:06.153327, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10310, Cos Sim Mean: 0.1769251755194777, Cos Sim Std: 0.011735313270239424, MSE Mean: 0.15508767200247542, MSE Std: 0.006401076708296615, Training Time: 0:00:06.275274, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10311, Cos Sim Mean: 0.17692518319400063, Cos Sim Std: 0.011735305595645028, MSE Mean: 0.16298694666039473, MSE Std: 0.007332369745761605, Training Time: 0:00:06.369960, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10312, Cos Sim Mean: 0.17692518915816766, Cos Sim Std: 0.01173531011181725, MSE Mean: 0.1549726553232543, MSE Std: 0.006396835152834157, Training Time: 0:00:06.331337, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10313, Cos Sim Mean: 0.17692518441089505, Cos Sim Std: 0.011735313665039564, MSE Mean: 0.15649872506189097, MSE Std: 0.006203991045176119, Training Time: 0:00:06.356685, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10314, Cos Sim Mean: 0.17692518441089505, Cos Sim Std: 0.011735313665039564, MSE Mean: 0.18862323764286737, MSE Std: 0.010679911701450048, Training Time: 0:00:06.352356, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10315, Cos Sim Mean: 0.2661147596846064, Cos Sim Std: 0.07852467649789034, MSE Mean: 0.21969247439847067, MSE Std: 0.009121032335015383, Training Time: 0:00:01.648021, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10316, Cos Sim Mean: 0.23492110240920874, Cos Sim Std: 0.1196594483766993, MSE Mean: 0.2280398214716819, MSE Std: 0.008423417185635227, Training Time: 0:00:01.516803, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10317, Cos Sim Mean: 0.22928013539930978, Cos Sim Std: 0.11674084254723474, MSE Mean: 0.24618940929405325, MSE Std: 0.006743476560680701, Training Time: 0:00:01.535056, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10318, Cos Sim Mean: 0.28050901033155073, Cos Sim Std: 0.09406442151164342, MSE Mean: 0.21926992063306616, MSE Std: 0.010111877569191638, Training Time: 0:00:01.586376, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10319, Cos Sim Mean: 0.2503225695544901, Cos Sim Std: 0.11151814562926807, MSE Mean: 0.23075812852642974, MSE Std: 0.011481588027840753, Training Time: 0:00:01.517517, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10320, Cos Sim Mean: 0.2311609272383893, Cos Sim Std: 0.08678823975017368, MSE Mean: 0.2503282824849701, MSE Std: 0.011290572222816113, Training Time: 0:00:01.547034, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10321, Cos Sim Mean: 0.2709422687287407, Cos Sim Std: 0.07915529329283709, MSE Mean: 0.22747461708170552, MSE Std: 0.016717533045881687, Training Time: 0:00:01.556014, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10322, Cos Sim Mean: 0.24219986653688702, Cos Sim Std: 0.11405216693151882, MSE Mean: 0.2382824376999594, MSE Std: 0.014619530250025168, Training Time: 0:00:01.534506, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10323, Cos Sim Mean: 0.18981681299398528, Cos Sim Std: 0.09158204011072278, MSE Mean: 0.25545448705372087, MSE Std: 0.016037145861340734, Training Time: 0:00:01.561222, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10324, Cos Sim Mean: 0.31352012309724187, Cos Sim Std: 0.08138996185546515, MSE Mean: 0.19081923731925005, MSE Std: 0.001070650796011439, Training Time: 0:00:01.864890, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10325, Cos Sim Mean: 0.27101109322859857, Cos Sim Std: 0.10437692913028628, MSE Mean: 0.21962367498738064, MSE Std: 0.006010089729521123, Training Time: 0:00:01.848721, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10326, Cos Sim Mean: 0.18929951968058137, Cos Sim Std: 0.01423343726605615, MSE Mean: 0.26851779977248674, MSE Std: 0.011089487457646334, Training Time: 0:00:01.894895, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10327, Cos Sim Mean: 0.3012435102920372, Cos Sim Std: 0.049629625360239356, MSE Mean: 0.20070826101287, MSE Std: 0.007897221921168818, Training Time: 0:00:01.828453, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10328, Cos Sim Mean: 0.29770893837492257, Cos Sim Std: 0.06886475500748616, MSE Mean: 0.23529351391009495, MSE Std: 0.008500596952327568, Training Time: 0:00:01.572377, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10329, Cos Sim Mean: 0.17692518889613312, Cos Sim Std: 0.011735310713032453, MSE Mean: 0.28668188029568203, MSE Std: 0.011911769605659282, Training Time: 0:00:01.945898, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10330, Cos Sim Mean: 0.22605115499498263, Cos Sim Std: 0.03703907055338741, MSE Mean: 0.2230329120203654, MSE Std: 0.012145975695671357, Training Time: 0:00:01.823163, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10331, Cos Sim Mean: 0.18575921916765736, Cos Sim Std: 0.016051340369661982, MSE Mean: 0.24999289823471518, MSE Std: 0.013405671060949502, Training Time: 0:00:01.852551, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10332, Cos Sim Mean: 0.17692518785398575, Cos Sim Std: 0.011735311337848801, MSE Mean: 0.2880812256467386, MSE Std: 0.015135606212240332, Training Time: 0:00:01.977238, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10333, Cos Sim Mean: 0.2834246843881682, Cos Sim Std: 0.026698049450098925, MSE Mean: 0.17676789438449253, MSE Std: 0.007933442936518714, Training Time: 0:00:02.273744, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10334, Cos Sim Mean: 0.1769251877780475, Cos Sim Std: 0.011735310157621857, MSE Mean: 0.21045595596531244, MSE Std: 0.013443298774054212, Training Time: 0:00:02.197810, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10335, Cos Sim Mean: 0.1769251878651055, Cos Sim Std: 0.011735310730479932, MSE Mean: 0.2839458514557337, MSE Std: 0.02085739970250868, Training Time: 0:00:02.215711, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10336, Cos Sim Mean: 0.2514392762823654, Cos Sim Std: 0.06971959357917372, MSE Mean: 0.19597215333369264, MSE Std: 0.013337625419718474, Training Time: 0:00:02.224086, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10337, Cos Sim Mean: 0.17692518944132754, Cos Sim Std: 0.01173531401744804, MSE Mean: 0.23467867557509262, MSE Std: 0.01574851564035736, Training Time: 0:00:02.221833, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10338, Cos Sim Mean: 0.1769251881172604, Cos Sim Std: 0.011735311251468547, MSE Mean: 0.32125532411800756, MSE Std: 0.018925488270841083, Training Time: 0:00:02.231001, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10339, Cos Sim Mean: 0.1769251865606035, Cos Sim Std: 0.011735314525586734, MSE Mean: 0.2261455167391302, MSE Std: 0.01685309723072211, Training Time: 0:00:02.218354, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10340, Cos Sim Mean: 0.1769251863613602, Cos Sim Std: 0.011735311395387965, MSE Mean: 0.2711240438552343, MSE Std: 0.021183524267693453, Training Time: 0:00:02.217197, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10341, Cos Sim Mean: 0.17692518715703512, Cos Sim Std: 0.011735312262707123, MSE Mean: 0.34953110305449486, MSE Std: 0.03062090962742065, Training Time: 0:00:02.223262, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10342, Cos Sim Mean: 0.1769251885873048, Cos Sim Std: 0.011735311544052272, MSE Mean: 0.15838385665762397, MSE Std: 0.005912351953578601, Training Time: 0:00:02.785870, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10343, Cos Sim Mean: 0.17692518364889548, Cos Sim Std: 0.0117353146517413, MSE Mean: 0.17007102169770127, MSE Std: 0.0066796455015953795, Training Time: 0:00:02.838628, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10344, Cos Sim Mean: 0.17692518811355884, Cos Sim Std: 0.01173531213963455, MSE Mean: 0.24096660760192612, MSE Std: 0.013533743781846056, Training Time: 0:00:02.809903, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10345, Cos Sim Mean: 0.17692518411314379, Cos Sim Std: 0.011735311113977843, MSE Mean: 0.1657508590564284, MSE Std: 0.006096648350919483, Training Time: 0:00:02.704934, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10346, Cos Sim Mean: 0.17692518449013978, Cos Sim Std: 0.011735310965662403, MSE Mean: 0.19125598394029036, MSE Std: 0.006447449791625245, Training Time: 0:00:02.627923, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10347, Cos Sim Mean: 0.176925189116655, Cos Sim Std: 0.011735311816934, MSE Mean: 0.3019526399043123, MSE Std: 0.009830996819649713, Training Time: 0:00:02.828611, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10348, Cos Sim Mean: 0.1769251847110665, Cos Sim Std: 0.011735312225090952, MSE Mean: 0.19080475658992907, MSE Std: 0.016510480108881887, Training Time: 0:00:02.823178, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10349, Cos Sim Mean: 0.17692518379696826, Cos Sim Std: 0.011735307875188283, MSE Mean: 0.24413847444222983, MSE Std: 0.02530042718456537, Training Time: 0:00:02.822086, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10350, Cos Sim Mean: 0.17692518512995897, Cos Sim Std: 0.01173531289452902, MSE Mean: 0.3900424941025221, MSE Std: 0.05078971317143076, Training Time: 0:00:02.841858, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10351, Cos Sim Mean: 0.17692518205192329, Cos Sim Std: 0.011735302536495679, MSE Mean: 0.15498501580779236, MSE Std: 0.006386619794865798, Training Time: 0:00:04.565371, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10352, Cos Sim Mean: 0.17692518936482066, Cos Sim Std: 0.011735310689213518, MSE Mean: 0.1560329102752115, MSE Std: 0.0062199021321512945, Training Time: 0:00:04.605998, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10353, Cos Sim Mean: 0.17692518592099674, Cos Sim Std: 0.01173530783049773, MSE Mean: 0.2016954713805404, MSE Std: 0.0072574877922717326, Training Time: 0:00:04.604897, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10354, Cos Sim Mean: 0.1769251824127942, Cos Sim Std: 0.011735314528206822, MSE Mean: 0.15517983590462123, MSE Std: 0.006417217641810015, Training Time: 0:00:04.599882, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10355, Cos Sim Mean: 0.1769251854957472, Cos Sim Std: 0.011735305395213893, MSE Mean: 0.15907542244885273, MSE Std: 0.007052058527603439, Training Time: 0:00:04.471492, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10356, Cos Sim Mean: 0.17692518689540307, Cos Sim Std: 0.011735315931216298, MSE Mean: 0.25364446801431095, MSE Std: 0.013244558438387868, Training Time: 0:00:04.451778, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10357, Cos Sim Mean: 0.17692518059023218, Cos Sim Std: 0.011735309066876622, MSE Mean: 0.16016220178930868, MSE Std: 0.006081496062170786, Training Time: 0:00:04.526643, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10358, Cos Sim Mean: 0.1769251868769746, Cos Sim Std: 0.011735314092952137, MSE Mean: 0.18854661408208817, MSE Std: 0.005919365892044052, Training Time: 0:00:04.642924, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10359, Cos Sim Mean: 0.17692518197145957, Cos Sim Std: 0.011735317764612722, MSE Mean: 0.381109136310608, MSE Std: 0.035673372565829274, Training Time: 0:00:04.652488, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n"
     ]
    }
   ],
   "source": [
    "kfold_id = 10000\n",
    "\n",
    "resumo = pd.DataFrame(columns=['kfold_id','cos_sim_mean','cos_sim_std','mse_mean','mse_std','training_time','batch_size','number_hidden','num_dense','dropout'])\n",
    "\n",
    "number_epochs = 30\n",
    "\n",
    "\n",
    "for emb_dim in [300, 200, 100, 50]:\n",
    "  \n",
    "  embeddings_index_kfold = load_embedding(emb_dim)\n",
    "\n",
    "  for batch_size in [32, 64]:\n",
    "           for number_hidden in [1, 2, 3, 5, 10]:\n",
    "              for number_dense in [150, 100, 50]:\n",
    "                  for dropout_value in [0.3, 0.4, 0.5]:\n",
    "\n",
    "                    cvscores_mse = []\n",
    "                    cvscores_cos_sim = []\n",
    "                    time_list = []\n",
    "                    \n",
    "                    seed = 42\n",
    "                    np.random.seed(seed)\n",
    "                    \n",
    "                    for train, val in skf.split(df_train, df_train['quantile']):\n",
    "#                         print(train)\n",
    "                        X_train = df_train.iloc[train]\n",
    "                        X_val = df_train.iloc[val]\n",
    "    \n",
    "                        Y_train = df_train['sentiment'].iloc[train]\n",
    "                        Y_val = df_train['sentiment'].iloc[val]\n",
    "                \n",
    "                        # get sentences ready for usage\n",
    "                        sentences_train_pad, sentences_val_pad, tok_kfold = get_tok_sentences(X_train[\"new_title\"], X_val[\"new_title\"])\n",
    "                  \n",
    "                        embedding_matrix = get_embedding_matrix(emb_dim, MAX_VOCAB_SIZE, MAX_SEQUENCE_LENGTH, tok_kfold, embeddings_index_kfold)\n",
    "                        \n",
    "#                         nn_input_train = {'Word_Seq': sentences_train_pad, 'Lexical': np.array(X_train['mean_VADER_LMD'].tolist())}\n",
    "#                         nn_input_val = {'Word_Seq': sentences_val_pad, 'Lexical': np.array(X_val['mean_VADER_LMD'].tolist())}\n",
    "                        nn_input_train = {'Word_Seq': sentences_train_pad, 'Lexical': np.array(X_train['mean_LMD'].tolist())}\n",
    "                        nn_input_val = {'Word_Seq': sentences_val_pad, 'Lexical': np.array(X_val['mean_LMD'].tolist())}\n",
    "\n",
    "                      \n",
    "                        model_name = 'kfoldid_' + str(kfold_id) + '-dim_' + str(emb_dim) + '-bs_' + str(batch_size) + '-nh_' + str(number_hidden) + '-nd_' + str(number_dense) + '-dv_' + str(10*dropout_value)\n",
    "                        \n",
    "                        if number_hidden == 1:\n",
    "                          ann = create_ANN_model_hidden_1(number_dense, dropout_value, embedding_matrix, True)\n",
    "                        elif number_hidden == 2:\n",
    "                          ann = create_ANN_model_hidden_2(number_dense, dropout_value, embedding_matrix, True)\n",
    "                        elif number_hidden == 3:\n",
    "                          ann = create_ANN_model_hidden_3(number_dense, dropout_value, embedding_matrix, True)\n",
    "                        elif number_hidden == 5:\n",
    "                          ann = create_ANN_model_hidden_5(number_dense, dropout_value, embedding_matrix, True)\n",
    "                        else:\n",
    "                          ann = create_ANN_model_hidden_10(number_dense, dropout_value, embedding_matrix, True)                              \n",
    "\n",
    "                        init = datetime.datetime.now()\n",
    "                        trained = train_model(ann, nn_input_train, Y_train, batch_size, number_epochs, model_name, nn_input_val, Y_val)\n",
    "                        training_time = (datetime.datetime.now() - init)\n",
    "                        cvscores_mse.append(trained.history['val_loss'][-1])\n",
    "                        cvscores_cos_sim.append(-trained.history['val_cosine_proximity'][-1])\n",
    "                        time_list.append(training_time)\n",
    "                        # save_model(ann, trained, model_name)\n",
    "                  \n",
    "                        if K.backend() == 'tensorflow':\n",
    "                          K.clear_session()\n",
    "\n",
    "                    result = [kfold_id, np.mean(cvscores_cos_sim), np.std(cvscores_cos_sim), np.mean(cvscores_mse), np.std(cvscores_mse), np.mean(time_list), batch_size, number_hidden, number_dense, dropout_value]\n",
    "                    resumo = resumo.append(pd.Series(result, index=resumo.columns), ignore_index=True)\n",
    "\n",
    "                    print('ID: {}, Cos Sim Mean: {}, Cos Sim Std: {}, MSE Mean: {}, MSE Std: {}, Training Time: {}, Batch: {}, Num Hidden: {}, Num Dense: {}, Dropout: {}'.format(*result))\n",
    "                    \n",
    "                    kfold_id = kfold_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1960
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5723109,
     "status": "ok",
     "timestamp": 1560543521787,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "2uxkO9P3wp8W",
    "outputId": "e29420df-358b-46c3-a263-309f5cee3f07"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kfold_id</th>\n",
       "      <th>cos_sim_mean</th>\n",
       "      <th>cos_sim_std</th>\n",
       "      <th>mse_mean</th>\n",
       "      <th>mse_std</th>\n",
       "      <th>training_time</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>number_hidden</th>\n",
       "      <th>num_dense</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10009</td>\n",
       "      <td>0.465855</td>\n",
       "      <td>0.031477</td>\n",
       "      <td>0.122334</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>00:00:02.728585</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.458835</td>\n",
       "      <td>0.026611</td>\n",
       "      <td>0.124075</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>00:00:02.265769</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10006</td>\n",
       "      <td>0.470949</td>\n",
       "      <td>0.032925</td>\n",
       "      <td>0.124404</td>\n",
       "      <td>0.013881</td>\n",
       "      <td>00:00:02.320909</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10012</td>\n",
       "      <td>0.448316</td>\n",
       "      <td>0.070094</td>\n",
       "      <td>0.124603</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>00:00:02.771600</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>0.478470</td>\n",
       "      <td>0.051760</td>\n",
       "      <td>0.125437</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>00:00:02.312797</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10015</td>\n",
       "      <td>0.443053</td>\n",
       "      <td>0.047780</td>\n",
       "      <td>0.126432</td>\n",
       "      <td>0.004865</td>\n",
       "      <td>00:00:02.739130</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10099</td>\n",
       "      <td>0.455773</td>\n",
       "      <td>0.050904</td>\n",
       "      <td>0.127267</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>00:00:02.943165</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10007</td>\n",
       "      <td>0.480098</td>\n",
       "      <td>0.029483</td>\n",
       "      <td>0.128062</td>\n",
       "      <td>0.006087</td>\n",
       "      <td>00:00:02.355577</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>10108</td>\n",
       "      <td>0.493999</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.128635</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>00:00:03.429914</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>0.464414</td>\n",
       "      <td>0.039840</td>\n",
       "      <td>0.128786</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>00:00:02.343638</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10018</td>\n",
       "      <td>0.482073</td>\n",
       "      <td>0.051048</td>\n",
       "      <td>0.129802</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>00:00:03.125727</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10013</td>\n",
       "      <td>0.429013</td>\n",
       "      <td>0.027975</td>\n",
       "      <td>0.130472</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>00:00:02.725112</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10021</td>\n",
       "      <td>0.471345</td>\n",
       "      <td>0.043904</td>\n",
       "      <td>0.130540</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>00:00:03.122371</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>10096</td>\n",
       "      <td>0.480041</td>\n",
       "      <td>0.019066</td>\n",
       "      <td>0.130694</td>\n",
       "      <td>0.008897</td>\n",
       "      <td>00:00:02.419242</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10010</td>\n",
       "      <td>0.474586</td>\n",
       "      <td>0.037381</td>\n",
       "      <td>0.131027</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>00:00:02.714949</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>10102</td>\n",
       "      <td>0.448663</td>\n",
       "      <td>0.036386</td>\n",
       "      <td>0.131264</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>00:00:02.937108</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>0.459004</td>\n",
       "      <td>0.046115</td>\n",
       "      <td>0.131413</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>00:00:02.270613</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>10090</td>\n",
       "      <td>0.447064</td>\n",
       "      <td>0.049486</td>\n",
       "      <td>0.133425</td>\n",
       "      <td>0.006665</td>\n",
       "      <td>00:00:02.458024</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10016</td>\n",
       "      <td>0.432166</td>\n",
       "      <td>0.076347</td>\n",
       "      <td>0.133822</td>\n",
       "      <td>0.005732</td>\n",
       "      <td>00:00:02.689050</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>10093</td>\n",
       "      <td>0.471076</td>\n",
       "      <td>0.029290</td>\n",
       "      <td>0.134803</td>\n",
       "      <td>0.010070</td>\n",
       "      <td>00:00:02.431273</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>10105</td>\n",
       "      <td>0.446746</td>\n",
       "      <td>0.032721</td>\n",
       "      <td>0.135540</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>00:00:02.945388</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>10100</td>\n",
       "      <td>0.469559</td>\n",
       "      <td>0.063684</td>\n",
       "      <td>0.136019</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>00:00:02.948569</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>10111</td>\n",
       "      <td>0.457081</td>\n",
       "      <td>0.056040</td>\n",
       "      <td>0.136103</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>00:00:03.402033</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10024</td>\n",
       "      <td>0.464227</td>\n",
       "      <td>0.028532</td>\n",
       "      <td>0.136989</td>\n",
       "      <td>0.006825</td>\n",
       "      <td>00:00:03.032002</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>10091</td>\n",
       "      <td>0.471435</td>\n",
       "      <td>0.039545</td>\n",
       "      <td>0.138909</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>00:00:02.413041</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>10103</td>\n",
       "      <td>0.471324</td>\n",
       "      <td>0.056171</td>\n",
       "      <td>0.140281</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>00:00:02.907910</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>10114</td>\n",
       "      <td>0.426783</td>\n",
       "      <td>0.128709</td>\n",
       "      <td>0.141249</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>00:00:03.390486</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>10097</td>\n",
       "      <td>0.446886</td>\n",
       "      <td>0.029077</td>\n",
       "      <td>0.141482</td>\n",
       "      <td>0.009232</td>\n",
       "      <td>00:00:02.476617</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>10094</td>\n",
       "      <td>0.451875</td>\n",
       "      <td>0.016964</td>\n",
       "      <td>0.141591</td>\n",
       "      <td>0.006442</td>\n",
       "      <td>00:00:02.439529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>10189</td>\n",
       "      <td>0.380699</td>\n",
       "      <td>0.067812</td>\n",
       "      <td>0.142544</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>00:00:02.742463</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>10349</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.244138</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>00:00:02.822086</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>10230</td>\n",
       "      <td>0.304744</td>\n",
       "      <td>0.035865</td>\n",
       "      <td>0.244926</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>00:00:01.268859</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>10317</td>\n",
       "      <td>0.229280</td>\n",
       "      <td>0.116741</td>\n",
       "      <td>0.246189</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>00:00:01.535056</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>10236</td>\n",
       "      <td>0.208242</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.248272</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>00:00:01.591847</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>10331</td>\n",
       "      <td>0.185759</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>0.249993</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>00:00:01.852551</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>10320</td>\n",
       "      <td>0.231161</td>\n",
       "      <td>0.086788</td>\n",
       "      <td>0.250328</td>\n",
       "      <td>0.011291</td>\n",
       "      <td>00:00:01.547034</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>10356</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.253644</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>00:00:04.451778</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>10158</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.253899</td>\n",
       "      <td>0.012817</td>\n",
       "      <td>00:00:01.961844</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>10323</td>\n",
       "      <td>0.189817</td>\n",
       "      <td>0.091582</td>\n",
       "      <td>0.255454</td>\n",
       "      <td>0.016037</td>\n",
       "      <td>00:00:01.561222</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>10242</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.257646</td>\n",
       "      <td>0.015838</td>\n",
       "      <td>00:00:01.600386</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>10245</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.259482</td>\n",
       "      <td>0.020603</td>\n",
       "      <td>00:00:01.864718</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>10161</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.014483</td>\n",
       "      <td>00:00:01.960030</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>10239</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.263511</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>00:00:01.596264</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>10257</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.263978</td>\n",
       "      <td>0.012611</td>\n",
       "      <td>00:00:02.409068</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>10326</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.014233</td>\n",
       "      <td>0.268518</td>\n",
       "      <td>0.011089</td>\n",
       "      <td>00:00:01.894895</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>10340</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.271124</td>\n",
       "      <td>0.021184</td>\n",
       "      <td>00:00:02.217197</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>10170</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.282866</td>\n",
       "      <td>0.030539</td>\n",
       "      <td>00:00:02.998222</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>10335</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.283946</td>\n",
       "      <td>0.020857</td>\n",
       "      <td>00:00:02.215711</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>10248</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.286265</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>00:00:01.868382</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>10329</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.286682</td>\n",
       "      <td>0.011912</td>\n",
       "      <td>00:00:01.945898</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>10332</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.288081</td>\n",
       "      <td>0.015136</td>\n",
       "      <td>00:00:01.977238</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>10251</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.299047</td>\n",
       "      <td>0.025921</td>\n",
       "      <td>00:00:01.874793</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>10179</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.299602</td>\n",
       "      <td>0.027369</td>\n",
       "      <td>00:00:04.903259</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>10347</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.301953</td>\n",
       "      <td>0.009831</td>\n",
       "      <td>00:00:02.828611</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>10269</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.315429</td>\n",
       "      <td>0.026905</td>\n",
       "      <td>00:00:04.321180</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>10338</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.321255</td>\n",
       "      <td>0.018925</td>\n",
       "      <td>00:00:02.231001</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>10260</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.322617</td>\n",
       "      <td>0.041392</td>\n",
       "      <td>00:00:02.352770</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>10341</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.349531</td>\n",
       "      <td>0.030621</td>\n",
       "      <td>00:00:02.223262</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>10359</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.381109</td>\n",
       "      <td>0.035673</td>\n",
       "      <td>00:00:04.652488</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>10350</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.390042</td>\n",
       "      <td>0.050790</td>\n",
       "      <td>00:00:02.841858</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    kfold_id  cos_sim_mean  cos_sim_std  mse_mean   mse_std   training_time  \\\n",
       "9      10009      0.465855     0.031477  0.122334  0.004619 00:00:02.728585   \n",
       "0      10000      0.458835     0.026611  0.124075  0.003959 00:00:02.265769   \n",
       "6      10006      0.470949     0.032925  0.124404  0.013881 00:00:02.320909   \n",
       "12     10012      0.448316     0.070094  0.124603  0.005143 00:00:02.771600   \n",
       "3      10003      0.478470     0.051760  0.125437  0.005395 00:00:02.312797   \n",
       "15     10015      0.443053     0.047780  0.126432  0.004865 00:00:02.739130   \n",
       "99     10099      0.455773     0.050904  0.127267  0.006828 00:00:02.943165   \n",
       "7      10007      0.480098     0.029483  0.128062  0.006087 00:00:02.355577   \n",
       "108    10108      0.493999     0.050000  0.128635  0.007435 00:00:03.429914   \n",
       "4      10004      0.464414     0.039840  0.128786  0.006645 00:00:02.343638   \n",
       "18     10018      0.482073     0.051048  0.129802  0.006247 00:00:03.125727   \n",
       "13     10013      0.429013     0.027975  0.130472  0.005636 00:00:02.725112   \n",
       "21     10021      0.471345     0.043904  0.130540  0.004320 00:00:03.122371   \n",
       "96     10096      0.480041     0.019066  0.130694  0.008897 00:00:02.419242   \n",
       "10     10010      0.474586     0.037381  0.131027  0.006300 00:00:02.714949   \n",
       "102    10102      0.448663     0.036386  0.131264  0.006609 00:00:02.937108   \n",
       "1      10001      0.459004     0.046115  0.131413  0.006216 00:00:02.270613   \n",
       "90     10090      0.447064     0.049486  0.133425  0.006665 00:00:02.458024   \n",
       "16     10016      0.432166     0.076347  0.133822  0.005732 00:00:02.689050   \n",
       "93     10093      0.471076     0.029290  0.134803  0.010070 00:00:02.431273   \n",
       "105    10105      0.446746     0.032721  0.135540  0.005079 00:00:02.945388   \n",
       "100    10100      0.469559     0.063684  0.136019  0.004489 00:00:02.948569   \n",
       "111    10111      0.457081     0.056040  0.136103  0.012126 00:00:03.402033   \n",
       "24     10024      0.464227     0.028532  0.136989  0.006825 00:00:03.032002   \n",
       "91     10091      0.471435     0.039545  0.138909  0.004345 00:00:02.413041   \n",
       "103    10103      0.471324     0.056171  0.140281  0.003328 00:00:02.907910   \n",
       "114    10114      0.426783     0.128709  0.141249  0.008617 00:00:03.390486   \n",
       "97     10097      0.446886     0.029077  0.141482  0.009232 00:00:02.476617   \n",
       "94     10094      0.451875     0.016964  0.141591  0.006442 00:00:02.439529   \n",
       "189    10189      0.380699     0.067812  0.142544  0.007067 00:00:02.742463   \n",
       "..       ...           ...          ...       ...       ...             ...   \n",
       "349    10349      0.176925     0.011735  0.244138  0.025300 00:00:02.822086   \n",
       "230    10230      0.304744     0.035865  0.244926  0.010245 00:00:01.268859   \n",
       "317    10317      0.229280     0.116741  0.246189  0.006743 00:00:01.535056   \n",
       "236    10236      0.208242     0.020482  0.248272  0.006030 00:00:01.591847   \n",
       "331    10331      0.185759     0.016051  0.249993  0.013406 00:00:01.852551   \n",
       "320    10320      0.231161     0.086788  0.250328  0.011291 00:00:01.547034   \n",
       "356    10356      0.176925     0.011735  0.253644  0.013245 00:00:04.451778   \n",
       "158    10158      0.176925     0.011735  0.253899  0.012817 00:00:01.961844   \n",
       "323    10323      0.189817     0.091582  0.255454  0.016037 00:00:01.561222   \n",
       "242    10242      0.176925     0.011735  0.257646  0.015838 00:00:01.600386   \n",
       "245    10245      0.176925     0.011735  0.259482  0.020603 00:00:01.864718   \n",
       "161    10161      0.176925     0.011735  0.260374  0.014483 00:00:01.960030   \n",
       "239    10239      0.176925     0.011735  0.263511  0.008592 00:00:01.596264   \n",
       "257    10257      0.176925     0.011735  0.263978  0.012611 00:00:02.409068   \n",
       "326    10326      0.189300     0.014233  0.268518  0.011089 00:00:01.894895   \n",
       "340    10340      0.176925     0.011735  0.271124  0.021184 00:00:02.217197   \n",
       "170    10170      0.176925     0.011735  0.282866  0.030539 00:00:02.998222   \n",
       "335    10335      0.176925     0.011735  0.283946  0.020857 00:00:02.215711   \n",
       "248    10248      0.176925     0.011735  0.286265  0.014304 00:00:01.868382   \n",
       "329    10329      0.176925     0.011735  0.286682  0.011912 00:00:01.945898   \n",
       "332    10332      0.176925     0.011735  0.288081  0.015136 00:00:01.977238   \n",
       "251    10251      0.176925     0.011735  0.299047  0.025921 00:00:01.874793   \n",
       "179    10179      0.176925     0.011735  0.299602  0.027369 00:00:04.903259   \n",
       "347    10347      0.176925     0.011735  0.301953  0.009831 00:00:02.828611   \n",
       "269    10269      0.176925     0.011735  0.315429  0.026905 00:00:04.321180   \n",
       "338    10338      0.176925     0.011735  0.321255  0.018925 00:00:02.231001   \n",
       "260    10260      0.176925     0.011735  0.322617  0.041392 00:00:02.352770   \n",
       "341    10341      0.176925     0.011735  0.349531  0.030621 00:00:02.223262   \n",
       "359    10359      0.176925     0.011735  0.381109  0.035673 00:00:04.652488   \n",
       "350    10350      0.176925     0.011735  0.390042  0.050790 00:00:02.841858   \n",
       "\n",
       "    batch_size number_hidden num_dense  dropout  \n",
       "9           32             2       150      0.3  \n",
       "0           32             1       150      0.3  \n",
       "6           32             1        50      0.3  \n",
       "12          32             2       100      0.3  \n",
       "3           32             1       100      0.3  \n",
       "15          32             2        50      0.3  \n",
       "99          32             2       150      0.3  \n",
       "7           32             1        50      0.4  \n",
       "108         32             3       150      0.3  \n",
       "4           32             1       100      0.4  \n",
       "18          32             3       150      0.3  \n",
       "13          32             2       100      0.4  \n",
       "21          32             3       100      0.3  \n",
       "96          32             1        50      0.3  \n",
       "10          32             2       150      0.4  \n",
       "102         32             2       100      0.3  \n",
       "1           32             1       150      0.4  \n",
       "90          32             1       150      0.3  \n",
       "16          32             2        50      0.4  \n",
       "93          32             1       100      0.3  \n",
       "105         32             2        50      0.3  \n",
       "100         32             2       150      0.4  \n",
       "111         32             3       100      0.3  \n",
       "24          32             3        50      0.3  \n",
       "91          32             1       150      0.4  \n",
       "103         32             2       100      0.4  \n",
       "114         32             3        50      0.3  \n",
       "97          32             1        50      0.4  \n",
       "94          32             1       100      0.4  \n",
       "189         32             2       150      0.3  \n",
       "..         ...           ...       ...      ...  \n",
       "349         64             5        50      0.4  \n",
       "230         64             1       100      0.5  \n",
       "317         64             1       150      0.5  \n",
       "236         64             2       150      0.5  \n",
       "331         64             2        50      0.4  \n",
       "320         64             1       100      0.5  \n",
       "356         64            10       100      0.5  \n",
       "158         64             3       100      0.5  \n",
       "323         64             1        50      0.5  \n",
       "242         64             2        50      0.5  \n",
       "245         64             3       150      0.5  \n",
       "161         64             3        50      0.5  \n",
       "239         64             2       100      0.5  \n",
       "257         64             5       100      0.5  \n",
       "326         64             2       150      0.5  \n",
       "340         64             3        50      0.4  \n",
       "170         64             5        50      0.5  \n",
       "335         64             3       150      0.5  \n",
       "248         64             3       100      0.5  \n",
       "329         64             2       100      0.5  \n",
       "332         64             2        50      0.5  \n",
       "251         64             3        50      0.5  \n",
       "179         64            10        50      0.5  \n",
       "347         64             5       100      0.5  \n",
       "269         64            10        50      0.5  \n",
       "338         64             3       100      0.5  \n",
       "260         64             5        50      0.5  \n",
       "341         64             3        50      0.5  \n",
       "359         64            10        50      0.5  \n",
       "350         64             5        50      0.5  \n",
       "\n",
       "[360 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melhores = resumo.sort_values('mse_mean', ascending=True)\n",
    "melhores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ICvVLbG2ET2e"
   },
   "source": [
    "### Results Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVQEWgXy9A9H"
   },
   "outputs": [],
   "source": [
    "# specifying results filepath dest file\n",
    "results_filepath = 'results/ann/emb_lmd-5-fold-v1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vqdWn_EYuowP"
   },
   "outputs": [],
   "source": [
    "# all_files = glob.glob(results_ann + \"*.csv\")\n",
    "# #   all_files = glob.glob(results_ann + \"kfoldid_10000-dim_300-bs_32-nf_384-sf_4-nd_150-dv_3.0.csv\")\n",
    "\n",
    "# li = []\n",
    "# for filename in all_files:\n",
    "#     # 1) we process the filename which has info in itself\n",
    "#   params_raw = filename.strip(results_ann).strip('.csv').split('-')\n",
    "  \n",
    "#   print(params_raw)\n",
    "    \n",
    "#   params_dict = dict()\n",
    "    \n",
    "#   for param in params_raw:\n",
    "#     key, value = param.split('_')\n",
    "#     if key == 'dv':\n",
    "#       params_dict[key] = float(value) * 0.1\n",
    "#     elif key == 'sf':\n",
    "#       continue\n",
    "#     else:\n",
    "#       params_dict[key] = int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Mgz7mWaEXOI"
   },
   "outputs": [],
   "source": [
    "# this function goes through all csv results process and group them together\n",
    "def process_raw_data(results_filepath):\n",
    "  all_files = glob.glob(results_ann + \"*.csv\")\n",
    "#   all_files = glob.glob(results_ann + \"kfoldid_10000-dim_300-bs_32-nf_384-sf_4-nd_150-dv_3.0.csv\")\n",
    "\n",
    "  li = []\n",
    "  \n",
    "  for filename in all_files:\n",
    "    # 1) we process the filename which has info in itself\n",
    "    params_raw = filename.strip(results_ann).strip('.csv').split('-')\n",
    "    \n",
    "    params_dict = dict()\n",
    "    \n",
    "#     for param in params_raw:\n",
    "#       key, value = param.split('_')\n",
    "#       if key == 'dv':\n",
    "#         params_dict[key] = float(value) * 0.1\n",
    "#       elif key == 'sf':\n",
    "#         continue\n",
    "#       else:\n",
    "#         params_dict[key] = int(value)\n",
    "\n",
    "    for param in params_raw:\n",
    "      key, value = param.split('_')\n",
    "      if key == 'dv':\n",
    "        params_dict[key] = float(value) / 10\n",
    "      else:\n",
    "        params_dict[key] = int(value)\n",
    "      \n",
    "    df_params = pd.DataFrame(params_dict, index=[0])\n",
    "    df_params.columns = ['kfold_id','emb_dim','batch_size','num_hidden','num_dense','dropout']\n",
    "\n",
    "    # 2) we process the content inside the file\n",
    "    df_results = pd.read_csv(filename, index_col=None, header=0, sep=';')\n",
    "    df_results = df_results.groupby(['epoch'], as_index=False).mean().join(df_results.groupby(['epoch']).std(), lsuffix='_mean', rsuffix='_std')\n",
    "    \n",
    "    # 2.1) Converting negative values to positives\n",
    "    df_results['cosine_proximity_mean'] = abs(df_results['cosine_proximity_mean'])\n",
    "    df_results['val_cosine_proximity_mean'] = abs(df_results['val_cosine_proximity_mean'])\n",
    "  \n",
    "    # 2.2) Defining row with best value\n",
    "    df_results['best_val_loss_mean'] = False\n",
    "    df_results['best_val_cosine_proximity_mean'] = False\n",
    "  \n",
    "    best_val_loss_mean = df_results['val_loss_mean'].min()\n",
    "    best_val_cosine_proximity_mean = df_results['val_cosine_proximity_mean'].max()\n",
    "  \n",
    "    df_results.loc[df_results['val_loss_mean'] == best_val_loss_mean, 'best_val_loss_mean'] = True\n",
    "    df_results.loc[df_results['val_cosine_proximity_mean'] == best_val_cosine_proximity_mean, 'best_val_cosine_proximity_mean'] = True\n",
    "\n",
    "    # 3) we join all info together\n",
    "    df_processed = df_params.join(df_results, how='right').ffill()\n",
    "    \n",
    "    # 4) changing some of the collumns to int\n",
    "    df_processed[['kfold_id','emb_dim','batch_size','num_hidden','num_dense']] = df_processed[['kfold_id','emb_dim','batch_size','num_hidden','num_dense']].astype('int64')\n",
    "    \n",
    "    li.append(df_processed)\n",
    "    \n",
    "  df_final = pd.concat(li, axis=0, ignore_index=True)\n",
    "  \n",
    "  df_final.to_csv(results_filepath, index=False, sep=',', encoding='utf-8')\n",
    "  \n",
    "process_raw_data(results_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S6T0i-OHwp8i"
   },
   "source": [
    "## Treinando em todo o conjunto de Treino e avaliando no conjunto de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5723109,
     "status": "ok",
     "timestamp": 1560543521805,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "uXYPn4A48h0R",
    "outputId": "0e2625bc-9e96-448d-bc09-b36fac1c1cb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kfold_id                               10009\n",
       "emb_dim                                  300\n",
       "batch_size                                32\n",
       "num_hidden                                 2\n",
       "num_dense                                150\n",
       "dropout                                  0.3\n",
       "epoch                                     29\n",
       "cosine_proximity_mean               0.763997\n",
       "loss_mean                          0.0650659\n",
       "time_passed_mean                   0.0611634\n",
       "val_cosine_proximity_mean           0.465855\n",
       "val_loss_mean                       0.122334\n",
       "cosine_proximity_std                0.013936\n",
       "loss_std                           0.0041475\n",
       "time_passed_std                   0.00271762\n",
       "val_cosine_proximity_std            0.035192\n",
       "val_loss_std                       0.0051639\n",
       "best_val_loss_mean                      True\n",
       "best_val_cosine_proximity_mean         False\n",
       "Name: 5909, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MSE(train)= loss_mean\n",
    "#MSE(val) = Val_loss_mean\n",
    "#MSE(test) = o at the bottom of the page\n",
    "#Time = time_passed_mean\n",
    "\n",
    "# selecting best models\n",
    "df_results = pd.read_csv(results_filepath)\n",
    "\n",
    "best_mse_model = df_results[df_results['best_val_loss_mean'] == True].sort_values(by=['val_loss_mean']).iloc[0]\n",
    "best_cos_model = df_results[df_results['best_val_cosine_proximity_mean'] == True].sort_values(by=['val_cosine_proximity_mean'], ascending=[False]).iloc[0]\n",
    "\n",
    "# best_cos_model[['emb_dim','num_hidden', 'num_dense', 'dropout', 'epoch', 'batch_size']]\n",
    "best_mse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fsY1wB0xwp8i"
   },
   "outputs": [],
   "source": [
    "def run_final_test(best_model_config, eval_type):\n",
    "\n",
    "  # fix random seed for reproducibility\n",
    "  seed = 42\n",
    "  np.random.seed(seed)\n",
    "\n",
    "  emb_dim, num_hidden, num_dense, dropout, epoch, batch_size = best_model_config[['emb_dim','num_hidden', 'num_dense', 'dropout', 'epoch', 'batch_size']]\n",
    "\n",
    "  embeddings_index_final = load_embedding(emb_dim)\n",
    "\n",
    "  sentences_train_final_pad, sentences_test_final_pad, tok_final = get_tok_sentences(df_train[\"new_title\"], df_test[\"new_title\"])\n",
    "\n",
    "  # X = {'Word_Seq': sentences_train_final_pad, 'Lexical': np.array(df_train['mean_VADER_LMD'].tolist())}\n",
    "  X = {'Word_Seq': sentences_train_final_pad, 'Lexical': np.array(df_train['mean_LMD'].tolist())}\n",
    "  # X = {'Word_Seq': sentences_train_final_pad}\n",
    "  Y = df_train['sentiment']\n",
    "\n",
    "  embedding_matrix = get_embedding_matrix(emb_dim, MAX_VOCAB_SIZE, MAX_SEQUENCE_LENGTH, tok_final, embeddings_index_final)\n",
    "\n",
    "  if number_hidden == 1:\n",
    "    ann = create_ANN_model_hidden_1(number_dense, dropout_value, embedding_matrix, True)\n",
    "  elif number_hidden == 2:\n",
    "    ann = create_ANN_model_hidden_2(number_dense, dropout_value, embedding_matrix, True)\n",
    "  elif number_hidden == 3:\n",
    "    ann = create_ANN_model_hidden_3(number_dense, dropout_value, embedding_matrix, True)\n",
    "  elif number_hidden == 5:\n",
    "    ann = create_ANN_model_hidden_5(number_dense, dropout_value, embedding_matrix, True)\n",
    "  else:\n",
    "    ann = create_ANN_model_hidden_10(number_dense, dropout_value, embedding_matrix, True)  \n",
    "  # ann = create_ANN_model(150, 0.4, embedding_matrix, True)\n",
    "  # ann = create_ANN_model(50, 0.5, embedding_matrix, True)\n",
    "#   ann = create_ANN_model(150, 0.3, embedding_matrix, True)\n",
    "#   ann = create_ANN_model(num_dense, dropout, embedding_matrix, True)\n",
    "  trained = train_model(ann, X, Y, batch_size, epoch, 'main_data_test', X, Y)\n",
    "#   trained = train_model(ann, X, Y, 32, 15, 'main_data_test', X, Y)\n",
    "  # ann = True\n",
    "  # trained =  True\n",
    "  \n",
    "  \n",
    "  # X_test = {'Word_Seq': sentences_seq_test, 'Lexical': np.array(df_test['mean_VADER_LMD'].tolist())}\n",
    "  X_test = {'Word_Seq': sentences_test_final_pad, 'Lexical': np.array(df_test['mean_LMD'].tolist())}\n",
    "  # X_test = {'Word_Seq': sentences_seq_test}\n",
    "\n",
    "  if eval_type == 'cos_sim':\n",
    "    y_pred = ann.predict(X_test)\n",
    "    return cosine_similarity(y_pred.reshape(1, -1), df_test['sentiment'].values.reshape(1, -1))\n",
    "  else:\n",
    "    return ann.evaluate(X_test, df_test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5723112,
     "status": "ok",
     "timestamp": 1560543521810,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "7yTRTULqwp8p",
    "outputId": "8d066d22-972d-4e54-df7b-e26a43fc2880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 34us/step\n",
      "[0.17180132811278287, -0.14867615645140592]\n"
     ]
    }
   ],
   "source": [
    "final_mse_score = run_final_test(best_mse_model, 'mse')\n",
    "# final_cos_score = run_final_test(best_mse_model, 'cos_sim')\n",
    "\n",
    "print(final_mse_score)\n",
    "# print('Cos_sim: {}'.format(final_cos_score))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[oficial] ANN  Emb Loughran.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
