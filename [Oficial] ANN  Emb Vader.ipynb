{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KWuNFSk8bPHA"
   },
   "source": [
    "# Imports and Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1358,
     "status": "ok",
     "timestamp": 1560543752410,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "qY6m8_IMNfAU",
    "outputId": "cb482019-88cb-4abe-f91e-a6499147ffd6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/xicocaio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/xicocaio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/xicocaio/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "\n",
    "# scikit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras import layers, regularizers, callbacks, utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk import word_tokenize, tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1631,
     "status": "ok",
     "timestamp": 1560543752702,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "l47G7mqPHlBA",
    "outputId": "0cdb7fc8-751b-475b-ebcb-bf4890f0f071"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing if GPU available and if using CUDA\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=True,\n",
    "    min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1628,
     "status": "ok",
     "timestamp": 1560543752708,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "OQbtHrHUbgWQ",
    "outputId": "a9d60e22-537e-4d3a-ce0b-415cd941c9ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_available_gpus():\n",
    "   local_device_protos = device_lib.list_local_devices()\n",
    "   return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "num_gpu = len(get_available_gpus())\n",
    "num_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lZweddAbcgq"
   },
   "outputs": [],
   "source": [
    "#folder setup\n",
    "\n",
    "results_ann = 'results/ann/raw/emb_vader/'\n",
    "results_cnn = 'results/cnn/raw/'\n",
    "results_svr = 'results/svr/raw/'\n",
    "results_lstm = 'results/lstm/raw/'\n",
    "\n",
    "resources = '../resources/'\n",
    "\n",
    "if not os.path.isdir(results_ann):\n",
    "    ! mkdir -p $results_ann\n",
    "    ! mkdir -p $results_cnn\n",
    "    ! mkdir -p $results_svr\n",
    "    ! mkdir -p $results_lstm\n",
    "    \n",
    "if not os.path.isdir(resources):\n",
    "    ! mkdir -p $resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OdHkxTFawp7b"
   },
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2181,
     "status": "ok",
     "timestamp": 1560543753281,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "c8ZQ9Xj0wp7c",
    "outputId": "ddab151f-c1c4-4d13-db95-c7a3d01a2745"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment                                              title\n",
       "0  Morrisons   2      0.430  Morrisons book second consecutive quarter of s...\n",
       "1        IMI   3     -0.344  IMI posts drop in first-quarter organic revenu...\n",
       "2   Glencore   4      0.340  Glencore to refinance its short-term debt earl...\n",
       "3    Ryanair   5      0.259  EasyJet attracts more passengers in June but s...\n",
       "4   Barclays   6     -0.231             Barclays 'bad bank' chief to step down"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading training data\n",
    "df_train = pd.read_json('Headline_Trainingdata.json')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2179,
     "status": "ok",
     "timestamp": 1560543753287,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "vb5O2ouj-BlX",
    "outputId": "8468c989-9198-444a-c368-664fa4ce57a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    131\n",
       "3    129\n",
       "8    128\n",
       "2    127\n",
       "1    127\n",
       "9    126\n",
       "5    126\n",
       "4    125\n",
       "7    123\n",
       "Name: quantile, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bins = 9\n",
    "# bins = df_train['sentiment'].quantile([0.1*q for q in range(0,n_bins)])\n",
    "# df_train['quantile'] = pd.cut(df_train['sentiment'], bins=bins, labels=range(1,n_bins+1))\n",
    "# df_train['quantile'] = pd.cut(df_train['sentiment'], bins=bins, include_lowest=True)\n",
    "\n",
    "df_train['quantile'] = pd.qcut(df_train['sentiment'], q=n_bins, labels=range(1,n_bins+1))\n",
    "df_train['quantile'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2174,
     "status": "ok",
     "timestamp": 1560543753289,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "XKTCXsWaD9RW",
    "outputId": "19112962-ed9b-4c0f-dbc7-d406f89e0a28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.03104903677758319; std: 0.39360209451145045\n"
     ]
    }
   ],
   "source": [
    "print('mean: {}; std: {}'.format(np.mean(df_train['sentiment']), np.std(df_train['sentiment'])))\n",
    "# df_train['sentiment'].min()\n",
    "# df_train['sentiment'].idxmin()\n",
    "# df_train.iloc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2207,
     "status": "ok",
     "timestamp": 1560543753337,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "w619GiP9clF9",
    "outputId": "eed3e154-1d71-4783-a85e-8e36aed641d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train CV: mean: 0.03412017167381975; std: 0.38683983574619385\n",
      "df_train CV: mean: 0.028765217391304363; std: 0.4037852384500579\n",
      "df_train CV: mean: 0.029614035087719294; std: 0.3849741278336272\n",
      "df_train CV: mean: 0.02813274336283186; std: 0.4028562295301328\n",
      "df_train CV: mean: 0.03458666666666667; std: 0.3891696491534537\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "for fit_index, cv_index in skf.split(df_train, df_train['quantile']):\n",
    "#   print(\"TRAIN:\", train_index.size, \"TEST:\", test_index.size)\n",
    "#   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#   print(\"TRAIN:\", df_train.iloc[train_index], \"TEST:\", df_train.iloc[test_index])\n",
    "#   print('TRAIN: mean: {}; std: {}'.format(np.mean(df_train['sentiment'].iloc[train_index]), np.std(df_train['sentiment'].iloc[train_index])))\n",
    "  print('df_train CV: mean: {}; std: {}'.format(np.mean(df_train['sentiment'].iloc[cv_index]), np.std(df_train['sentiment'].iloc[cv_index])))\n",
    "#   df_train['sentiment'].iloc[test_index]\n",
    "#   df_train.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4983,
     "status": "ok",
     "timestamp": 1560543756125,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "sq_o9rsM08Mg",
    "outputId": "1581408f-31d2-450a-9938-c02fa0d403b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashtead</td>\n",
       "      <td>1144</td>\n",
       "      <td>0.588</td>\n",
       "      <td>Ashtead to buy back shares, full-year profit b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shell</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.276</td>\n",
       "      <td>EU regulators clear Shell's takeover of BG Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prudential</td>\n",
       "      <td>1146</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>UK's FTSE has worst day so far in 2015 as BG a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GlaxoSmithKline</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.390</td>\n",
       "      <td>GlaxoSmithKline acquires HIV assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>1148</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>Barclays faces another heavy forex fine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company    id  sentiment  \\\n",
       "0          Ashtead  1144      0.588   \n",
       "1            Shell  1145      0.276   \n",
       "2       Prudential  1146     -0.651   \n",
       "3  GlaxoSmithKline  1147      0.390   \n",
       "4         Barclays  1148     -0.834   \n",
       "\n",
       "                                               title  \n",
       "0  Ashtead to buy back shares, full-year profit b...  \n",
       "1   EU regulators clear Shell's takeover of BG Group  \n",
       "2  UK's FTSE has worst day so far in 2015 as BG a...  \n",
       "3                GlaxoSmithKline acquires HIV assets  \n",
       "4            Barclays faces another heavy forex fine  "
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading testing data, and removing normalizing collumns\n",
    "df_test = pd.read_json(\"Headlines_Testdata_withscores.json\")\n",
    "\n",
    "df_test.drop('UniqueID', axis=1, inplace=True)\n",
    "df_test.rename(columns={'sentiment score': 'sentiment'}, inplace=True)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4971,
     "status": "ok",
     "timestamp": 1560543756127,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "K9ufADTxblRd",
    "outputId": "2c5155d6-3cd7-490e-809e-dff9677c2389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test: mean: 0.014820773930753563; std: 0.4137897136769093\n"
     ]
    }
   ],
   "source": [
    "print('df_test: mean: {}; std: {}'.format(np.mean(df_test['sentiment']), np.std(df_test['sentiment'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-_1M_B-wp7k"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4965,
     "status": "ok",
     "timestamp": 1560543756128,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "2dpikgLywp7k",
    "outputId": "d1914a92-176a-409e-a974-fbe1571ef16b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashtead</td>\n",
       "      <td>1144</td>\n",
       "      <td>0.588</td>\n",
       "      <td>Ashtead to buy back shares, full-year profit b...</td>\n",
       "      <td>[company, buy, back, shares, ,, full-year, pro...</td>\n",
       "      <td>company buy back shares , full-year profit bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shell</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.276</td>\n",
       "      <td>EU regulators clear Shell's takeover of BG Group</td>\n",
       "      <td>[eu, regulators, clear, company, s, takeover, ...</td>\n",
       "      <td>eu regulators clear company s takeover bg group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prudential</td>\n",
       "      <td>1146</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>UK's FTSE has worst day so far in 2015 as BG a...</td>\n",
       "      <td>[uk, s, ftse, worst, day, far, 2015, bg, compa...</td>\n",
       "      <td>uk s ftse worst day far 2015 bg company fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GlaxoSmithKline</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.390</td>\n",
       "      <td>GlaxoSmithKline acquires HIV assets</td>\n",
       "      <td>[company, acquires, hiv, assets]</td>\n",
       "      <td>company acquires hiv assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>1148</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>Barclays faces another heavy forex fine</td>\n",
       "      <td>[company, faces, another, heavy, forex, fine]</td>\n",
       "      <td>company faces another heavy forex fine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company    id  sentiment  \\\n",
       "0          Ashtead  1144      0.588   \n",
       "1            Shell  1145      0.276   \n",
       "2       Prudential  1146     -0.651   \n",
       "3  GlaxoSmithKline  1147      0.390   \n",
       "4         Barclays  1148     -0.834   \n",
       "\n",
       "                                               title  \\\n",
       "0  Ashtead to buy back shares, full-year profit b...   \n",
       "1   EU regulators clear Shell's takeover of BG Group   \n",
       "2  UK's FTSE has worst day so far in 2015 as BG a...   \n",
       "3                GlaxoSmithKline acquires HIV assets   \n",
       "4            Barclays faces another heavy forex fine   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, buy, back, shares, ,, full-year, pro...   \n",
       "1  [eu, regulators, clear, company, s, takeover, ...   \n",
       "2  [uk, s, ftse, worst, day, far, 2015, bg, compa...   \n",
       "3                   [company, acquires, hiv, assets]   \n",
       "4      [company, faces, another, heavy, forex, fine]   \n",
       "\n",
       "                                           new_title  \n",
       "0  company buy back shares , full-year profit bea...  \n",
       "1    eu regulators clear company s takeover bg group  \n",
       "2       uk s ftse worst day far 2015 bg company fall  \n",
       "3                        company acquires hiv assets  \n",
       "4             company faces another heavy forex fine  "
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop words removal\n",
    "def run_preprocessing(df):\n",
    "  # replace company name by placeholder and remove double quotes that is not preprocessed well by word_tokenize\n",
    "  # also lower casing words for compatilbility with glove, which only has lower casing words\n",
    "  # be aware that some companies namies are not identical\n",
    "  # example: id = 10 Centrica PLC appears as just Centrica on title\n",
    "  title_company_replaced = df['title'].replace(df['company'], 'company', regex = True).replace('\"', '', regex = True).str.lower()\n",
    "#   title_company_replaced = df['title'].replace(df['company'], 'company', regex = True)\n",
    "\n",
    "  # tokenize headlines\n",
    "  tokenized_title = title_company_replaced.apply(word_tokenize)\n",
    "  \n",
    "  # removing stopwords and single quotes\n",
    "  # stop_words: {'does', 'under', 'own', 'at', 'of', 'don', 'hers', 'further', 're', \"you'll\", 'into', 'she', 'such', 'shan', 'you', \"haven't\", 'when', 'me', 'a', 'all', \"shan't\", 'mustn', \"should've\", \"didn't\", \"aren't\", \"weren't\", 'after', 'ain', 's', \"that'll\", 'just', 'am', 'the', 'too', 'before', \"wasn't\", 'what', 'haven', 'm', 'up', 'against', 'how', 'who', 'yourselves', 'nor', 'than', 've', 'between', 'being', 'are', 'and', \"don't\", 'themselves', 'were', 'itself', 'd', 'doesn', 'there', \"wouldn't\", 'both', 'we', 'why', 'needn', 'those', 'out', 'mightn', 'which', 'it', 'here', 'theirs', 'any', 'my', 'that', \"doesn't\", 'should', 'him', 'weren', 'from', 'no', 'wouldn', 'once', 'with', 'will', 'have', 'is', 'most', 'hasn', 'll', 'yours', 'himself', 'was', 'this', 'or', 'over', 'again', 'y', 'do', 'through', \"hasn't\", \"she's\", 'same', 'down', 'has', 'so', 'can', 'shouldn', \"hadn't\", 'while', 'for', 'but', 'whom', \"mustn't\", 'our', 'if', \"couldn't\", \"you've\", 'be', 'been', 'myself', 'did', 'few', 'hadn', 'other', \"you'd\", 'not', 'ma', 'their', 'off', \"shouldn't\", 'had', 'these', 'his', 'yourself', 'very', \"isn't\", 'aren', 'o', 'won', 'because', 'isn', 'wasn', 'herself', 'by', 'where', 'your', 'i', \"it's\", 'above', 'until', \"you're\", 'they', 'only', 'ours', 'below', \"mightn't\", 'some', \"won't\", 'about', 'couldn', 'ourselves', 'them', 'he', 'during', 'more', 't', 'as', 'now', 'didn', \"needn't\", 'an', 'to', 'each', 'its', 'her', 'doing', 'then', 'on', 'in', 'having'}  \n",
    "  # some of these word should probably not be removed like the word: won't\n",
    "  # also maybe consider using TweetTokenizer, that mayy deal better with contactions like: Glencore's \n",
    "  stopwords_english = stopwords.words('english')\n",
    "  stopwords_english.append('\\'')\n",
    "\n",
    "  df['clean_tokens'] = tokenized_title.apply(lambda x: [item.strip('\\'') for item in x if item not in stopwords_english])\n",
    "#   df['clean_tokens'] = tokenized_title.apply(lambda x: [item for item in x if item not in stopwords_english])\n",
    "  df['new_title'] =  df['clean_tokens'].apply(lambda x: ' '.join(x))\n",
    "  \n",
    "run_preprocessing(df_train)\n",
    "run_preprocessing(df_test)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NmyHJxUwp7x"
   },
   "source": [
    "## Tokenizing and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4958,
     "status": "ok",
     "timestamp": 1560543756129,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "iVc6F4_vj7Gx",
    "outputId": "cccc4cf9-e0ca-4f0d-cc0b-783a6661be59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 16 | min: 3 | mean: 8.249562171628721 | std: 2.0743354560287957\n"
     ]
    }
   ],
   "source": [
    "clean_tokens_length = df_train[\"clean_tokens\"].apply(lambda x: len(x))\n",
    "\n",
    "max_sentence_length_train = np.max(clean_tokens_length)\n",
    "min_sentence_length_train = np.min(clean_tokens_length)\n",
    "mean_sentence_length_train = np.mean(clean_tokens_length)\n",
    "std_sentence_length_train = np.std(clean_tokens_length)\n",
    "\n",
    "\n",
    "print(\"max: {} | min: {} | mean: {} | std: {}\".format(max_sentence_length_train, min_sentence_length_train, mean_sentence_length_train, std_sentence_length_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9gLNeUqVnkmc"
   },
   "outputs": [],
   "source": [
    "# giving the max_sentence_length_train, we will use a number a little above\n",
    "# TODO: evaluate if this is too much of a leakage, because each fold may yield different sequence MAX\n",
    "MAX_SEQUENCE_LENGTH = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJXCYNGwowZS"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 10000\n",
    "\n",
    "# receives healines and returns tokenizer with vocab mappings and padded sentences read to use\n",
    "def get_tok_sentences(doc_fit, doc_cv):\n",
    "  tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='', lower=False)\n",
    "  tokenizer.fit_on_texts(doc_fit)\n",
    "\n",
    "  fit_sentences = tokenizer.texts_to_sequences(doc_fit)\n",
    "  cv_sentences = tokenizer.texts_to_sequences(doc_cv)\n",
    "  \n",
    "  fit_sentences_pad = pad_sequences(fit_sentences, padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "  cv_sentences_pad = pad_sequences(cv_sentences, padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "  return fit_sentences_pad, cv_sentences_pad, tokenizer\n",
    "\n",
    "# sentences_seq_train, vocab_size, tokenizer = prepare_tokenizer(df_train)\n",
    "# tokenizer.word_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83-K4yu5r9Gv"
   },
   "source": [
    "## Sentiment Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jocsyJfGwp7n"
   },
   "source": [
    "### Loughran McDonald Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXsRVyu6XLy_"
   },
   "outputs": [],
   "source": [
    "LMDDictionary = {}\n",
    "vetor = []\n",
    "\n",
    "# TODO: this can be done directly by converting to pandas and than calling the to_dict function\n",
    "with open('LoughranMcDonald_MasterDictionary_2016.csv', 'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        palavra = line.split(',')[0].lower()\n",
    "        vetor_char = line.split(',')[7:14]\n",
    "        vetor = [1 if x!='0' else 0 for x in vetor_char]\n",
    "\n",
    "        LMDDictionary[palavra] = np.asarray(vetor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5050,
     "status": "ok",
     "timestamp": 1560543756232,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "Ju9zpKQAwp7o",
    "outputId": "faacea17-a003-4669-ace7-8c504d202e88"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>quantile</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "      <th>LMDVector</th>\n",
       "      <th>mean_LMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "      <td>8</td>\n",
       "      <td>[company, book, second, consecutive, quarter, ...</td>\n",
       "      <td>company book second consecutive quarter sales ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[company, posts, drop, first-quarter, organic,...</td>\n",
       "      <td>company posts drop first-quarter organic reven...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[company, refinance, short-term, debt, early, ...</td>\n",
       "      <td>company refinance short-term debt early , shar...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "      <td>6</td>\n",
       "      <td>[easyjet, attracts, passengers, june, still, l...</td>\n",
       "      <td>easyjet attracts passengers june still lags co...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "      <td>3</td>\n",
       "      <td>[company, bad, bank, chief, step]</td>\n",
       "      <td>company bad bank chief step</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment  \\\n",
       "0  Morrisons   2      0.430   \n",
       "1        IMI   3     -0.344   \n",
       "2   Glencore   4      0.340   \n",
       "3    Ryanair   5      0.259   \n",
       "4   Barclays   6     -0.231   \n",
       "\n",
       "                                               title quantile  \\\n",
       "0  Morrisons book second consecutive quarter of s...        8   \n",
       "1  IMI posts drop in first-quarter organic revenu...        2   \n",
       "2  Glencore to refinance its short-term debt earl...        7   \n",
       "3  EasyJet attracts more passengers in June but s...        6   \n",
       "4             Barclays 'bad bank' chief to step down        3   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, book, second, consecutive, quarter, ...   \n",
       "1  [company, posts, drop, first-quarter, organic,...   \n",
       "2  [company, refinance, short-term, debt, early, ...   \n",
       "3  [easyjet, attracts, passengers, june, still, l...   \n",
       "4                  [company, bad, bank, chief, step]   \n",
       "\n",
       "                                           new_title  \\\n",
       "0  company book second consecutive quarter sales ...   \n",
       "1  company posts drop first-quarter organic reven...   \n",
       "2  company refinance short-term debt early , shar...   \n",
       "3  easyjet attracts passengers june still lags co...   \n",
       "4                        company bad bank chief step   \n",
       "\n",
       "                                           LMDVector  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...   \n",
       "\n",
       "                                            mean_LMD  \n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1                [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]  \n",
       "2                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4                [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = [0, 0, 0, 0, 0, 0, 0]\n",
    "nan_list = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "def run_LMD(df):\n",
    "  df['LMDVector'] = df['clean_tokens'].apply(lambda x: [LMDDictionary.get(item, zeros) for item in x])\n",
    "  df['mean_LMD'] = df['LMDVector'].apply(lambda x: np.mean(x, axis=0, dtype=np.float64))\n",
    "  \n",
    "#   df['LMDVector'] = df['new_title'].apply(lambda x: [LMDDictionary.get(item, nan_list) for item in x]) #Taynan\n",
    "#   df['mean_LMD'] = df['LMDVector'].apply(lambda x: np.nanmean(x, axis=0, dtype=np.float64)) #Taynan\n",
    "  \n",
    "run_LMD(df_train)\n",
    "run_LMD(df_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbzybLUewp70"
   },
   "source": [
    "### VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5045,
     "status": "ok",
     "timestamp": 1560543756235,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "Rtd3NaKuznfJ",
    "outputId": "916164d6-f381-41d2-84d1-9d5cf2087585"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>quantile</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "      <th>LMDVector</th>\n",
       "      <th>mean_LMD</th>\n",
       "      <th>neu_VADER</th>\n",
       "      <th>pos_VADER</th>\n",
       "      <th>neg_VADER</th>\n",
       "      <th>compound_VADER</th>\n",
       "      <th>mean_VADER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "      <td>8</td>\n",
       "      <td>[company, book, second, consecutive, quarter, ...</td>\n",
       "      <td>company book second consecutive quarter sales ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]</td>\n",
       "      <td>[0.0, 0.698, 0.302, 0.3818]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[company, posts, drop, first-quarter, organic,...</td>\n",
       "      <td>company posts drop first-quarter organic reven...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...</td>\n",
       "      <td>[0.333, 0.667, 0.0, -0.3612]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[company, refinance, short-term, debt, early, ...</td>\n",
       "      <td>company refinance short-term debt early , shar...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]</td>\n",
       "      <td>[0.258, 0.515, 0.227, -0.0772]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "      <td>6</td>\n",
       "      <td>[easyjet, attracts, passengers, june, still, l...</td>\n",
       "      <td>easyjet attracts passengers june still lags co...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]</td>\n",
       "      <td>[0.245, 0.49, 0.265, 0.0516]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "      <td>3</td>\n",
       "      <td>[company, bad, bank, chief, step]</td>\n",
       "      <td>company bad bank chief step</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, -0.5423, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.467, 0.533, 0.0, -0.5423]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment  \\\n",
       "0  Morrisons   2      0.430   \n",
       "1        IMI   3     -0.344   \n",
       "2   Glencore   4      0.340   \n",
       "3    Ryanair   5      0.259   \n",
       "4   Barclays   6     -0.231   \n",
       "\n",
       "                                               title quantile  \\\n",
       "0  Morrisons book second consecutive quarter of s...        8   \n",
       "1  IMI posts drop in first-quarter organic revenu...        2   \n",
       "2  Glencore to refinance its short-term debt earl...        7   \n",
       "3  EasyJet attracts more passengers in June but s...        6   \n",
       "4             Barclays 'bad bank' chief to step down        3   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, book, second, consecutive, quarter, ...   \n",
       "1  [company, posts, drop, first-quarter, organic,...   \n",
       "2  [company, refinance, short-term, debt, early, ...   \n",
       "3  [easyjet, attracts, passengers, june, still, l...   \n",
       "4                  [company, bad, bank, chief, step]   \n",
       "\n",
       "                                           new_title  \\\n",
       "0  company book second consecutive quarter sales ...   \n",
       "1  company posts drop first-quarter organic reven...   \n",
       "2  company refinance short-term debt early , shar...   \n",
       "3  easyjet attracts passengers june still lags co...   \n",
       "4                        company bad bank chief step   \n",
       "\n",
       "                                           LMDVector  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...   \n",
       "\n",
       "                                            mean_LMD  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1                [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]   \n",
       "2                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4                [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neu_VADER  \\\n",
       "0                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]   \n",
       "1  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...   \n",
       "2           [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]   \n",
       "3                [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]   \n",
       "4                          [1.0, 0.0, 1.0, 1.0, 1.0]   \n",
       "\n",
       "                                           pos_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "3                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "4                          [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neg_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "4                          [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                      compound_VADER  \\\n",
       "0             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]   \n",
       "1  [0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...   \n",
       "2     [0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]   \n",
       "3         [0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]   \n",
       "4                      [0.0, -0.5423, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                       mean_VADER  \n",
       "0     [0.0, 0.698, 0.302, 0.3818]  \n",
       "1    [0.333, 0.667, 0.0, -0.3612]  \n",
       "2  [0.258, 0.515, 0.227, -0.0772]  \n",
       "3    [0.245, 0.49, 0.265, 0.0516]  \n",
       "4    [0.467, 0.533, 0.0, -0.5423]  "
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_sid(df):\n",
    "  sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "  df['neu_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['neu'] for item in x])\n",
    "  df['pos_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['pos'] for item in x])\n",
    "  df['neg_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['neg'] for item in x])\n",
    "  df['compound_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['compound'] for item in x])\n",
    "  df['mean_VADER'] = df['new_title'].apply(lambda x: [v for k,v in sid.polarity_scores(x).items()])\n",
    "  \n",
    "#   df['neu_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['neu'] for item in x]))\n",
    "#   df['pos_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['pos'] for item in x]))\n",
    "#   df['neg_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['neg'] for item in x]))\n",
    "#   df['compound_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['compound'] for item in x]))\n",
    "#   df['mean_VADER'] = df[['neu_VADER', 'pos_VADER', 'neg_VADER', 'compound_VADER']].values.tolist()\n",
    "  \n",
    "                                 \n",
    "run_sid(df_train)\n",
    "run_sid(df_test)\n",
    "\n",
    "df_train.head()\n",
    "# np.mean(df_train['neu_VADER'])\n",
    "# [np.mean(item) for item in df_train['neu_VADER']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KwglgETsGV3"
   },
   "source": [
    "### Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5042,
     "status": "ok",
     "timestamp": 1560543756238,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "Cd30mr4hsLGe",
    "outputId": "66c2ee44-e3e3-4845-92d9-5d85657affb9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>quantile</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "      <th>LMDVector</th>\n",
       "      <th>mean_LMD</th>\n",
       "      <th>neu_VADER</th>\n",
       "      <th>pos_VADER</th>\n",
       "      <th>neg_VADER</th>\n",
       "      <th>compound_VADER</th>\n",
       "      <th>mean_VADER</th>\n",
       "      <th>mean_VADER_LMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "      <td>8</td>\n",
       "      <td>[company, book, second, consecutive, quarter, ...</td>\n",
       "      <td>company book second consecutive quarter sales ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]</td>\n",
       "      <td>[0.0, 0.698, 0.302, 0.3818]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[company, posts, drop, first-quarter, organic,...</td>\n",
       "      <td>company posts drop first-quarter organic reven...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...</td>\n",
       "      <td>[0.333, 0.667, 0.0, -0.3612]</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.333, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[company, refinance, short-term, debt, early, ...</td>\n",
       "      <td>company refinance short-term debt early , shar...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]</td>\n",
       "      <td>[0.258, 0.515, 0.227, -0.0772]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.258, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "      <td>6</td>\n",
       "      <td>[easyjet, attracts, passengers, june, still, l...</td>\n",
       "      <td>easyjet attracts passengers june still lags co...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]</td>\n",
       "      <td>[0.245, 0.49, 0.265, 0.0516]</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "      <td>3</td>\n",
       "      <td>[company, bad, bank, chief, step]</td>\n",
       "      <td>company bad bank chief step</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, -0.5423, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.467, 0.533, 0.0, -0.5423]</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.467, 0.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment  \\\n",
       "0  Morrisons   2      0.430   \n",
       "1        IMI   3     -0.344   \n",
       "2   Glencore   4      0.340   \n",
       "3    Ryanair   5      0.259   \n",
       "4   Barclays   6     -0.231   \n",
       "\n",
       "                                               title quantile  \\\n",
       "0  Morrisons book second consecutive quarter of s...        8   \n",
       "1  IMI posts drop in first-quarter organic revenu...        2   \n",
       "2  Glencore to refinance its short-term debt earl...        7   \n",
       "3  EasyJet attracts more passengers in June but s...        6   \n",
       "4             Barclays 'bad bank' chief to step down        3   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, book, second, consecutive, quarter, ...   \n",
       "1  [company, posts, drop, first-quarter, organic,...   \n",
       "2  [company, refinance, short-term, debt, early, ...   \n",
       "3  [easyjet, attracts, passengers, june, still, l...   \n",
       "4                  [company, bad, bank, chief, step]   \n",
       "\n",
       "                                           new_title  \\\n",
       "0  company book second consecutive quarter sales ...   \n",
       "1  company posts drop first-quarter organic reven...   \n",
       "2  company refinance short-term debt early , shar...   \n",
       "3  easyjet attracts passengers june still lags co...   \n",
       "4                        company bad bank chief step   \n",
       "\n",
       "                                           LMDVector  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...   \n",
       "\n",
       "                                            mean_LMD  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1                [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]   \n",
       "2                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4                [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neu_VADER  \\\n",
       "0                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]   \n",
       "1  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...   \n",
       "2           [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]   \n",
       "3                [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]   \n",
       "4                          [1.0, 0.0, 1.0, 1.0, 1.0]   \n",
       "\n",
       "                                           pos_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "3                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "4                          [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neg_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "4                          [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                      compound_VADER  \\\n",
       "0             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]   \n",
       "1  [0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...   \n",
       "2     [0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]   \n",
       "3         [0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]   \n",
       "4                      [0.0, -0.5423, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                       mean_VADER  \\\n",
       "0     [0.0, 0.698, 0.302, 0.3818]   \n",
       "1    [0.333, 0.667, 0.0, -0.3612]   \n",
       "2  [0.258, 0.515, 0.227, -0.0772]   \n",
       "3    [0.245, 0.49, 0.265, 0.0516]   \n",
       "4    [0.467, 0.533, 0.0, -0.5423]   \n",
       "\n",
       "                                      mean_VADER_LMD  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.698...  \n",
       "1  [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.333, 0.6...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.258, 0.5...  \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4  [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.467, 0.5...  "
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_vader_LMD(df):\n",
    "  df['mean_VADER_LMD'] = [np.hstack([x,y]) for x, y in zip(df['mean_LMD'], df['mean_VADER'])]\n",
    "\n",
    "join_vader_LMD(df_train)\n",
    "join_vader_LMD(df_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKNfykDiwp76"
   },
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsTrK_2z9b-i"
   },
   "outputs": [],
   "source": [
    "# EMBEDDING_DIM = 300\n",
    "\n",
    "# TODO: use: vocab_size = max(MAX_VOCAB_SIZE, len(word_index)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCkEUlw1DL2v"
   },
   "outputs": [],
   "source": [
    "def load_embedding(emb_dim):\n",
    "  \n",
    "  # load the whole embedding into memory\n",
    "  embeddings_index = dict()\n",
    "  \n",
    "  if not os.path.exists(resources + 'glove.6B.zip'):\n",
    "    ! wget http://nlp.stanford.edu/data/glove.6B.zip -P /resources/\n",
    "  if not os.path.exists(resources + 'glove.6B.' + str(emb_dim) + 'd.txt'):\n",
    "    ! unzip resources/glove.6B.zip -d resources\n",
    "  \n",
    "  f = open(resources + 'glove.6B.' + str(emb_dim) + 'd.txt', 'r', encoding=\"utf8\")\n",
    "  for line in f:\n",
    "      values = line.split()\n",
    "      word = values[0]\n",
    "      coefs = np.asarray(values[1:], dtype='float32')\n",
    "      embeddings_index[word] = coefs\n",
    "  f.close()\n",
    "  \n",
    "  return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tcmZ6KVgwp78"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "def get_embedding_matrix(emb_dim, vocab_size, input_length, tokenizer, embeddings_index):\n",
    "  vocab_size = min(MAX_VOCAB_SIZE, len(tokenizer.word_index)) + 1 # Adding 1 because of reserved 0 index\n",
    "  embedding_matrix = np.zeros((vocab_size, emb_dim))\n",
    "  for word, i in tokenizer.word_index.items():\n",
    "      embedding_vector = embeddings_index.get(word)\n",
    "      if (embedding_vector is not None):\n",
    "          embedding_matrix[i] = embedding_vector\n",
    "\n",
    "  return embedding_matrix\n",
    "\n",
    "\n",
    "# banna, maca, tokenizer = get_tok_sentences(df_train['new_title'], df_test['new_title'])\n",
    "# get_embedding_matrix(300, MAX_VOCAB_SIZE, True, MAX_SEQUENCE_LENGTH, tokenizer).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buH-SkpPpdPm"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DAqcBAvnwp8A"
   },
   "source": [
    "## ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRqZgB3-hY7t"
   },
   "outputs": [],
   "source": [
    "def cos_sim(y_true, y_pred):\n",
    "#   x = K.l2_normalize(y_true, axis=-1)\n",
    "#   y = K.l2_normalize(y_pred, axis=-1)\n",
    "#   return K.mean(x * y, axis=-1, keepdims=True)\n",
    "  return cosine_similarity(y_true, y_pred)\n",
    "\n",
    "metrics = ['cosine_proximity']\n",
    "# dropout = 0.3\n",
    "# loss = 'mse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2B9necCNwp8D"
   },
   "outputs": [],
   "source": [
    "# callback for time: https://stackoverflow.com/questions/43178668/record-the-computation-time-for-each-epoch-in-keras-during-model-fit\n",
    "# or maybe just use keras LambdaCallback\n",
    "\n",
    "class TimeHistory(callbacks.Callback):  \n",
    "  def on_epoch_begin(self, epoch, logs={}):\n",
    "    self.epoch_time_start = time.time()\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    logs['time_passed'] = time.time() - self.epoch_time_start\n",
    "\n",
    "def callback_functions(nome_log):\n",
    "  time_callback = TimeHistory()\n",
    "  csv_logger = callbacks.CSVLogger(results_ann + nome_log + '.csv', separator=';', append=True)\n",
    "#     tensorboard_callback = callbacks.TensorBoard(nome_log, histogram_freq=1)\n",
    "#     best_model = callbacks.ModelCheckpoint(results_ann + nome_log + '.h5', monitor='val_loss', verbose=0, save_best_only=True, mode='auto')\n",
    "\n",
    "  return [time_callback, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeUV9qR9wp8H"
   },
   "outputs": [],
   "source": [
    "def create_ANN_model_hidden_1(number_dense, dropout_value, embedding_matrix, emb_layer_trainable):\n",
    "    \n",
    "    # first input model\n",
    "    visible1 = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), name='Word_Seq')\n",
    "    embedding = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable)(visible1)\n",
    "#     conv1 = layers.Conv1D(num_filters_1, size_filters_1, padding='same', activation='relu')(embedding)\n",
    "#     conv2 = layers.Conv1D(num_filters_2, size_filters_2, padding='same', activation='relu')(conv1)\n",
    "    pool1 = layers.GlobalMaxPooling1D()(embedding)\n",
    "    flat1 = pool1\n",
    "    \n",
    "    # second input model\n",
    "#     visible2 = layers.Input(shape=(np.array(df_train['mean_VADER_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    visible2 = layers.Input(shape=(np.array(df_train['mean_VADER'].tolist()).shape[1],), name='Lexical')\n",
    "    flat2 = visible2\n",
    "\n",
    "    # merge input models\n",
    "    merge = layers.concatenate([flat1, flat2])\n",
    "#     merge = flat1\n",
    "    \n",
    "    # interpretation model\n",
    "    dropout1 = layers.Dropout(dropout_value)(merge)    \n",
    "    hidden1 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n",
    "    dropout2 = layers.Dropout(dropout_value)(hidden1)\n",
    "    output = layers.Dense(1, activation='tanh')(dropout2)\n",
    "    model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "\n",
    "    return model\n",
    "  \n",
    "def create_ANN_model_hidden_2(number_dense, dropout_value, embedding_matrix, emb_layer_trainable):\n",
    "    \n",
    "    # first input model\n",
    "    visible1 = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), name='Word_Seq')\n",
    "    embedding = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable)(visible1)\n",
    "#     conv1 = layers.Conv1D(num_filters_1, size_filters_1, padding='same', activation='relu')(embedding)\n",
    "#     conv2 = layers.Conv1D(num_filters_2, size_filters_2, padding='same', activation='relu')(conv1)\n",
    "    pool1 = layers.GlobalMaxPooling1D()(embedding)\n",
    "    flat1 = pool1\n",
    "    \n",
    "    # second input model\n",
    "#     visible2 = layers.Input(shape=(np.array(df_train['mean_VADER_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    visible2 = layers.Input(shape=(np.array(df_train['mean_VADER'].tolist()).shape[1],), name='Lexical')\n",
    "    flat2 = visible2\n",
    "\n",
    "    # merge input models\n",
    "    merge = layers.concatenate([flat1, flat2])\n",
    "#     merge = flat1\n",
    "    \n",
    "    # interpretation model\n",
    "    dropout1 = layers.Dropout(dropout_value)(merge)  \n",
    "    hidden1 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n",
    "    dropout2 = layers.Dropout(dropout_value)(hidden1)\n",
    "    hidden2 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout2)\n",
    "    dropout3 = layers.Dropout(dropout_value)(hidden2)\n",
    "    output = layers.Dense(1, activation='tanh')(dropout3)\n",
    "    model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "\n",
    "    return model\n",
    "  \n",
    "def create_ANN_model_hidden_3(number_dense, dropout_value, embedding_matrix, emb_layer_trainable):\n",
    "    \n",
    "    # first input model\n",
    "    visible1 = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), name='Word_Seq')\n",
    "    embedding = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable)(visible1)\n",
    "#     conv1 = layers.Conv1D(num_filters_1, size_filters_1, padding='same', activation='relu')(embedding)\n",
    "#     conv2 = layers.Conv1D(num_filters_2, size_filters_2, padding='same', activation='relu')(conv1)\n",
    "    pool1 = layers.GlobalMaxPooling1D()(embedding)\n",
    "    flat1 = pool1\n",
    "    \n",
    "    # second input model\n",
    "#     visible2 = layers.Input(shape=(np.array(df_train['mean_VADER_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    visible2 = layers.Input(shape=(np.array(df_train['mean_VADER'].tolist()).shape[1],), name='Lexical')\n",
    "    flat2 = visible2\n",
    "\n",
    "    # merge input models\n",
    "    merge = layers.concatenate([flat1, flat2])\n",
    "#     merge = flat1\n",
    "    \n",
    "    # interpretation model\n",
    "    dropout1 = layers.Dropout(dropout_value)(merge)  \n",
    "    hidden1 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n",
    "    dropout2 = layers.Dropout(dropout_value)(hidden1)\n",
    "    hidden2 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout2)\n",
    "    dropout3 = layers.Dropout(dropout_value)(hidden2)\n",
    "    hidden3 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout3)\n",
    "    dropout4 = layers.Dropout(dropout_value)(hidden3)\n",
    "    output = layers.Dense(1, activation='tanh')(dropout4)\n",
    "    model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "\n",
    "    return model\n",
    "  \n",
    "def create_ANN_model_hidden_5(number_dense, dropout_value, embedding_matrix, emb_layer_trainable):\n",
    "    \n",
    "    # first input model\n",
    "    visible1 = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), name='Word_Seq')\n",
    "    embedding = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable)(visible1)\n",
    "#     conv1 = layers.Conv1D(num_filters_1, size_filters_1, padding='same', activation='relu')(embedding)\n",
    "#     conv2 = layers.Conv1D(num_filters_2, size_filters_2, padding='same', activation='relu')(conv1)\n",
    "    pool1 = layers.GlobalMaxPooling1D()(embedding)\n",
    "    flat1 = pool1\n",
    "    \n",
    "    # second input model\n",
    "#     visible2 = layers.Input(shape=(np.array(df_train['mean_VADER_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    visible2 = layers.Input(shape=(np.array(df_train['mean_VADER'].tolist()).shape[1],), name='Lexical')\n",
    "    flat2 = visible2\n",
    "\n",
    "    # merge input models\n",
    "    merge = layers.concatenate([flat1, flat2])\n",
    "#     merge = flat1\n",
    "    \n",
    "    # interpretation model\n",
    "    dropout1 = layers.Dropout(dropout_value)(merge)  \n",
    "    hidden1 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n",
    "    dropout2 = layers.Dropout(dropout_value)(hidden1)\n",
    "    hidden2 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout2)\n",
    "    dropout3 = layers.Dropout(dropout_value)(hidden2)\n",
    "    hidden3 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout3)\n",
    "    dropout4 = layers.Dropout(dropout_value)(hidden3)\n",
    "    hidden4 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout4)\n",
    "    dropout5 = layers.Dropout(dropout_value)(hidden4)\n",
    "    hidden5 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout5)\n",
    "    dropout6 = layers.Dropout(dropout_value)(hidden5)\n",
    "    output = layers.Dense(1, activation='tanh')(dropout6)\n",
    "    model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "\n",
    "    return model\n",
    "  \n",
    "def create_ANN_model_hidden_10(number_dense, dropout_value, embedding_matrix, emb_layer_trainable):\n",
    "    \n",
    "    # first input model\n",
    "    visible1 = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), name='Word_Seq')\n",
    "    embedding = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable)(visible1)\n",
    "#     conv1 = layers.Conv1D(num_filters_1, size_filters_1, padding='same', activation='relu')(embedding)\n",
    "#     conv2 = layers.Conv1D(num_filters_2, size_filters_2, padding='same', activation='relu')(conv1)\n",
    "    pool1 = layers.GlobalMaxPooling1D()(embedding)\n",
    "    flat1 = pool1\n",
    "    \n",
    "    # second input model\n",
    "#     visible2 = layers.Input(shape=(np.array(df_train['mean_VADER_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    visible2 = layers.Input(shape=(np.array(df_train['mean_VADER'].tolist()).shape[1],), name='Lexical')\n",
    "    flat2 = visible2\n",
    "\n",
    "    # merge input models\n",
    "    merge = layers.concatenate([flat1, flat2])\n",
    "#     merge = flat1\n",
    "    \n",
    "    # interpretation model\n",
    "    dropout1 = layers.Dropout(dropout_value)(merge)  \n",
    "    hidden1 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n",
    "    dropout2 = layers.Dropout(dropout_value)(hidden1)\n",
    "    hidden2 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout2)\n",
    "    dropout3 = layers.Dropout(dropout_value)(hidden2)\n",
    "    hidden3 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout3)\n",
    "    dropout4 = layers.Dropout(dropout_value)(hidden3)\n",
    "    hidden4 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout4)\n",
    "    dropout5 = layers.Dropout(dropout_value)(hidden4)\n",
    "    hidden5 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout5)\n",
    "    dropout6 = layers.Dropout(dropout_value)(hidden5)\n",
    "    hidden6 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout6)\n",
    "    dropout7 = layers.Dropout(dropout_value)(hidden6)\n",
    "    hidden7 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout7)\n",
    "    dropout8 = layers.Dropout(dropout_value)(hidden7)\n",
    "    hidden8 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout8)\n",
    "    dropout9 = layers.Dropout(dropout_value)(hidden8)\n",
    "    hidden9 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout9)\n",
    "    dropout10 = layers.Dropout(dropout_value)(hidden9)\n",
    "    hidden10 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout10)\n",
    "    dropout11 = layers.Dropout(dropout_value)(hidden10)\n",
    "    output = layers.Dense(1, activation='tanh')(dropout11)\n",
    "    model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XMj2FWnlwp8K"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X, Y, batch_size, epochs_value, nome_log, X_cv, Y_cv):\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=metrics)\n",
    "    \n",
    "    return model.fit(X, Y, batch_size,\n",
    "                     validation_data=(X_cv, Y_cv),\n",
    "                     epochs=epochs_value,\n",
    "                     verbose=0,\n",
    "                     callbacks=callback_functions(nome_log)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPhI1NJswp8N"
   },
   "outputs": [],
   "source": [
    "def save_model(model, trained_model_history, model_name):\n",
    "    \n",
    "#     model.save(model_name + '.h5')\n",
    "    trained_model = trained_model_history\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.plot([abs(v) for v in trained_model.history['loss']])\n",
    "    plt.plot([abs(v) for v in trained_model.history['val_loss']])\n",
    "    plt.plot([abs(v) for v in trained_model.history['cosine_proximity']])\n",
    "    plt.plot([abs(v) for v in trained_model.history['val_cosine_proximity']])\n",
    "    plt.title('model mean squared error')\n",
    "    plt.ylabel('mean squared error')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['mse_train', 'mse_test', 'cos_sim_train', 'cos_sim_test'], loc='upper left')\n",
    "    plt.savefig(results_ann + model_name + '_mse.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqcHcjJOwp8R"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, Y_expected):\n",
    "    input = X\n",
    "    output = np.array(model.predict(input))\n",
    "    expected = np.array(Y_expected)\n",
    "\n",
    "    dot = np.dot(expected, output)\n",
    "    output_mod = np.linalg.norm(output)\n",
    "    expected_mod = np.linalg.norm(expected)\n",
    "    cos = dot / output_mod / expected_mod\n",
    "\n",
    "    final_score = cos\n",
    "    \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tP6QpoR77w2y"
   },
   "source": [
    "## K-fold on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6414
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5450906,
     "status": "ok",
     "timestamp": 1560549202127,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "aMRsC6M3wp8T",
    "outputId": "897d3da8-bef2-42af-ecca-77e216e7e260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "ID: 10000, Cos Sim Mean: 0.48551588884857394, Cos Sim Std: 0.04837032409890005, MSE Mean: 0.12752698364114295, MSE Std: 0.004494073600828822, Training Time: 0:00:02.349765, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10001, Cos Sim Mean: 0.4872404907847095, Cos Sim Std: 0.04929254654105025, MSE Mean: 0.12425349299067132, MSE Std: 0.004602246159496657, Training Time: 0:00:02.311457, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10002, Cos Sim Mean: 0.48551182502167467, Cos Sim Std: 0.041497538842530185, MSE Mean: 0.13792315931902396, MSE Std: 0.0031985426885465683, Training Time: 0:00:02.330790, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10003, Cos Sim Mean: 0.49585196397103387, Cos Sim Std: 0.032249588317871745, MSE Mean: 0.12182172874674904, MSE Std: 0.005829260604126169, Training Time: 0:00:02.332175, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10004, Cos Sim Mean: 0.4924039624180071, Cos Sim Std: 0.03528525074091482, MSE Mean: 0.12402495983488611, MSE Std: 0.005388907841059576, Training Time: 0:00:02.372637, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10005, Cos Sim Mean: 0.45750845990294026, Cos Sim Std: 0.045432727354029416, MSE Mean: 0.14217362721567456, MSE Std: 0.01047065267813276, Training Time: 0:00:02.337037, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10006, Cos Sim Mean: 0.4781731244490305, Cos Sim Std: 0.02321359293127492, MSE Mean: 0.12148132907088387, MSE Std: 0.009443977701198371, Training Time: 0:00:02.339812, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10007, Cos Sim Mean: 0.4958595621262643, Cos Sim Std: 0.02969906984270928, MSE Mean: 0.12157868313071367, MSE Std: 0.0068462930529857545, Training Time: 0:00:02.374343, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10008, Cos Sim Mean: 0.4592277015077803, Cos Sim Std: 0.052514392458968794, MSE Mean: 0.13655764927339611, MSE Std: 0.010561329026687967, Training Time: 0:00:02.303672, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10009, Cos Sim Mean: 0.47486100047039426, Cos Sim Std: 0.03514124820583653, MSE Mean: 0.12385836138590334, MSE Std: 0.007928364675847984, Training Time: 0:00:02.752835, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10010, Cos Sim Mean: 0.48362533381543055, Cos Sim Std: 0.0422473685106316, MSE Mean: 0.12550066025661658, MSE Std: 0.006331984005456686, Training Time: 0:00:02.752064, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10011, Cos Sim Mean: 0.4746467670718463, Cos Sim Std: 0.021301424634737432, MSE Mean: 0.13946777522597, MSE Std: 0.004891063360695631, Training Time: 0:00:02.782529, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10012, Cos Sim Mean: 0.47142773005696553, Cos Sim Std: 0.03352747343538496, MSE Mean: 0.11949617886267774, MSE Std: 0.0075899373416878115, Training Time: 0:00:02.776895, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10013, Cos Sim Mean: 0.4641217850126777, Cos Sim Std: 0.040467828616425026, MSE Mean: 0.12645826876273839, MSE Std: 0.006043140075932888, Training Time: 0:00:02.756576, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10014, Cos Sim Mean: 0.43093383622269144, Cos Sim Std: 0.02787949580770912, MSE Mean: 0.14406714752387612, MSE Std: 0.005206207303184502, Training Time: 0:00:02.803556, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10015, Cos Sim Mean: 0.48707460658047763, Cos Sim Std: 0.045632104697686963, MSE Mean: 0.12356614216503056, MSE Std: 0.006258912975947962, Training Time: 0:00:02.759178, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10016, Cos Sim Mean: 0.46234662683940336, Cos Sim Std: 0.0322389963843212, MSE Mean: 0.12896967953936445, MSE Std: 0.002986559462439561, Training Time: 0:00:02.727548, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10017, Cos Sim Mean: 0.35339631706123065, Cos Sim Std: 0.06143640580776415, MSE Mean: 0.15455755001302843, MSE Std: 0.005381665525137997, Training Time: 0:00:02.783079, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10018, Cos Sim Mean: 0.4625811894104531, Cos Sim Std: 0.040404929101477687, MSE Mean: 0.13071593503580897, MSE Std: 0.014242936463384688, Training Time: 0:00:03.138777, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10019, Cos Sim Mean: 0.4800664858652935, Cos Sim Std: 0.035521705594357245, MSE Mean: 0.13707266623707992, MSE Std: 0.01030922045523349, Training Time: 0:00:03.134635, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10020, Cos Sim Mean: 0.24507164069388127, Cos Sim Std: 0.0857801749749025, MSE Mean: 0.1593529145471509, MSE Std: 0.007427198089387218, Training Time: 0:00:03.148362, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10021, Cos Sim Mean: 0.5010980759599829, Cos Sim Std: 0.02957286145055636, MSE Mean: 0.1281446424943214, MSE Std: 0.009892535644646951, Training Time: 0:00:02.746670, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10022, Cos Sim Mean: 0.4938511067433569, Cos Sim Std: 0.027125293748231052, MSE Mean: 0.1407610312040663, MSE Std: 0.006127412573438453, Training Time: 0:00:02.755676, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10023, Cos Sim Mean: 0.17692518828597587, Cos Sim Std: 0.011735313157013065, MSE Mean: 0.16175250159581953, MSE Std: 0.006336592495471682, Training Time: 0:00:02.674733, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10024, Cos Sim Mean: 0.46952963680748516, Cos Sim Std: 0.04829557620094593, MSE Mean: 0.12847348814120924, MSE Std: 0.005419376504468447, Training Time: 0:00:02.659641, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10025, Cos Sim Mean: 0.24183127263746088, Cos Sim Std: 0.06330540343863739, MSE Mean: 0.15445531255978082, MSE Std: 0.006977047859528121, Training Time: 0:00:02.693948, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10026, Cos Sim Mean: 0.17692518594065426, Cos Sim Std: 0.011735310499397184, MSE Mean: 0.1622612842757686, MSE Std: 0.006547960441759308, Training Time: 0:00:02.664315, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10027, Cos Sim Mean: 0.17692518884718691, Cos Sim Std: 0.011735310537284497, MSE Mean: 0.15495749496820416, MSE Std: 0.006392196668095012, Training Time: 0:00:03.309207, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10028, Cos Sim Mean: 0.17692518915816766, Cos Sim Std: 0.01173531011181725, MSE Mean: 0.15508116372847996, MSE Std: 0.006382487624825748, Training Time: 0:00:03.333329, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10029, Cos Sim Mean: 0.17692518240624333, Cos Sim Std: 0.011735306798901767, MSE Mean: 0.1570003418790434, MSE Std: 0.006150936449590583, Training Time: 0:00:03.310048, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10030, Cos Sim Mean: 0.17692518143066283, Cos Sim Std: 0.011735317742432326, MSE Mean: 0.15497896202227962, MSE Std: 0.006408541226450628, Training Time: 0:00:03.348714, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10031, Cos Sim Mean: 0.17692518325155876, Cos Sim Std: 0.011735305590938818, MSE Mean: 0.15523791028880685, MSE Std: 0.006361971436060654, Training Time: 0:00:03.350616, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10032, Cos Sim Mean: 0.1769251874634004, Cos Sim Std: 0.011735310250388441, MSE Mean: 0.15915535998570435, MSE Std: 0.00519412436380248, Training Time: 0:00:03.314647, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10033, Cos Sim Mean: 0.17692518491961515, Cos Sim Std: 0.01173530659339857, MSE Mean: 0.15521196198028875, MSE Std: 0.006416538959849009, Training Time: 0:00:03.286192, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10034, Cos Sim Mean: 0.17692518927597672, Cos Sim Std: 0.011735305098361905, MSE Mean: 0.15615909660473365, MSE Std: 0.006207430477334114, Training Time: 0:00:03.343298, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10035, Cos Sim Mean: 0.17692518460313028, Cos Sim Std: 0.011735306830279815, MSE Mean: 0.16480296753261553, MSE Std: 0.006434256674844288, Training Time: 0:00:03.502408, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10036, Cos Sim Mean: 0.17692518096009985, Cos Sim Std: 0.01173530894336399, MSE Mean: 0.15495597149378737, MSE Std: 0.006394775205190508, Training Time: 0:00:06.548352, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10037, Cos Sim Mean: 0.17692518491503892, Cos Sim Std: 0.011735306642084931, MSE Mean: 0.15495959952113306, MSE Std: 0.006393284404779119, Training Time: 0:00:06.055027, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10038, Cos Sim Mean: 0.17692518915816766, Cos Sim Std: 0.01173531011181725, MSE Mean: 0.15568847423317536, MSE Std: 0.0062497805452588285, Training Time: 0:00:06.224382, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10039, Cos Sim Mean: 0.17692518004047386, Cos Sim Std: 0.011735312092080818, MSE Mean: 0.15495903955240928, MSE Std: 0.006392456142208544, Training Time: 0:00:06.671966, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10040, Cos Sim Mean: 0.1769251802137684, Cos Sim Std: 0.011735309673040284, MSE Mean: 0.15496423037304047, MSE Std: 0.006400676173081155, Training Time: 0:00:06.456844, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10041, Cos Sim Mean: 0.17692518564981433, Cos Sim Std: 0.011735305394847803, MSE Mean: 0.1577119823870204, MSE Std: 0.006569774889082897, Training Time: 0:00:06.833914, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10042, Cos Sim Mean: 0.17692519005886007, Cos Sim Std: 0.011735310859481872, MSE Mean: 0.15495006318510426, MSE Std: 0.006395412750554089, Training Time: 0:00:06.649967, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10043, Cos Sim Mean: 0.1769251756631216, Cos Sim Std: 0.011735316315893609, MSE Mean: 0.15520113140541447, MSE Std: 0.006273414531660358, Training Time: 0:00:06.372187, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10044, Cos Sim Mean: 0.1769251897465397, Cos Sim Std: 0.01173531389743279, MSE Mean: 0.1621932185887657, MSE Std: 0.0043694228256271695, Training Time: 0:00:06.428257, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10045, Cos Sim Mean: 0.46439753588960625, Cos Sim Std: 0.04229255645410556, MSE Mean: 0.18169964214363177, MSE Std: 0.013128809642317817, Training Time: 0:00:01.320187, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10046, Cos Sim Mean: 0.4467133891988787, Cos Sim Std: 0.02113551236912994, MSE Mean: 0.17866799063647604, MSE Std: 0.005862193623130712, Training Time: 0:00:01.304947, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10047, Cos Sim Mean: 0.4089337645303101, Cos Sim Std: 0.08390767607873587, MSE Mean: 0.19039967476958647, MSE Std: 0.007251783905326153, Training Time: 0:00:01.302751, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10048, Cos Sim Mean: 0.4503267608676877, Cos Sim Std: 0.026051316301313625, MSE Mean: 0.1733247505513627, MSE Std: 0.019911137696947717, Training Time: 0:00:01.290781, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10049, Cos Sim Mean: 0.4558317022272023, Cos Sim Std: 0.05111806026570364, MSE Mean: 0.16808272043870187, MSE Std: 0.013029976056699312, Training Time: 0:00:01.304315, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10050, Cos Sim Mean: 0.4017456730646621, Cos Sim Std: 0.0599205507048635, MSE Mean: 0.18392578802575493, MSE Std: 0.008855071180325799, Training Time: 0:00:01.284654, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10051, Cos Sim Mean: 0.4538584019573788, Cos Sim Std: 0.027626221278048577, MSE Mean: 0.1505984765382929, MSE Std: 0.013661381000702952, Training Time: 0:00:01.315876, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10052, Cos Sim Mean: 0.45380911748287145, Cos Sim Std: 0.04984489967494302, MSE Mean: 0.15531020703919565, MSE Std: 0.010907845748991637, Training Time: 0:00:01.306726, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10053, Cos Sim Mean: 0.4034327113039963, Cos Sim Std: 0.08246692821035811, MSE Mean: 0.17421830001705943, MSE Std: 0.009917416793226424, Training Time: 0:00:01.272883, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10054, Cos Sim Mean: 0.4729272428620891, Cos Sim Std: 0.03845780421009747, MSE Mean: 0.14434428963199292, MSE Std: 0.004855608259689964, Training Time: 0:00:01.553014, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10055, Cos Sim Mean: 0.47657309757607996, Cos Sim Std: 0.03900581039939927, MSE Mean: 0.14997937820739815, MSE Std: 0.003029629730090312, Training Time: 0:00:01.558255, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10056, Cos Sim Mean: 0.38377420412016583, Cos Sim Std: 0.023959122240318927, MSE Mean: 0.18702341642145304, MSE Std: 0.004741806513840634, Training Time: 0:00:01.534431, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10057, Cos Sim Mean: 0.45187194647752305, Cos Sim Std: 0.03165873272594368, MSE Mean: 0.14490994986112674, MSE Std: 0.006363528687794398, Training Time: 0:00:01.567185, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10058, Cos Sim Mean: 0.4307146114415069, Cos Sim Std: 0.033436700033520186, MSE Mean: 0.15327661992863234, MSE Std: 0.004348062618025529, Training Time: 0:00:01.554421, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10059, Cos Sim Mean: 0.35905952709998185, Cos Sim Std: 0.04115850136138381, MSE Mean: 0.1904444093227197, MSE Std: 0.004778148294243348, Training Time: 0:00:01.523182, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10060, Cos Sim Mean: 0.4679137762055009, Cos Sim Std: 0.034994891299175844, MSE Mean: 0.14142277292469982, MSE Std: 0.002642312663562232, Training Time: 0:00:01.568723, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10061, Cos Sim Mean: 0.36111641803192235, Cos Sim Std: 0.07713011113656548, MSE Mean: 0.1608436913313087, MSE Std: 0.005460127872115706, Training Time: 0:00:01.549931, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10062, Cos Sim Mean: 0.22384183691209897, Cos Sim Std: 0.06577774360359435, MSE Mean: 0.19737705035654282, MSE Std: 0.006362160022669814, Training Time: 0:00:01.521931, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10063, Cos Sim Mean: 0.4835929264772007, Cos Sim Std: 0.05946277891490407, MSE Mean: 0.13928955441024193, MSE Std: 0.0036288133733317182, Training Time: 0:00:01.784769, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10064, Cos Sim Mean: 0.4447224112691047, Cos Sim Std: 0.047643148085895655, MSE Mean: 0.1534022195877584, MSE Std: 0.007847474676663307, Training Time: 0:00:01.771034, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10065, Cos Sim Mean: 0.19083823040297374, Cos Sim Std: 0.0215694981809908, MSE Mean: 0.19861219783284723, MSE Std: 0.009682539809463498, Training Time: 0:00:01.791101, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10066, Cos Sim Mean: 0.4922114562202923, Cos Sim Std: 0.023416132805716566, MSE Mean: 0.14142686314811012, MSE Std: 0.007667565017738808, Training Time: 0:00:01.769577, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10067, Cos Sim Mean: 0.3751285033995243, Cos Sim Std: 0.041290598731635465, MSE Mean: 0.16494308135468166, MSE Std: 0.009631630377809144, Training Time: 0:00:01.791792, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10068, Cos Sim Mean: 0.17692518821905379, Cos Sim Std: 0.011735312060674142, MSE Mean: 0.21252339816165938, MSE Std: 0.007348234133890799, Training Time: 0:00:01.770644, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10069, Cos Sim Mean: 0.45883519076713075, Cos Sim Std: 0.04679897239991467, MSE Mean: 0.14847750295603357, MSE Std: 0.004211651542725091, Training Time: 0:00:01.764716, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10070, Cos Sim Mean: 0.19582356490795233, Cos Sim Std: 0.03710289673471403, MSE Mean: 0.1796587889089736, MSE Std: 0.005552451131287677, Training Time: 0:00:01.769289, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10071, Cos Sim Mean: 0.17692518905567456, Cos Sim Std: 0.01173531117754281, MSE Mean: 0.20870881001823544, MSE Std: 0.00827650593481652, Training Time: 0:00:01.761764, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10072, Cos Sim Mean: 0.17692518422557574, Cos Sim Std: 0.01173530642313119, MSE Mean: 0.15565016093195166, MSE Std: 0.006240722347750798, Training Time: 0:00:02.279572, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10073, Cos Sim Mean: 0.17692518301487245, Cos Sim Std: 0.011735310661911854, MSE Mean: 0.15850181528509025, MSE Std: 0.006066436582123336, Training Time: 0:00:02.178506, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10074, Cos Sim Mean: 0.17692518912745703, Cos Sim Std: 0.011735310866874453, MSE Mean: 0.18492723280379375, MSE Std: 0.005623937965246802, Training Time: 0:00:02.245165, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10075, Cos Sim Mean: 0.17692518445930563, Cos Sim Std: 0.01173531436087621, MSE Mean: 0.15710370442377056, MSE Std: 0.006884235981782024, Training Time: 0:00:02.199967, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10076, Cos Sim Mean: 0.17692518670178273, Cos Sim Std: 0.01173530797212503, MSE Mean: 0.162708766589081, MSE Std: 0.0070109748053968236, Training Time: 0:00:02.188701, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10077, Cos Sim Mean: 0.1769251881167418, Cos Sim Std: 0.011735310900187325, MSE Mean: 0.19768315421019664, MSE Std: 0.004692440939997205, Training Time: 0:00:02.204188, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10078, Cos Sim Mean: 0.17692518987961786, Cos Sim Std: 0.011735310576786971, MSE Mean: 0.16293307253101724, MSE Std: 0.007024237748792729, Training Time: 0:00:02.218388, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10079, Cos Sim Mean: 0.17692518601099866, Cos Sim Std: 0.011735313970291128, MSE Mean: 0.17438808814809087, MSE Std: 0.0076514071567777685, Training Time: 0:00:02.198348, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10080, Cos Sim Mean: 0.17692518864103357, Cos Sim Std: 0.01173531174483254, MSE Mean: 0.2260782747940208, MSE Std: 0.011789987374141955, Training Time: 0:00:02.201934, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10081, Cos Sim Mean: 0.1769251869814134, Cos Sim Std: 0.011735311317467852, MSE Mean: 0.1549576278058024, MSE Std: 0.0063927317799640365, Training Time: 0:00:04.028698, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10082, Cos Sim Mean: 0.17692517648112424, Cos Sim Std: 0.011735315073226064, MSE Mean: 0.15516212075138808, MSE Std: 0.006338206676600056, Training Time: 0:00:03.987632, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10083, Cos Sim Mean: 0.17692517714640826, Cos Sim Std: 0.011735306208157863, MSE Mean: 0.17322873435672498, MSE Std: 0.007865482480295005, Training Time: 0:00:03.761880, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10084, Cos Sim Mean: 0.1769251836300236, Cos Sim Std: 0.011735315495454923, MSE Mean: 0.15502889724303864, MSE Std: 0.006393597486084082, Training Time: 0:00:03.895008, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10085, Cos Sim Mean: 0.1769251854957472, Cos Sim Std: 0.011735305395213893, MSE Mean: 0.15599389127458343, MSE Std: 0.006597224031858895, Training Time: 0:00:04.061096, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10086, Cos Sim Mean: 0.17692518936482066, Cos Sim Std: 0.011735310689213518, MSE Mean: 0.18882456038553774, MSE Std: 0.012915587936964826, Training Time: 0:00:04.086368, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10087, Cos Sim Mean: 0.1769251868769746, Cos Sim Std: 0.011735314092952137, MSE Mean: 0.15769711372072254, MSE Std: 0.006149702272207396, Training Time: 0:00:04.138178, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10088, Cos Sim Mean: 0.17692517956407722, Cos Sim Std: 0.011735305940235113, MSE Mean: 0.16588569685745586, MSE Std: 0.0037422048857903693, Training Time: 0:00:04.080778, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10089, Cos Sim Mean: 0.17692517714640826, Cos Sim Std: 0.011735306208157863, MSE Mean: 0.2419717458789262, MSE Std: 0.013375823272289884, Training Time: 0:00:04.017564, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10090, Cos Sim Mean: 0.46262986999324085, Cos Sim Std: 0.03873365287377916, MSE Mean: 0.13229452399868327, MSE Std: 0.00855809546556774, Training Time: 0:00:02.052961, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10091, Cos Sim Mean: 0.4767606840240618, Cos Sim Std: 0.05624875225010992, MSE Mean: 0.13708494569652246, MSE Std: 0.01102453379452349, Training Time: 0:00:02.013626, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10092, Cos Sim Mean: 0.4256861531345709, Cos Sim Std: 0.042008103351144445, MSE Mean: 0.15665854380790284, MSE Std: 0.008909844532509485, Training Time: 0:00:02.029224, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10093, Cos Sim Mean: 0.46946647354162885, Cos Sim Std: 0.04451566992189512, MSE Mean: 0.13284876274406052, MSE Std: 0.013927089924424601, Training Time: 0:00:02.035426, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10094, Cos Sim Mean: 0.46791296522055326, Cos Sim Std: 0.03568430838902412, MSE Mean: 0.13798835085634903, MSE Std: 0.007779809114784833, Training Time: 0:00:02.054672, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10095, Cos Sim Mean: 0.43485052172996175, Cos Sim Std: 0.04718755460811349, MSE Mean: 0.15437281840940134, MSE Std: 0.010176000161429907, Training Time: 0:00:02.038201, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10096, Cos Sim Mean: 0.4994267524391165, Cos Sim Std: 0.04238919742989092, MSE Mean: 0.12410166711673805, MSE Std: 0.007972376374099935, Training Time: 0:00:02.034347, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10097, Cos Sim Mean: 0.4678067264323671, Cos Sim Std: 0.02035292091019036, MSE Mean: 0.1351701413108657, MSE Std: 0.011582205555031835, Training Time: 0:00:02.060106, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10098, Cos Sim Mean: 0.423854471899197, Cos Sim Std: 0.036131661222628175, MSE Mean: 0.15106871512056858, MSE Std: 0.00953911664872263, Training Time: 0:00:02.025171, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10099, Cos Sim Mean: 0.48247929975169956, Cos Sim Std: 0.08726524098825306, MSE Mean: 0.12432512538364801, MSE Std: 0.008540846875859294, Training Time: 0:00:02.461758, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10100, Cos Sim Mean: 0.5031185811453303, Cos Sim Std: 0.041466247341156136, MSE Mean: 0.13105801472214468, MSE Std: 0.005751700470437427, Training Time: 0:00:02.451948, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10101, Cos Sim Mean: 0.4503485192443125, Cos Sim Std: 0.0496974554233957, MSE Mean: 0.1531044874663689, MSE Std: 0.005016571441995043, Training Time: 0:00:02.486862, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10102, Cos Sim Mean: 0.47704967377865753, Cos Sim Std: 0.0687131156463962, MSE Mean: 0.12969848457878852, MSE Std: 0.01212368081115995, Training Time: 0:00:02.457363, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10103, Cos Sim Mean: 0.48758591814130064, Cos Sim Std: 0.0650788276895708, MSE Mean: 0.13633277520168882, MSE Std: 0.0063914754713133674, Training Time: 0:00:02.431068, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10104, Cos Sim Mean: 0.35542893874928677, Cos Sim Std: 0.07096143004944871, MSE Mean: 0.16495758307605263, MSE Std: 0.0026652735161890114, Training Time: 0:00:02.470995, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10105, Cos Sim Mean: 0.49085820616397857, Cos Sim Std: 0.04730263280237956, MSE Mean: 0.12804125837361294, MSE Std: 0.005410039149903628, Training Time: 0:00:02.449894, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10106, Cos Sim Mean: 0.46980154281888586, Cos Sim Std: 0.044927452830700654, MSE Mean: 0.14281593226143613, MSE Std: 0.0026954677682266125, Training Time: 0:00:02.423862, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10107, Cos Sim Mean: 0.2951682069247615, Cos Sim Std: 0.1147825816725871, MSE Mean: 0.17180308913309683, MSE Std: 0.006749059613471749, Training Time: 0:00:02.474208, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10108, Cos Sim Mean: 0.48193958289166383, Cos Sim Std: 0.03806001914868867, MSE Mean: 0.1251552735956734, MSE Std: 0.007449574253892724, Training Time: 0:00:02.852311, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10109, Cos Sim Mean: 0.46771920723850047, Cos Sim Std: 0.03988741509328159, MSE Mean: 0.14017824114804492, MSE Std: 0.008049213636271563, Training Time: 0:00:02.836923, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10110, Cos Sim Mean: 0.17692518779254846, Cos Sim Std: 0.01173531083788287, MSE Mean: 0.16619275090690358, MSE Std: 0.007251715898093692, Training Time: 0:00:02.826239, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10111, Cos Sim Mean: 0.49439655497861396, Cos Sim Std: 0.05303042979527174, MSE Mean: 0.12913371635998022, MSE Std: 0.008771758260188499, Training Time: 0:00:02.828990, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10112, Cos Sim Mean: 0.3738874755611597, Cos Sim Std: 0.10665552978982126, MSE Mean: 0.15208183703979516, MSE Std: 0.00507441103738333, Training Time: 0:00:02.826372, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10113, Cos Sim Mean: 0.17692518570778054, Cos Sim Std: 0.01173531426596671, MSE Mean: 0.17021382578910477, MSE Std: 0.005925390773565131, Training Time: 0:00:02.825685, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10114, Cos Sim Mean: 0.4819221395092175, Cos Sim Std: 0.0643303948869715, MSE Mean: 0.13661910253817372, MSE Std: 0.007589071724737518, Training Time: 0:00:02.808650, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10115, Cos Sim Mean: 0.27373678288945935, Cos Sim Std: 0.11866844796535103, MSE Mean: 0.1589642526965743, MSE Std: 0.007877804373044807, Training Time: 0:00:02.807601, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10116, Cos Sim Mean: 0.17692518731944118, Cos Sim Std: 0.011735310914291908, MSE Mean: 0.17918259447123833, MSE Std: 0.008145626349128183, Training Time: 0:00:02.845280, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10117, Cos Sim Mean: 0.17692518491961515, Cos Sim Std: 0.01173530659339857, MSE Mean: 0.1549883658290004, MSE Std: 0.006384268066865159, Training Time: 0:00:03.594408, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10118, Cos Sim Mean: 0.17692518570737245, Cos Sim Std: 0.011735305390141643, MSE Mean: 0.1552832253929261, MSE Std: 0.006376026693441182, Training Time: 0:00:03.529679, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10119, Cos Sim Mean: 0.1769251847047571, Cos Sim Std: 0.01173531663002572, MSE Mean: 0.1592615861649989, MSE Std: 0.006578808898178135, Training Time: 0:00:03.551751, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10120, Cos Sim Mean: 0.17692518617793543, Cos Sim Std: 0.011735314189212453, MSE Mean: 0.15512120107911803, MSE Std: 0.00636240305812164, Training Time: 0:00:03.551094, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10121, Cos Sim Mean: 0.17692518497259707, Cos Sim Std: 0.011735306637378776, MSE Mean: 0.1560101140349941, MSE Std: 0.006211011291236489, Training Time: 0:00:03.559383, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10122, Cos Sim Mean: 0.17692518529973528, Cos Sim Std: 0.011735313311025224, MSE Mean: 0.16486135910322042, MSE Std: 0.004967645885524079, Training Time: 0:00:03.551019, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10123, Cos Sim Mean: 0.17692518664479584, Cos Sim Std: 0.011735310317321291, MSE Mean: 0.15592141448980024, MSE Std: 0.006395198501837814, Training Time: 0:00:03.498815, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10124, Cos Sim Mean: 0.1769251841658483, Cos Sim Std: 0.011735313317873695, MSE Mean: 0.15992180000169187, MSE Std: 0.006777632574316776, Training Time: 0:00:03.489483, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10125, Cos Sim Mean: 0.1769251851555365, Cos Sim Std: 0.011735309703400301, MSE Mean: 0.17661712210411737, MSE Std: 0.0090751242563771, Training Time: 0:00:03.565393, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10126, Cos Sim Mean: 0.17692518441089505, Cos Sim Std: 0.011735313665039564, MSE Mean: 0.1549528936405203, MSE Std: 0.006394564340990212, Training Time: 0:00:06.653532, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10127, Cos Sim Mean: 0.1769251872592586, Cos Sim Std: 0.011735311533105384, MSE Mean: 0.1549593261743318, MSE Std: 0.006395258233565631, Training Time: 0:00:06.531505, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10128, Cos Sim Mean: 0.17692518470055935, Cos Sim Std: 0.011735315031307512, MSE Mean: 0.15639847667943485, MSE Std: 0.0064810632105621845, Training Time: 0:00:07.079329, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10129, Cos Sim Mean: 0.17692518570737245, Cos Sim Std: 0.011735305390141643, MSE Mean: 0.15495641437360588, MSE Std: 0.006393103846146174, Training Time: 0:00:06.911305, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10130, Cos Sim Mean: 0.17692518377510363, Cos Sim Std: 0.011735314433989848, MSE Mean: 0.15500627719482404, MSE Std: 0.00639238303864633, Training Time: 0:00:06.934503, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10131, Cos Sim Mean: 0.17692517426573368, Cos Sim Std: 0.011735305625737293, MSE Mean: 0.1602306795679072, MSE Std: 0.0068296378593035705, Training Time: 0:00:06.430846, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10132, Cos Sim Mean: 0.17692518280279187, Cos Sim Std: 0.011735314569520964, MSE Mean: 0.15495806243938004, MSE Std: 0.006393926614819817, Training Time: 0:00:06.744596, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10133, Cos Sim Mean: 0.1769251872592586, Cos Sim Std: 0.011735311533105384, MSE Mean: 0.15558732572844688, MSE Std: 0.006212170953426677, Training Time: 0:00:06.801725, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10134, Cos Sim Mean: 0.17692518617793543, Cos Sim Std: 0.011735314189212453, MSE Mean: 0.1744053319870859, MSE Std: 0.0065258550482655995, Training Time: 0:00:06.741707, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10135, Cos Sim Mean: 0.47900454432763784, Cos Sim Std: 0.07176238831870355, MSE Mean: 0.18895830963648233, MSE Std: 0.01799090760287494, Training Time: 0:00:01.457309, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10136, Cos Sim Mean: 0.46296100077256314, Cos Sim Std: 0.058369619505939684, MSE Mean: 0.19060881048252315, MSE Std: 0.009622677828745508, Training Time: 0:00:01.384552, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10137, Cos Sim Mean: 0.3696655379605564, Cos Sim Std: 0.10028016967377802, MSE Mean: 0.21991700419932636, MSE Std: 0.004066022683223117, Training Time: 0:00:01.376131, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10138, Cos Sim Mean: 0.46610120358624485, Cos Sim Std: 0.037415956968816284, MSE Mean: 0.18869879464810882, MSE Std: 0.01401242331241986, Training Time: 0:00:01.409772, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10139, Cos Sim Mean: 0.42047310032677243, Cos Sim Std: 0.06171351009856613, MSE Mean: 0.19298083694362472, MSE Std: 0.00982653338886685, Training Time: 0:00:01.353054, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10140, Cos Sim Mean: 0.41781449471713455, Cos Sim Std: 0.10042384622232454, MSE Mean: 0.21442605138097287, MSE Std: 0.009620722665816246, Training Time: 0:00:01.385919, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10141, Cos Sim Mean: 0.41522650986638815, Cos Sim Std: 0.0256955198565344, MSE Mean: 0.17092301040428487, MSE Std: 0.01430921855155805, Training Time: 0:00:01.387016, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10142, Cos Sim Mean: 0.39111813091243963, Cos Sim Std: 0.05282068815481096, MSE Mean: 0.18467214215003352, MSE Std: 0.01725464098167547, Training Time: 0:00:01.374539, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10143, Cos Sim Mean: 0.3840835845479231, Cos Sim Std: 0.10196709117273373, MSE Mean: 0.20540590702051484, MSE Std: 0.019148432089368075, Training Time: 0:00:01.383145, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10144, Cos Sim Mean: 0.4925289122706557, Cos Sim Std: 0.04615841639940375, MSE Mean: 0.1534391419042507, MSE Std: 0.004288649663047782, Training Time: 0:00:01.667463, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10145, Cos Sim Mean: 0.46625606167516603, Cos Sim Std: 0.036795976859616344, MSE Mean: 0.16996056484146085, MSE Std: 0.006025202610109961, Training Time: 0:00:01.687829, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10146, Cos Sim Mean: 0.3801843289222423, Cos Sim Std: 0.03818464154779103, MSE Mean: 0.222082062442, MSE Std: 0.005252572358010088, Training Time: 0:00:01.690411, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10147, Cos Sim Mean: 0.49432300638669024, Cos Sim Std: 0.046529956209484205, MSE Mean: 0.1575322554246053, MSE Std: 0.005721629960959539, Training Time: 0:00:01.694512, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10148, Cos Sim Mean: 0.4576889573754267, Cos Sim Std: 0.05193673580418136, MSE Mean: 0.18005818156131453, MSE Std: 0.005140350893401082, Training Time: 0:00:01.672306, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10149, Cos Sim Mean: 0.3576926367437142, Cos Sim Std: 0.07731880203216956, MSE Mean: 0.23466338200732104, MSE Std: 0.0051729225385050304, Training Time: 0:00:01.915600, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10150, Cos Sim Mean: 0.4554078771562657, Cos Sim Std: 0.040664995084549765, MSE Mean: 0.1624060504212415, MSE Std: 0.007910417517934807, Training Time: 0:00:01.695600, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10151, Cos Sim Mean: 0.36926971558824917, Cos Sim Std: 0.08246317806132798, MSE Mean: 0.19128983650154935, MSE Std: 0.006846579256156978, Training Time: 0:00:01.656406, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10152, Cos Sim Mean: 0.17692518864290904, Cos Sim Std: 0.011735312412516321, MSE Mean: 0.23569222923939206, MSE Std: 0.01157540031328171, Training Time: 0:00:01.714645, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10153, Cos Sim Mean: 0.4468433583897785, Cos Sim Std: 0.07195602216815153, MSE Mean: 0.14756213848687355, MSE Std: 0.006570401177855763, Training Time: 0:00:01.994687, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10154, Cos Sim Mean: 0.4155882945868957, Cos Sim Std: 0.08841958333134198, MSE Mean: 0.16994182405953978, MSE Std: 0.0044413612580265225, Training Time: 0:00:01.976624, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10155, Cos Sim Mean: 0.20301214480242283, Cos Sim Std: 0.04496832108901865, MSE Mean: 0.23845721403999276, MSE Std: 0.013002942016951315, Training Time: 0:00:01.966796, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10156, Cos Sim Mean: 0.460623776424108, Cos Sim Std: 0.05196822655752971, MSE Mean: 0.15417203966745943, MSE Std: 0.0064979387729815225, Training Time: 0:00:01.970910, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10157, Cos Sim Mean: 0.2869375291965338, Cos Sim Std: 0.08577508889207001, MSE Mean: 0.1909801227626135, MSE Std: 0.00479051621546077, Training Time: 0:00:01.964686, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10158, Cos Sim Mean: 0.17692518576240157, Cos Sim Std: 0.0117353145595673, MSE Mean: 0.2562540411708963, MSE Std: 0.005861082625486881, Training Time: 0:00:01.963997, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10159, Cos Sim Mean: 0.44887476281981825, Cos Sim Std: 0.058245759104234504, MSE Mean: 0.16652867071547534, MSE Std: 0.005314211070135866, Training Time: 0:00:01.961546, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10160, Cos Sim Mean: 0.21518605919618655, Cos Sim Std: 0.06902673259005511, MSE Mean: 0.20496616837119058, MSE Std: 0.009077460540421401, Training Time: 0:00:01.958759, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10161, Cos Sim Mean: 0.17692518774855517, Cos Sim Std: 0.011735309389029164, MSE Mean: 0.2650116769193573, MSE Std: 0.013774848757286165, Training Time: 0:00:01.954496, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10162, Cos Sim Mean: 0.17692518731830922, Cos Sim Std: 0.01173531085654504, MSE Mean: 0.1561842209541465, MSE Std: 0.006110983541922558, Training Time: 0:00:02.476860, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10163, Cos Sim Mean: 0.17692518873918972, Cos Sim Std: 0.01173531141442403, MSE Mean: 0.16155993126641938, MSE Std: 0.005621064551470741, Training Time: 0:00:02.471523, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10164, Cos Sim Mean: 0.1769251880852309, Cos Sim Std: 0.011735311035534516, MSE Mean: 0.20311376941897158, MSE Std: 0.008031329979663425, Training Time: 0:00:02.463268, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10165, Cos Sim Mean: 0.17692518832454873, Cos Sim Std: 0.011735311981713733, MSE Mean: 0.160025765159578, MSE Std: 0.0064078463164642255, Training Time: 0:00:02.472866, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10166, Cos Sim Mean: 0.1769251855917102, Cos Sim Std: 0.011735310362873787, MSE Mean: 0.17231984668272712, MSE Std: 0.005293744262482151, Training Time: 0:00:02.485183, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10167, Cos Sim Mean: 0.176925186958127, Cos Sim Std: 0.011735314621767941, MSE Mean: 0.24265908513446757, MSE Std: 0.014598657034897409, Training Time: 0:00:02.474784, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10168, Cos Sim Mean: 0.17692518765933712, Cos Sim Std: 0.011735310312847006, MSE Mean: 0.17186318957524643, MSE Std: 0.009913116378243724, Training Time: 0:00:02.467041, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10169, Cos Sim Mean: 0.1769251877561749, Cos Sim Std: 0.011735309251609533, MSE Mean: 0.19797241132989993, MSE Std: 0.01263991808799652, Training Time: 0:00:02.484843, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10170, Cos Sim Mean: 0.17692518671021892, Cos Sim Std: 0.011735313494581614, MSE Mean: 0.2843698859298055, MSE Std: 0.02250055683224979, Training Time: 0:00:02.488476, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10171, Cos Sim Mean: 0.17692518936482066, Cos Sim Std: 0.011735310689213518, MSE Mean: 0.15496538711290903, MSE Std: 0.006393939045014311, Training Time: 0:00:04.247664, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10172, Cos Sim Mean: 0.17692518067858587, Cos Sim Std: 0.011735311963082482, MSE Mean: 0.1553946586131413, MSE Std: 0.00632090250571223, Training Time: 0:00:04.367354, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10173, Cos Sim Mean: 0.17692517854372075, Cos Sim Std: 0.011735309234206636, MSE Mean: 0.18049164702460058, MSE Std: 0.0049735315876577035, Training Time: 0:00:04.243765, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10174, Cos Sim Mean: 0.17692518805059204, Cos Sim Std: 0.011735310856702291, MSE Mean: 0.15509194576807517, MSE Std: 0.006381090068385345, Training Time: 0:00:04.374690, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10175, Cos Sim Mean: 0.17692518936482066, Cos Sim Std: 0.011735310689213518, MSE Mean: 0.15717454932332958, MSE Std: 0.006430353347834399, Training Time: 0:00:04.341342, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10176, Cos Sim Mean: 0.17692518055735723, Cos Sim Std: 0.011735312536146592, MSE Mean: 0.2143665168194528, MSE Std: 0.015584891173601302, Training Time: 0:00:04.310169, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10177, Cos Sim Mean: 0.17692518530701612, Cos Sim Std: 0.011735315064560745, MSE Mean: 0.1586836719997127, MSE Std: 0.006157628379301647, Training Time: 0:00:04.206939, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10178, Cos Sim Mean: 0.176925189446203, Cos Sim Std: 0.011735311722460836, MSE Mean: 0.17284818765521812, MSE Std: 0.0035619405717728704, Training Time: 0:00:04.385001, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10179, Cos Sim Mean: 0.17692518422557574, Cos Sim Std: 0.01173530642313119, MSE Mean: 0.3044823806523971, MSE Std: 0.014436428824663434, Training Time: 0:00:04.499265, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10180, Cos Sim Mean: 0.44153894203322697, Cos Sim Std: 0.04527990461911714, MSE Mean: 0.14659505284901786, MSE Std: 0.011513456348147464, Training Time: 0:00:01.930584, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10181, Cos Sim Mean: 0.3995520863168033, Cos Sim Std: 0.05083745097532613, MSE Mean: 0.15483456637982146, MSE Std: 0.010697375640439778, Training Time: 0:00:01.850655, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10182, Cos Sim Mean: 0.41391715929153144, Cos Sim Std: 0.05246608061443426, MSE Mean: 0.168275791889655, MSE Std: 0.006393318483360504, Training Time: 0:00:01.853626, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10183, Cos Sim Mean: 0.4029900346420502, Cos Sim Std: 0.02293941979353633, MSE Mean: 0.1501967850876334, MSE Std: 0.011434585798287383, Training Time: 0:00:01.879560, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10184, Cos Sim Mean: 0.39439522931481524, Cos Sim Std: 0.058667062675505754, MSE Mean: 0.15735094375354985, MSE Std: 0.010640959275402116, Training Time: 0:00:01.823705, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10185, Cos Sim Mean: 0.3961677065555955, Cos Sim Std: 0.05170106671363302, MSE Mean: 0.16919191534537564, MSE Std: 0.0076174695777028656, Training Time: 0:00:01.856619, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10186, Cos Sim Mean: 0.39622649578247127, Cos Sim Std: 0.045094920602140695, MSE Mean: 0.14808076228684378, MSE Std: 0.014638950725706782, Training Time: 0:00:01.870508, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10187, Cos Sim Mean: 0.41700351965151083, Cos Sim Std: 0.031296595109154925, MSE Mean: 0.15387361919584602, MSE Std: 0.012993222101058558, Training Time: 0:00:01.850199, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10188, Cos Sim Mean: 0.3857195745168297, Cos Sim Std: 0.04205786126267084, MSE Mean: 0.17072566390848662, MSE Std: 0.013524117594352228, Training Time: 0:00:01.858142, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10189, Cos Sim Mean: 0.44000029329389373, Cos Sim Std: 0.039894096829696295, MSE Mean: 0.1363006001846318, MSE Std: 0.005274380838005922, Training Time: 0:00:02.190545, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10190, Cos Sim Mean: 0.40139938852989127, Cos Sim Std: 0.04863323051976713, MSE Mean: 0.14420586079848882, MSE Std: 0.0046493077207158, Training Time: 0:00:02.215517, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10191, Cos Sim Mean: 0.39243658352962296, Cos Sim Std: 0.05156433272984358, MSE Mean: 0.16427665198712202, MSE Std: 0.006434613836912774, Training Time: 0:00:02.243971, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10192, Cos Sim Mean: 0.4472474872923599, Cos Sim Std: 0.06553814646107356, MSE Mean: 0.13768401456740334, MSE Std: 0.005182869518784394, Training Time: 0:00:02.238802, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10193, Cos Sim Mean: 0.4170525453998545, Cos Sim Std: 0.04402835923240825, MSE Mean: 0.14806549353983908, MSE Std: 0.0026099322424865553, Training Time: 0:00:02.210159, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10194, Cos Sim Mean: 0.33637378338997964, Cos Sim Std: 0.03512975585952765, MSE Mean: 0.1742957788663388, MSE Std: 0.004182847507620102, Training Time: 0:00:02.247439, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10195, Cos Sim Mean: 0.4436852553751903, Cos Sim Std: 0.05506335288815745, MSE Mean: 0.13940259875891903, MSE Std: 0.005587390145316665, Training Time: 0:00:02.228737, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10196, Cos Sim Mean: 0.4258267737648297, Cos Sim Std: 0.02993533215601285, MSE Mean: 0.15523305637318366, MSE Std: 0.0075372957509999144, Training Time: 0:00:02.185475, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10197, Cos Sim Mean: 0.18218961460472155, Cos Sim Std: 0.01250816363656547, MSE Mean: 0.1826833934998972, MSE Std: 0.007858013676150046, Training Time: 0:00:02.248230, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10198, Cos Sim Mean: 0.415302757923924, Cos Sim Std: 0.04692205183474726, MSE Mean: 0.1471545834093701, MSE Std: 0.010326554382465911, Training Time: 0:00:02.597148, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10199, Cos Sim Mean: 0.35624984263459897, Cos Sim Std: 0.09975206041438789, MSE Mean: 0.15061668803584788, MSE Std: 0.006895121398784065, Training Time: 0:00:02.583027, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10200, Cos Sim Mean: 0.1769251864182876, Cos Sim Std: 0.011735311010027373, MSE Mean: 0.16978029126528632, MSE Std: 0.007213084402645975, Training Time: 0:00:02.562052, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10201, Cos Sim Mean: 0.42036914337365217, Cos Sim Std: 0.04440158498532856, MSE Mean: 0.14862191907617753, MSE Std: 0.008179020403518915, Training Time: 0:00:02.575683, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10202, Cos Sim Mean: 0.2378516819061201, Cos Sim Std: 0.06266515119263358, MSE Mean: 0.16104245478169835, MSE Std: 0.004926158674933401, Training Time: 0:00:02.563474, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10203, Cos Sim Mean: 0.176925185653822, Cos Sim Std: 0.011735310897400816, MSE Mean: 0.17988209698038451, MSE Std: 0.005939065392251204, Training Time: 0:00:02.578130, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10204, Cos Sim Mean: 0.394914260666978, Cos Sim Std: 0.09736058308324196, MSE Mean: 0.1477060843467311, MSE Std: 0.009301431365392757, Training Time: 0:00:02.554791, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10205, Cos Sim Mean: 0.17692518871530932, Cos Sim Std: 0.011735308962637133, MSE Mean: 0.1681757286388459, MSE Std: 0.007078606601378948, Training Time: 0:00:02.565306, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10206, Cos Sim Mean: 0.17692518352447847, Cos Sim Std: 0.011735311190639796, MSE Mean: 0.1926796155754374, MSE Std: 0.012072993327282077, Training Time: 0:00:02.558434, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10207, Cos Sim Mean: 0.17692518915816766, Cos Sim Std: 0.01173531011181725, MSE Mean: 0.15499527834410962, MSE Std: 0.006381005708620635, Training Time: 0:00:03.213206, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10208, Cos Sim Mean: 0.17692518189752324, Cos Sim Std: 0.011735313870542524, MSE Mean: 0.15534240486506393, MSE Std: 0.006396170911480971, Training Time: 0:00:03.214115, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10209, Cos Sim Mean: 0.176925188419703, Cos Sim Std: 0.01173531066454029, MSE Mean: 0.15998104851789724, MSE Std: 0.006717645618251903, Training Time: 0:00:03.205840, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10210, Cos Sim Mean: 0.1769251785415696, Cos Sim Std: 0.011735305993096648, MSE Mean: 0.15516889653866275, MSE Std: 0.006303549422680761, Training Time: 0:00:03.215080, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10211, Cos Sim Mean: 0.17692518554145542, Cos Sim Std: 0.011735307672369091, MSE Mean: 0.15638991757645573, MSE Std: 0.006082238332609261, Training Time: 0:00:03.234009, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10212, Cos Sim Mean: 0.17692518628934914, Cos Sim Std: 0.011735305342557196, MSE Mean: 0.16902946729430793, MSE Std: 0.004891317841355796, Training Time: 0:00:03.208744, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10213, Cos Sim Mean: 0.17692518904341875, Cos Sim Std: 0.011735312411193313, MSE Mean: 0.1562085440120655, MSE Std: 0.006461272359178828, Training Time: 0:00:03.758890, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10214, Cos Sim Mean: 0.17692518667032164, Cos Sim Std: 0.011735313515555741, MSE Mean: 0.1612975525775109, MSE Std: 0.007341876743517044, Training Time: 0:00:03.201115, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10215, Cos Sim Mean: 0.1769251858641946, Cos Sim Std: 0.011735314773859227, MSE Mean: 0.19070650471255465, MSE Std: 0.015965742202258135, Training Time: 0:00:03.191044, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10216, Cos Sim Mean: 0.17692518497259707, Cos Sim Std: 0.011735306637378776, MSE Mean: 0.15495342670332596, MSE Std: 0.006393870762277431, Training Time: 0:00:06.315072, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10217, Cos Sim Mean: 0.17692518474588678, Cos Sim Std: 0.011735311738608993, MSE Mean: 0.15496002057645558, MSE Std: 0.006395728467654781, Training Time: 0:00:06.157127, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10218, Cos Sim Mean: 0.17692518531158746, Cos Sim Std: 0.011735314412704324, MSE Mean: 0.15668445403509762, MSE Std: 0.006643711516620363, Training Time: 0:00:06.106538, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10219, Cos Sim Mean: 0.17692518915816766, Cos Sim Std: 0.01173531011181725, MSE Mean: 0.15496107580602803, MSE Std: 0.006392650257437841, Training Time: 0:00:06.201557, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10220, Cos Sim Mean: 0.17692518570737245, Cos Sim Std: 0.011735305390141643, MSE Mean: 0.1549949313565008, MSE Std: 0.006388321767037364, Training Time: 0:00:05.747248, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10221, Cos Sim Mean: 0.1769251862556806, Cos Sim Std: 0.011735314082845602, MSE Mean: 0.16089717873826576, MSE Std: 0.005955989439288033, Training Time: 0:00:06.461446, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10222, Cos Sim Mean: 0.17692518450612593, Cos Sim Std: 0.011735307275579681, MSE Mean: 0.15495394101635002, MSE Std: 0.006394272405910815, Training Time: 0:00:06.338148, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10223, Cos Sim Mean: 0.17692518441089505, Cos Sim Std: 0.011735313665039564, MSE Mean: 0.1556671515182976, MSE Std: 0.006157795402855436, Training Time: 0:00:06.220088, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10224, Cos Sim Mean: 0.17692518915816766, Cos Sim Std: 0.01173531011181725, MSE Mean: 0.1751353456676544, MSE Std: 0.007563264055907116, Training Time: 0:00:06.531217, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10225, Cos Sim Mean: 0.36494468866916696, Cos Sim Std: 0.07731163701221126, MSE Mean: 0.2115909138747487, MSE Std: 0.016666103019054156, Training Time: 0:00:01.217492, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10226, Cos Sim Mean: 0.39113993906456057, Cos Sim Std: 0.06852163644417902, MSE Mean: 0.2201944737139292, MSE Std: 0.01222180258225725, Training Time: 0:00:01.246087, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10227, Cos Sim Mean: 0.35923107866431764, Cos Sim Std: 0.03151601872290652, MSE Mean: 0.24074908911577503, MSE Std: 0.01188923643686455, Training Time: 0:00:01.256500, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10228, Cos Sim Mean: 0.38068893535001685, Cos Sim Std: 0.0831786027789918, MSE Mean: 0.20640064417815815, MSE Std: 0.015855228210264048, Training Time: 0:00:01.238407, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10229, Cos Sim Mean: 0.3842663722305189, Cos Sim Std: 0.0707658676880596, MSE Mean: 0.2178339235063944, MSE Std: 0.012015376168846318, Training Time: 0:00:01.242798, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10230, Cos Sim Mean: 0.37985161942618384, Cos Sim Std: 0.01806672539414319, MSE Mean: 0.24170234535855523, MSE Std: 0.010485976348695775, Training Time: 0:00:01.223450, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10231, Cos Sim Mean: 0.3856555208751453, Cos Sim Std: 0.0414852455273731, MSE Mean: 0.19218507288498646, MSE Std: 0.017601300414017678, Training Time: 0:00:01.262682, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10232, Cos Sim Mean: 0.3698578463522341, Cos Sim Std: 0.0380483278051531, MSE Mean: 0.20952539831975772, MSE Std: 0.021192942114969388, Training Time: 0:00:01.243531, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10233, Cos Sim Mean: 0.3291543661211348, Cos Sim Std: 0.02997161178227654, MSE Mean: 0.2331978849539031, MSE Std: 0.0178881546999862, Training Time: 0:00:01.244487, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10234, Cos Sim Mean: 0.40673449807457696, Cos Sim Std: 0.054135547993699955, MSE Mean: 0.16996674078422727, MSE Std: 0.006562477586842737, Training Time: 0:00:01.515031, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10235, Cos Sim Mean: 0.3974709207840002, Cos Sim Std: 0.02729469125110606, MSE Mean: 0.1935116680600733, MSE Std: 0.006318254403554427, Training Time: 0:00:01.514572, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10236, Cos Sim Mean: 0.3377715634793602, Cos Sim Std: 0.025885856325006024, MSE Mean: 0.2454504519579827, MSE Std: 0.00980022157287132, Training Time: 0:00:01.503165, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10237, Cos Sim Mean: 0.3924555824320762, Cos Sim Std: 0.01788113729918604, MSE Mean: 0.18129260461919797, MSE Std: 0.005508113634034211, Training Time: 0:00:01.531406, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10238, Cos Sim Mean: 0.3834079671907878, Cos Sim Std: 0.014264381642039716, MSE Mean: 0.20723351469526655, MSE Std: 0.004685129418666231, Training Time: 0:00:01.510375, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10239, Cos Sim Mean: 0.24158585075833203, Cos Sim Std: 0.043654994711057646, MSE Mean: 0.26353660466888573, MSE Std: 0.01195962942344186, Training Time: 0:00:01.498799, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10240, Cos Sim Mean: 0.42967672623645825, Cos Sim Std: 0.0487081279200207, MSE Mean: 0.18954038083046726, MSE Std: 0.011546829568941352, Training Time: 0:00:01.519489, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10241, Cos Sim Mean: 0.3136055261401629, Cos Sim Std: 0.0809825934008751, MSE Mean: 0.22233587399188962, MSE Std: 0.013671242750266002, Training Time: 0:00:01.520801, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10242, Cos Sim Mean: 0.17692518661571915, Cos Sim Std: 0.011735312848584716, MSE Mean: 0.26313689619078373, MSE Std: 0.015184374735821784, Training Time: 0:00:01.500409, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10243, Cos Sim Mean: 0.4365039240099259, Cos Sim Std: 0.04783899574017509, MSE Mean: 0.1593653656201443, MSE Std: 0.008058314395447033, Training Time: 0:00:01.801988, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10244, Cos Sim Mean: 0.29407960234529873, Cos Sim Std: 0.07420570614679026, MSE Mean: 0.1897896023688396, MSE Std: 0.008595153281766795, Training Time: 0:00:01.731035, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10245, Cos Sim Mean: 0.1769251891538951, Cos Sim Std: 0.011735308819354204, MSE Mean: 0.2573378647839014, MSE Std: 0.018064414798763802, Training Time: 0:00:01.766380, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10246, Cos Sim Mean: 0.4047846073501513, Cos Sim Std: 0.024438273362505543, MSE Mean: 0.17196802985632378, MSE Std: 0.006940160374254885, Training Time: 0:00:01.778523, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10247, Cos Sim Mean: 0.2132901793852851, Cos Sim Std: 0.041189180401349786, MSE Mean: 0.212264425305021, MSE Std: 0.008147713669697973, Training Time: 0:00:01.770206, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10248, Cos Sim Mean: 0.1769251849707268, Cos Sim Std: 0.011735315262791313, MSE Mean: 0.2927314273207785, MSE Std: 0.012758906403338328, Training Time: 0:00:01.752396, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10249, Cos Sim Mean: 0.32207417033182184, Cos Sim Std: 0.07563033519149515, MSE Mean: 0.19177858880183912, MSE Std: 0.01300350919858481, Training Time: 0:00:01.752562, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10250, Cos Sim Mean: 0.1769251880798463, Cos Sim Std: 0.011735311907926664, MSE Mean: 0.23246233748585388, MSE Std: 0.015319713966537724, Training Time: 0:00:01.775847, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10251, Cos Sim Mean: 0.17692518918624425, Cos Sim Std: 0.01173531049589129, MSE Mean: 0.30013874042200134, MSE Std: 0.021214015334683558, Training Time: 0:00:01.756695, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10252, Cos Sim Mean: 0.17692518592099674, Cos Sim Std: 0.01173530783049773, MSE Mean: 0.1566246492083621, MSE Std: 0.0061264544219901546, Training Time: 0:00:02.216652, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10253, Cos Sim Mean: 0.17692518722854797, Cos Sim Std: 0.011735312288162533, MSE Mean: 0.16389256949779576, MSE Std: 0.006600607342412306, Training Time: 0:00:02.200553, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10254, Cos Sim Mean: 0.17692518857589737, Cos Sim Std: 0.011735309614545988, MSE Mean: 0.21837902888492716, MSE Std: 0.015791035952301663, Training Time: 0:00:02.205427, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10255, Cos Sim Mean: 0.1769251881024691, Cos Sim Std: 0.011735310552819024, MSE Mean: 0.1611081770281934, MSE Std: 0.005441571177179821, Training Time: 0:00:02.211175, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10256, Cos Sim Mean: 0.17692518505888896, Cos Sim Std: 0.01173531093169727, MSE Mean: 0.17800511283513618, MSE Std: 0.004477713014932378, Training Time: 0:00:02.214806, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10257, Cos Sim Mean: 0.17692518851922392, Cos Sim Std: 0.011735310966554374, MSE Mean: 0.26362938896451393, MSE Std: 0.010270956930372766, Training Time: 0:00:02.235384, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10258, Cos Sim Mean: 0.1769251873908279, Cos Sim Std: 0.011735312058058472, MSE Mean: 0.1756565641181507, MSE Std: 0.011366135855943453, Training Time: 0:00:02.375901, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10259, Cos Sim Mean: 0.17692518623781123, Cos Sim Std: 0.01173531412492949, MSE Mean: 0.21298717536951717, MSE Std: 0.019563097255219, Training Time: 0:00:02.219807, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10260, Cos Sim Mean: 0.17692518956313302, Cos Sim Std: 0.011735310813668222, MSE Mean: 0.3244504330256226, MSE Std: 0.038771228476989175, Training Time: 0:00:02.223354, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10261, Cos Sim Mean: 0.17692518466646517, Cos Sim Std: 0.011735306529793547, MSE Mean: 0.1549639298337228, MSE Std: 0.006392129892639526, Training Time: 0:00:03.868502, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10262, Cos Sim Mean: 0.17692518483046318, Cos Sim Std: 0.011735314260283177, MSE Mean: 0.155409130555817, MSE Std: 0.006352484725227347, Training Time: 0:00:04.035777, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10263, Cos Sim Mean: 0.17692518648902722, Cos Sim Std: 0.011735311991124295, MSE Mean: 0.19069084962274369, MSE Std: 0.009551898128950046, Training Time: 0:00:03.985489, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10264, Cos Sim Mean: 0.17692517810238612, Cos Sim Std: 0.011735312470613851, MSE Mean: 0.15508418823233036, MSE Std: 0.006378925167307709, Training Time: 0:00:03.962752, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10265, Cos Sim Mean: 0.17692518978309885, Cos Sim Std: 0.01173531126153797, MSE Mean: 0.15751345690304497, MSE Std: 0.0063239764973700985, Training Time: 0:00:04.106943, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10266, Cos Sim Mean: 0.1769251868769746, Cos Sim Std: 0.011735314092952137, MSE Mean: 0.23518306944126288, MSE Std: 0.014602843688884695, Training Time: 0:00:03.853792, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10267, Cos Sim Mean: 0.1769251868769746, Cos Sim Std: 0.011735314092952137, MSE Mean: 0.15884664962675982, MSE Std: 0.006211117226573272, Training Time: 0:00:03.981878, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10268, Cos Sim Mean: 0.17692518530701612, Cos Sim Std: 0.011735315064560745, MSE Mean: 0.1795531709734814, MSE Std: 0.004309343406950163, Training Time: 0:00:04.152384, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10269, Cos Sim Mean: 0.17692518205192329, Cos Sim Std: 0.011735302536495679, MSE Mean: 0.3243403785445549, MSE Std: 0.031538185372980414, Training Time: 0:00:03.871488, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10270, Cos Sim Mean: 0.4273352545201722, Cos Sim Std: 0.03541748429459972, MSE Mean: 0.15378617892372254, MSE Std: 0.009801371219221413, Training Time: 0:00:01.909816, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10271, Cos Sim Mean: 0.36100849471795776, Cos Sim Std: 0.060078355310868005, MSE Mean: 0.16516662078443484, MSE Std: 0.006550548560432823, Training Time: 0:00:01.900128, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10272, Cos Sim Mean: 0.3399844001381061, Cos Sim Std: 0.036066850830217025, MSE Mean: 0.1780933167283843, MSE Std: 0.004099114942934738, Training Time: 0:00:01.874479, Batch: 32, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10273, Cos Sim Mean: 0.3819022723097449, Cos Sim Std: 0.03753611238718888, MSE Mean: 0.15682918191296719, MSE Std: 0.010487988049428696, Training Time: 0:00:01.874093, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10274, Cos Sim Mean: 0.34220128092222313, Cos Sim Std: 0.07096140753393472, MSE Mean: 0.1684547631307879, MSE Std: 0.007854990056357364, Training Time: 0:00:01.882098, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10275, Cos Sim Mean: 0.3439493243454425, Cos Sim Std: 0.07254823333307205, MSE Mean: 0.18337279312606997, MSE Std: 0.009420061796695309, Training Time: 0:00:01.901406, Batch: 32, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10276, Cos Sim Mean: 0.3712106730350148, Cos Sim Std: 0.06195686310242508, MSE Mean: 0.16084533249289712, MSE Std: 0.013422232438393612, Training Time: 0:00:02.087044, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10277, Cos Sim Mean: 0.36087522401937555, Cos Sim Std: 0.05396290867091448, MSE Mean: 0.17436762891208366, MSE Std: 0.013444428498664871, Training Time: 0:00:01.880243, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10278, Cos Sim Mean: 0.3557375614785736, Cos Sim Std: 0.0306710283915157, MSE Mean: 0.18930230164020379, MSE Std: 0.014385148366049764, Training Time: 0:00:01.911294, Batch: 32, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10279, Cos Sim Mean: 0.40977185394230664, Cos Sim Std: 0.03827134707993994, MSE Mean: 0.13828745657567584, MSE Std: 0.008909639304570895, Training Time: 0:00:02.266689, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10280, Cos Sim Mean: 0.40996100189153994, Cos Sim Std: 0.04428132438485853, MSE Mean: 0.1502686961696725, MSE Std: 0.005850612993489012, Training Time: 0:00:02.307232, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10281, Cos Sim Mean: 0.3662152240380006, Cos Sim Std: 0.05405350673837295, MSE Mean: 0.17768428360280136, MSE Std: 0.004982268430239029, Training Time: 0:00:02.288612, Batch: 32, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10282, Cos Sim Mean: 0.40105962950084423, Cos Sim Std: 0.03843045546165306, MSE Mean: 0.14221847348747757, MSE Std: 0.0051958526256867185, Training Time: 0:00:02.264117, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10283, Cos Sim Mean: 0.38362119955875934, Cos Sim Std: 0.05227768200492018, MSE Mean: 0.16040683537373052, MSE Std: 0.005115223995649308, Training Time: 0:00:02.274767, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10284, Cos Sim Mean: 0.3485159638130887, Cos Sim Std: 0.04120882452997835, MSE Mean: 0.18948824066044578, MSE Std: 0.004512886248046724, Training Time: 0:00:02.285172, Batch: 32, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10285, Cos Sim Mean: 0.4078957572476997, Cos Sim Std: 0.03906371343570932, MSE Mean: 0.15305523370082072, MSE Std: 0.007208985498709293, Training Time: 0:00:02.242307, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10286, Cos Sim Mean: 0.348098855818427, Cos Sim Std: 0.05445318037203966, MSE Mean: 0.17669643641630192, MSE Std: 0.008756000099653669, Training Time: 0:00:02.293807, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10287, Cos Sim Mean: 0.17692518712228616, Cos Sim Std: 0.011735311939362732, MSE Mean: 0.20200967211400894, MSE Std: 0.010198781670214202, Training Time: 0:00:02.272473, Batch: 32, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10288, Cos Sim Mean: 0.4252984951480304, Cos Sim Std: 0.02829830014492305, MSE Mean: 0.14328752120516497, MSE Std: 0.003998427889693071, Training Time: 0:00:02.624069, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10289, Cos Sim Mean: 0.2488905215200153, Cos Sim Std: 0.07281672034804236, MSE Mean: 0.1609536092810953, MSE Std: 0.007307908493024063, Training Time: 0:00:02.624492, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10290, Cos Sim Mean: 0.1769251864407789, Cos Sim Std: 0.011735309506735452, MSE Mean: 0.17873727734530367, MSE Std: 0.006020685138502729, Training Time: 0:00:02.617553, Batch: 32, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10291, Cos Sim Mean: 0.41814778199793456, Cos Sim Std: 0.0507048874757279, MSE Mean: 0.14426412633616678, MSE Std: 0.006935770404380669, Training Time: 0:00:02.614714, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10292, Cos Sim Mean: 0.17692518631499732, Cos Sim Std: 0.011735312138214953, MSE Mean: 0.16924095178520798, MSE Std: 0.007730751295304316, Training Time: 0:00:02.613878, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10293, Cos Sim Mean: 0.17692518558405157, Cos Sim Std: 0.01173531425076561, MSE Mean: 0.19522948090756137, MSE Std: 0.01001513755158162, Training Time: 0:00:02.624774, Batch: 32, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10294, Cos Sim Mean: 0.2455700512387126, Cos Sim Std: 0.0686762455872353, MSE Mean: 0.16580957990749026, MSE Std: 0.00775809921322985, Training Time: 0:00:02.617642, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10295, Cos Sim Mean: 0.1769251865075466, Cos Sim Std: 0.011735308587610743, MSE Mean: 0.18396997830106263, MSE Std: 0.010818396769203768, Training Time: 0:00:02.601129, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10296, Cos Sim Mean: 0.17692518728944645, Cos Sim Std: 0.011735310792098408, MSE Mean: 0.21812014115841988, MSE Std: 0.01754345472958731, Training Time: 0:00:02.632361, Batch: 32, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10297, Cos Sim Mean: 0.17692518570737245, Cos Sim Std: 0.011735305390141643, MSE Mean: 0.15511180184348058, MSE Std: 0.006375845877442481, Training Time: 0:00:03.362109, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10298, Cos Sim Mean: 0.17692518915816766, Cos Sim Std: 0.01173531011181725, MSE Mean: 0.15606793601222466, MSE Std: 0.006349090391884, Training Time: 0:00:03.378092, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10299, Cos Sim Mean: 0.17692518872886517, Cos Sim Std: 0.011735309669266092, MSE Mean: 0.1653810182603611, MSE Std: 0.006126757258067264, Training Time: 0:00:03.243214, Batch: 32, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10300, Cos Sim Mean: 0.17692518491961515, Cos Sim Std: 0.01173530659339857, MSE Mean: 0.15547129432769227, MSE Std: 0.006319043885482961, Training Time: 0:00:03.240834, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10301, Cos Sim Mean: 0.1769251853622004, Cos Sim Std: 0.011735312510311287, MSE Mean: 0.15808660002390768, MSE Std: 0.0063706582214484025, Training Time: 0:00:03.273058, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10302, Cos Sim Mean: 0.1769251876134022, Cos Sim Std: 0.011735309217359205, MSE Mean: 0.17718516914165136, MSE Std: 0.005158103569922121, Training Time: 0:00:03.286264, Batch: 32, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10303, Cos Sim Mean: 0.17692518243351024, Cos Sim Std: 0.011735312622347302, MSE Mean: 0.15828806992770722, MSE Std: 0.007364162054665909, Training Time: 0:00:03.223110, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10304, Cos Sim Mean: 0.17692518507812705, Cos Sim Std: 0.011735315423790962, MSE Mean: 0.16972510794697876, MSE Std: 0.009536250110618738, Training Time: 0:00:03.211687, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10305, Cos Sim Mean: 0.1769251859931167, Cos Sim Std: 0.011735313175406381, MSE Mean: 0.21182732645796878, MSE Std: 0.021947295743748266, Training Time: 0:00:03.289054, Batch: 32, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10306, Cos Sim Mean: 0.1769251821482445, Cos Sim Std: 0.011735307268349166, MSE Mean: 0.1549534035429709, MSE Std: 0.00639691055821849, Training Time: 0:00:06.219986, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10307, Cos Sim Mean: 0.17692518670235396, Cos Sim Std: 0.011735310312615068, MSE Mean: 0.1549810663196844, MSE Std: 0.00639268338868001, Training Time: 0:00:06.436845, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10308, Cos Sim Mean: 0.17692518207011002, Cos Sim Std: 0.011735310608407266, MSE Mean: 0.15802233605767393, MSE Std: 0.006359293862172797, Training Time: 0:00:06.258904, Batch: 32, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10309, Cos Sim Mean: 0.17692518096009985, Cos Sim Std: 0.01173530894336399, MSE Mean: 0.154957878491204, MSE Std: 0.006397431148771999, Training Time: 0:00:06.215204, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10310, Cos Sim Mean: 0.17692518022532447, Cos Sim Std: 0.011735310190600447, MSE Mean: 0.15506138678387046, MSE Std: 0.006402163244191317, Training Time: 0:00:06.252165, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10311, Cos Sim Mean: 0.1769251862556806, Cos Sim Std: 0.011735314082845602, MSE Mean: 0.1634498339179833, MSE Std: 0.007117420767922458, Training Time: 0:00:06.178476, Batch: 32, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10312, Cos Sim Mean: 0.1769251778220396, Cos Sim Std: 0.011735306393809878, MSE Mean: 0.15497861489790232, MSE Std: 0.006392806345350252, Training Time: 0:00:06.183646, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10313, Cos Sim Mean: 0.17692518199236482, Cos Sim Std: 0.01173531071477412, MSE Mean: 0.1566633133867298, MSE Std: 0.006198297977946259, Training Time: 0:00:06.312103, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10314, Cos Sim Mean: 0.17692518497259707, Cos Sim Std: 0.011735306637378776, MSE Mean: 0.19428653572432855, MSE Std: 0.008278414876174338, Training Time: 0:00:06.442368, Batch: 32, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10315, Cos Sim Mean: 0.3649074098716688, Cos Sim Std: 0.06766671330107787, MSE Mean: 0.21180427626369153, MSE Std: 0.009832731421114916, Training Time: 0:00:01.334263, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10316, Cos Sim Mean: 0.3370911271351411, Cos Sim Std: 0.11714018663887193, MSE Mean: 0.22661778111170597, MSE Std: 0.008612931596596722, Training Time: 0:00:01.264467, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10317, Cos Sim Mean: 0.32277783702132307, Cos Sim Std: 0.13832902323001867, MSE Mean: 0.2447631879548302, MSE Std: 0.01036291352013684, Training Time: 0:00:01.268464, Batch: 64, Num Hidden: 1, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10318, Cos Sim Mean: 0.3613753464854445, Cos Sim Std: 0.06027760552794815, MSE Mean: 0.2119276284623485, MSE Std: 0.009500963997533524, Training Time: 0:00:01.290688, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10319, Cos Sim Mean: 0.3243800705002522, Cos Sim Std: 0.11816848607161777, MSE Mean: 0.22718689951914825, MSE Std: 0.011110886552336014, Training Time: 0:00:01.246557, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10320, Cos Sim Mean: 0.36410941634990934, Cos Sim Std: 0.03316983944605154, MSE Mean: 0.25133416652805296, MSE Std: 0.011544658907319134, Training Time: 0:00:01.259226, Batch: 64, Num Hidden: 1, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10321, Cos Sim Mean: 0.3801421104133776, Cos Sim Std: 0.033651012814910966, MSE Mean: 0.2206691532417114, MSE Std: 0.016536366902130627, Training Time: 0:00:01.265316, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10322, Cos Sim Mean: 0.3923961109493, Cos Sim Std: 0.029381553967308054, MSE Mean: 0.2355830488634, MSE Std: 0.016740123444104662, Training Time: 0:00:01.258904, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10323, Cos Sim Mean: 0.29565677809002855, Cos Sim Std: 0.050559775195441144, MSE Mean: 0.2554265829965566, MSE Std: 0.01795081958875228, Training Time: 0:00:01.261026, Batch: 64, Num Hidden: 1, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10324, Cos Sim Mean: 0.38693003110542956, Cos Sim Std: 0.07141665275243174, MSE Mean: 0.18320092341909525, MSE Std: 0.002827127064896819, Training Time: 0:00:01.527983, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10325, Cos Sim Mean: 0.37154135460167037, Cos Sim Std: 0.05639444298945805, MSE Mean: 0.21374523988509359, MSE Std: 0.004043964193777764, Training Time: 0:00:01.551109, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10326, Cos Sim Mean: 0.2723832473687058, Cos Sim Std: 0.08862756683823372, MSE Mean: 0.270547718869672, MSE Std: 0.007186970142414361, Training Time: 0:00:01.554852, Batch: 64, Num Hidden: 2, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10327, Cos Sim Mean: 0.382207994089291, Cos Sim Std: 0.048860551649647185, MSE Mean: 0.19452102703593452, MSE Std: 0.008287522927906538, Training Time: 0:00:01.564324, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10328, Cos Sim Mean: 0.3180180202916826, Cos Sim Std: 0.11780193763735983, MSE Mean: 0.23090179646697334, MSE Std: 0.006054576009037501, Training Time: 0:00:01.532840, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10329, Cos Sim Mean: 0.18212857668438237, Cos Sim Std: 0.012147742053931177, MSE Mean: 0.2919028100425204, MSE Std: 0.01017147591085493, Training Time: 0:00:01.570644, Batch: 64, Num Hidden: 2, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10330, Cos Sim Mean: 0.33250145866914094, Cos Sim Std: 0.03093245566091628, MSE Mean: 0.2201289261429812, MSE Std: 0.01586311518045356, Training Time: 0:00:01.561533, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10331, Cos Sim Mean: 0.18920589008171088, Cos Sim Std: 0.033695238273603406, MSE Mean: 0.253467824924766, MSE Std: 0.0195055408903209, Training Time: 0:00:01.513200, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10332, Cos Sim Mean: 0.1769251891769656, Cos Sim Std: 0.011735311604539621, MSE Mean: 0.29337611753000076, MSE Std: 0.019559943752504257, Training Time: 0:00:01.578910, Batch: 64, Num Hidden: 2, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10333, Cos Sim Mean: 0.3921501152447151, Cos Sim Std: 0.013213221882802918, MSE Mean: 0.1725628343509127, MSE Std: 0.006615967438264346, Training Time: 0:00:01.834175, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10334, Cos Sim Mean: 0.21013337429553927, Cos Sim Std: 0.02980288324798481, MSE Mean: 0.20819467234191022, MSE Std: 0.010934208254433949, Training Time: 0:00:01.808235, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10335, Cos Sim Mean: 0.1769251876897036, Cos Sim Std: 0.011735311787792427, MSE Mean: 0.29058020789948646, MSE Std: 0.018072685405887575, Training Time: 0:00:01.800232, Batch: 64, Num Hidden: 3, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10336, Cos Sim Mean: 0.37282825360907057, Cos Sim Std: 0.03279994751106531, MSE Mean: 0.19082202684426458, MSE Std: 0.013374818291381697, Training Time: 0:00:01.815351, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10337, Cos Sim Mean: 0.17692518951448546, Cos Sim Std: 0.011735311881741789, MSE Mean: 0.238915901937929, MSE Std: 0.018293231807002597, Training Time: 0:00:01.802803, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10338, Cos Sim Mean: 0.17692518767315057, Cos Sim Std: 0.011735310617212703, MSE Mean: 0.32952255016934007, MSE Std: 0.0185880040382582, Training Time: 0:00:01.803531, Batch: 64, Num Hidden: 3, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10339, Cos Sim Mean: 0.2105392227895626, Cos Sim Std: 0.053361723205790954, MSE Mean: 0.22484577297767222, MSE Std: 0.01821005507402039, Training Time: 0:00:01.797479, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10340, Cos Sim Mean: 0.17692518763190615, Cos Sim Std: 0.011735309908954003, MSE Mean: 0.2735464155289441, MSE Std: 0.02388847475935729, Training Time: 0:00:01.799169, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10341, Cos Sim Mean: 0.1769251878908812, Cos Sim Std: 0.011735310330109359, MSE Mean: 0.35265657103924364, MSE Std: 0.03723971206759938, Training Time: 0:00:01.799615, Batch: 64, Num Hidden: 3, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10342, Cos Sim Mean: 0.17692518772468507, Cos Sim Std: 0.011735314796636517, MSE Mean: 0.15851515218761192, MSE Std: 0.005894935019092586, Training Time: 0:00:02.260410, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10343, Cos Sim Mean: 0.17692518902383755, Cos Sim Std: 0.011735311613518781, MSE Mean: 0.17075682826333355, MSE Std: 0.005636786601514057, Training Time: 0:00:02.252160, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10344, Cos Sim Mean: 0.17692518936482066, Cos Sim Std: 0.011735310689213518, MSE Mean: 0.24320545903388285, MSE Std: 0.012056528987675516, Training Time: 0:00:02.250594, Batch: 64, Num Hidden: 5, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10345, Cos Sim Mean: 0.17692518651190653, Cos Sim Std: 0.011735313370126899, MSE Mean: 0.165568199253127, MSE Std: 0.0067016668808372905, Training Time: 0:00:02.254059, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10346, Cos Sim Mean: 0.17692518754862066, Cos Sim Std: 0.011735310967361178, MSE Mean: 0.1895088959365394, MSE Std: 0.00554652759884097, Training Time: 0:00:02.261207, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10347, Cos Sim Mean: 0.17692518643656632, Cos Sim Std: 0.01173531257052984, MSE Mean: 0.3040578642112449, MSE Std: 0.012238464912733688, Training Time: 0:00:02.247035, Batch: 64, Num Hidden: 5, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10348, Cos Sim Mean: 0.17692518648003275, Cos Sim Std: 0.011735313074544455, MSE Mean: 0.19142864827583028, MSE Std: 0.017377019608099134, Training Time: 0:00:02.247284, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10349, Cos Sim Mean: 0.17692518746204694, Cos Sim Std: 0.011735310579380404, MSE Mean: 0.25045808993951835, MSE Std: 0.030534075610402573, Training Time: 0:00:02.262464, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10350, Cos Sim Mean: 0.17692518448532316, Cos Sim Std: 0.011735311696743196, MSE Mean: 0.3864250228488765, MSE Std: 0.0561892675933282, Training Time: 0:00:02.272963, Batch: 64, Num Hidden: 5, Num Dense: 50, Dropout: 0.5\n",
      "ID: 10351, Cos Sim Mean: 0.17692517976095018, Cos Sim Std: 0.011735310201455573, MSE Mean: 0.1549882528612246, MSE Std: 0.006386382575400008, Training Time: 0:00:04.006418, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.3\n",
      "ID: 10352, Cos Sim Mean: 0.17692517663612978, Cos Sim Std: 0.011735301933965641, MSE Mean: 0.15611173015129426, MSE Std: 0.006216418519806811, Training Time: 0:00:04.091219, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.4\n",
      "ID: 10353, Cos Sim Mean: 0.17692518936482066, Cos Sim Std: 0.011735310689213518, MSE Mean: 0.20048955178151479, MSE Std: 0.010697259255149028, Training Time: 0:00:04.037395, Batch: 64, Num Hidden: 10, Num Dense: 150, Dropout: 0.5\n",
      "ID: 10354, Cos Sim Mean: 0.17692518936482066, Cos Sim Std: 0.011735310689213518, MSE Mean: 0.15518859326852064, MSE Std: 0.006407985915043548, Training Time: 0:00:03.968821, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.3\n",
      "ID: 10355, Cos Sim Mean: 0.1769251854957472, Cos Sim Std: 0.011735305395213893, MSE Mean: 0.15919866688297443, MSE Std: 0.0070197715256349255, Training Time: 0:00:04.095202, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.4\n",
      "ID: 10356, Cos Sim Mean: 0.17692518300790114, Cos Sim Std: 0.011735308798953226, MSE Mean: 0.24994776704705393, MSE Std: 0.014140451499823048, Training Time: 0:00:04.071719, Batch: 64, Num Hidden: 10, Num Dense: 100, Dropout: 0.5\n",
      "ID: 10357, Cos Sim Mean: 0.17692518000541185, Cos Sim Std: 0.011735302703826042, MSE Mean: 0.16018309466749073, MSE Std: 0.006462442386729756, Training Time: 0:00:03.883788, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.3\n",
      "ID: 10358, Cos Sim Mean: 0.1769251838744853, Cos Sim Std: 0.011735307997828693, MSE Mean: 0.18946211761662407, MSE Std: 0.004712320248019821, Training Time: 0:00:03.868380, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.4\n",
      "ID: 10359, Cos Sim Mean: 0.17692518592099674, Cos Sim Std: 0.01173530783049773, MSE Mean: 0.38543746329896217, MSE Std: 0.022637712741724682, Training Time: 0:00:03.858064, Batch: 64, Num Hidden: 10, Num Dense: 50, Dropout: 0.5\n"
     ]
    }
   ],
   "source": [
    "kfold_id = 10000\n",
    "\n",
    "resumo = pd.DataFrame(columns=['kfold_id','cos_sim_mean','cos_sim_std','mse_mean','mse_std','training_time','batch_size','number_hidden','num_dense','dropout'])\n",
    "\n",
    "number_epochs = 30\n",
    "\n",
    "\n",
    "for emb_dim in [300, 200, 100, 50]:\n",
    "  \n",
    "  embeddings_index_kfold = load_embedding(emb_dim)\n",
    "\n",
    "# Parametros corretos \n",
    "# Take out \"num_filters\" and \"size_filters\" to make an ANN\n",
    "\n",
    "  for batch_size in [32, 64]:\n",
    "           for number_hidden in [1, 2, 3, 5, 10]:\n",
    "              for number_dense in [150, 100, 50]:\n",
    "                  for dropout_value in [0.3, 0.4, 0.5]:\n",
    "\n",
    "                    cvscores_mse = []\n",
    "                    cvscores_cos_sim = []\n",
    "                    time_list = []\n",
    "                    \n",
    "                    seed = 42\n",
    "                    np.random.seed(seed)\n",
    "                    \n",
    "                    for train, val in skf.split(df_train, df_train['quantile']):\n",
    "#                         print(train)\n",
    "                        X_train = df_train.iloc[train]\n",
    "                        X_val = df_train.iloc[val]\n",
    "    \n",
    "                        Y_train = df_train['sentiment'].iloc[train]\n",
    "                        Y_val = df_train['sentiment'].iloc[val]\n",
    "                \n",
    "                        # get sentences ready for usage\n",
    "                        sentences_train_pad, sentences_val_pad, tok_kfold = get_tok_sentences(X_train[\"new_title\"], X_val[\"new_title\"])\n",
    "                  \n",
    "                        embedding_matrix = get_embedding_matrix(emb_dim, MAX_VOCAB_SIZE, MAX_SEQUENCE_LENGTH, tok_kfold, embeddings_index_kfold)\n",
    "                        \n",
    "#                         nn_input_train = {'Word_Seq': sentences_train_pad, 'Lexical': np.array(X_train['mean_VADER_LMD'].tolist())}\n",
    "#                         nn_input_val = {'Word_Seq': sentences_val_pad, 'Lexical': np.array(X_val['mean_VADER_LMD'].tolist())}\n",
    "                        nn_input_train = {'Word_Seq': sentences_train_pad, 'Lexical': np.array(X_train['mean_VADER'].tolist())}\n",
    "                        nn_input_val = {'Word_Seq': sentences_val_pad, 'Lexical': np.array(X_val['mean_VADER'].tolist())}\n",
    "\n",
    "                      \n",
    "                        model_name = 'kfoldid_' + str(kfold_id) + '-dim_' + str(emb_dim) + '-bs_' + str(batch_size) + '-nh_' + str(number_hidden) + '-nd_' + str(number_dense) + '-dv_' + str(10*dropout_value)\n",
    "                        \n",
    "                        if number_hidden == 1:\n",
    "                          ann = create_ANN_model_hidden_1(number_dense, dropout_value, embedding_matrix, True)\n",
    "                        elif number_hidden == 2:\n",
    "                          ann = create_ANN_model_hidden_2(number_dense, dropout_value, embedding_matrix, True)\n",
    "                        elif number_hidden == 3:\n",
    "                          ann = create_ANN_model_hidden_3(number_dense, dropout_value, embedding_matrix, True)\n",
    "                        elif number_hidden == 5:\n",
    "                          ann = create_ANN_model_hidden_5(number_dense, dropout_value, embedding_matrix, True)\n",
    "                        else:\n",
    "                          ann = create_ANN_model_hidden_10(number_dense, dropout_value, embedding_matrix, True)                              \n",
    "\n",
    "                        init = datetime.datetime.now()\n",
    "                        trained = train_model(ann, nn_input_train, Y_train, batch_size, number_epochs, model_name, nn_input_val, Y_val)\n",
    "                        training_time = (datetime.datetime.now() - init)\n",
    "                        cvscores_mse.append(trained.history['val_loss'][-1])\n",
    "                        cvscores_cos_sim.append(-trained.history['val_cosine_proximity'][-1])\n",
    "                        time_list.append(training_time)\n",
    "                        # save_model(ann, trained, model_name)\n",
    "                  \n",
    "                        if K.backend() == 'tensorflow':\n",
    "                          K.clear_session()\n",
    "\n",
    "                    result = [kfold_id, np.mean(cvscores_cos_sim), np.std(cvscores_cos_sim), np.mean(cvscores_mse), np.std(cvscores_mse), np.mean(time_list), batch_size, number_hidden, number_dense, dropout_value]\n",
    "                    resumo = resumo.append(pd.Series(result, index=resumo.columns), ignore_index=True)\n",
    "\n",
    "                    print('ID: {}, Cos Sim Mean: {}, Cos Sim Std: {}, MSE Mean: {}, MSE Std: {}, Training Time: {}, Batch: {}, Num Hidden: {}, Num Dense: {}, Dropout: {}'.format(*result))\n",
    "                    \n",
    "                    kfold_id = kfold_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1960
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5450899,
     "status": "ok",
     "timestamp": 1560549202134,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "2uxkO9P3wp8W",
    "outputId": "d23a34fb-5194-43ba-ecd8-4c836d4e0b96"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kfold_id</th>\n",
       "      <th>cos_sim_mean</th>\n",
       "      <th>cos_sim_std</th>\n",
       "      <th>mse_mean</th>\n",
       "      <th>mse_std</th>\n",
       "      <th>training_time</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>number_hidden</th>\n",
       "      <th>num_dense</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10012</td>\n",
       "      <td>0.471428</td>\n",
       "      <td>0.033527</td>\n",
       "      <td>0.119496</td>\n",
       "      <td>0.007590</td>\n",
       "      <td>00:00:02.776895</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10006</td>\n",
       "      <td>0.478173</td>\n",
       "      <td>0.023214</td>\n",
       "      <td>0.121481</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>00:00:02.339812</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10007</td>\n",
       "      <td>0.495860</td>\n",
       "      <td>0.029699</td>\n",
       "      <td>0.121579</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>00:00:02.374343</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>0.495852</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>0.121822</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>00:00:02.332175</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10015</td>\n",
       "      <td>0.487075</td>\n",
       "      <td>0.045632</td>\n",
       "      <td>0.123566</td>\n",
       "      <td>0.006259</td>\n",
       "      <td>00:00:02.759178</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10009</td>\n",
       "      <td>0.474861</td>\n",
       "      <td>0.035141</td>\n",
       "      <td>0.123858</td>\n",
       "      <td>0.007928</td>\n",
       "      <td>00:00:02.752835</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>0.492404</td>\n",
       "      <td>0.035285</td>\n",
       "      <td>0.124025</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>00:00:02.372637</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>10096</td>\n",
       "      <td>0.499427</td>\n",
       "      <td>0.042389</td>\n",
       "      <td>0.124102</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>00:00:02.034347</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>0.487240</td>\n",
       "      <td>0.049293</td>\n",
       "      <td>0.124253</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>00:00:02.311457</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10099</td>\n",
       "      <td>0.482479</td>\n",
       "      <td>0.087265</td>\n",
       "      <td>0.124325</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>00:00:02.461758</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>10108</td>\n",
       "      <td>0.481940</td>\n",
       "      <td>0.038060</td>\n",
       "      <td>0.125155</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>00:00:02.852311</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10010</td>\n",
       "      <td>0.483625</td>\n",
       "      <td>0.042247</td>\n",
       "      <td>0.125501</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>00:00:02.752064</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10013</td>\n",
       "      <td>0.464122</td>\n",
       "      <td>0.040468</td>\n",
       "      <td>0.126458</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>00:00:02.756576</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.485516</td>\n",
       "      <td>0.048370</td>\n",
       "      <td>0.127527</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>00:00:02.349765</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>10105</td>\n",
       "      <td>0.490858</td>\n",
       "      <td>0.047303</td>\n",
       "      <td>0.128041</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>00:00:02.449894</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10021</td>\n",
       "      <td>0.501098</td>\n",
       "      <td>0.029573</td>\n",
       "      <td>0.128145</td>\n",
       "      <td>0.009893</td>\n",
       "      <td>00:00:02.746670</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10024</td>\n",
       "      <td>0.469530</td>\n",
       "      <td>0.048296</td>\n",
       "      <td>0.128473</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>00:00:02.659641</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10016</td>\n",
       "      <td>0.462347</td>\n",
       "      <td>0.032239</td>\n",
       "      <td>0.128970</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>00:00:02.727548</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>10111</td>\n",
       "      <td>0.494397</td>\n",
       "      <td>0.053030</td>\n",
       "      <td>0.129134</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>00:00:02.828990</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>10102</td>\n",
       "      <td>0.477050</td>\n",
       "      <td>0.068713</td>\n",
       "      <td>0.129698</td>\n",
       "      <td>0.012124</td>\n",
       "      <td>00:00:02.457363</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10018</td>\n",
       "      <td>0.462581</td>\n",
       "      <td>0.040405</td>\n",
       "      <td>0.130716</td>\n",
       "      <td>0.014243</td>\n",
       "      <td>00:00:03.138777</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>10100</td>\n",
       "      <td>0.503119</td>\n",
       "      <td>0.041466</td>\n",
       "      <td>0.131058</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>00:00:02.451948</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>10090</td>\n",
       "      <td>0.462630</td>\n",
       "      <td>0.038734</td>\n",
       "      <td>0.132295</td>\n",
       "      <td>0.008558</td>\n",
       "      <td>00:00:02.052961</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>10093</td>\n",
       "      <td>0.469466</td>\n",
       "      <td>0.044516</td>\n",
       "      <td>0.132849</td>\n",
       "      <td>0.013927</td>\n",
       "      <td>00:00:02.035426</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>10097</td>\n",
       "      <td>0.467807</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>0.135170</td>\n",
       "      <td>0.011582</td>\n",
       "      <td>00:00:02.060106</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>10189</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.039894</td>\n",
       "      <td>0.136301</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>00:00:02.190545</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>10103</td>\n",
       "      <td>0.487586</td>\n",
       "      <td>0.065079</td>\n",
       "      <td>0.136333</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>00:00:02.431068</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10008</td>\n",
       "      <td>0.459228</td>\n",
       "      <td>0.052514</td>\n",
       "      <td>0.136558</td>\n",
       "      <td>0.010561</td>\n",
       "      <td>00:00:02.303672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>10114</td>\n",
       "      <td>0.481922</td>\n",
       "      <td>0.064330</td>\n",
       "      <td>0.136619</td>\n",
       "      <td>0.007589</td>\n",
       "      <td>00:00:02.808650</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10019</td>\n",
       "      <td>0.480066</td>\n",
       "      <td>0.035522</td>\n",
       "      <td>0.137073</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>00:00:03.134635</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>10344</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.243205</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>00:00:02.250594</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>10317</td>\n",
       "      <td>0.322778</td>\n",
       "      <td>0.138329</td>\n",
       "      <td>0.244763</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>00:00:01.268464</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>10236</td>\n",
       "      <td>0.337772</td>\n",
       "      <td>0.025886</td>\n",
       "      <td>0.245450</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>00:00:01.503165</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>10356</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.249948</td>\n",
       "      <td>0.014140</td>\n",
       "      <td>00:00:04.071719</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>10349</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.250458</td>\n",
       "      <td>0.030534</td>\n",
       "      <td>00:00:02.262464</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>10320</td>\n",
       "      <td>0.364109</td>\n",
       "      <td>0.033170</td>\n",
       "      <td>0.251334</td>\n",
       "      <td>0.011545</td>\n",
       "      <td>00:00:01.259226</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>10331</td>\n",
       "      <td>0.189206</td>\n",
       "      <td>0.033695</td>\n",
       "      <td>0.253468</td>\n",
       "      <td>0.019506</td>\n",
       "      <td>00:00:01.513200</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>10323</td>\n",
       "      <td>0.295657</td>\n",
       "      <td>0.050560</td>\n",
       "      <td>0.255427</td>\n",
       "      <td>0.017951</td>\n",
       "      <td>00:00:01.261026</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>10158</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.256254</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>00:00:01.963997</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>10245</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.257338</td>\n",
       "      <td>0.018064</td>\n",
       "      <td>00:00:01.766380</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>10242</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.263137</td>\n",
       "      <td>0.015184</td>\n",
       "      <td>00:00:01.500409</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>10239</td>\n",
       "      <td>0.241586</td>\n",
       "      <td>0.043655</td>\n",
       "      <td>0.263537</td>\n",
       "      <td>0.011960</td>\n",
       "      <td>00:00:01.498799</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>10257</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.263629</td>\n",
       "      <td>0.010271</td>\n",
       "      <td>00:00:02.235384</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>10161</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.265012</td>\n",
       "      <td>0.013775</td>\n",
       "      <td>00:00:01.954496</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>10326</td>\n",
       "      <td>0.272383</td>\n",
       "      <td>0.088628</td>\n",
       "      <td>0.270548</td>\n",
       "      <td>0.007187</td>\n",
       "      <td>00:00:01.554852</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>10340</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.273546</td>\n",
       "      <td>0.023888</td>\n",
       "      <td>00:00:01.799169</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>10170</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.284370</td>\n",
       "      <td>0.022501</td>\n",
       "      <td>00:00:02.488476</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>10335</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.290580</td>\n",
       "      <td>0.018073</td>\n",
       "      <td>00:00:01.800232</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>10329</td>\n",
       "      <td>0.182129</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>0.291903</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>00:00:01.570644</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>10248</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.292731</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>00:00:01.752396</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>10332</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.293376</td>\n",
       "      <td>0.019560</td>\n",
       "      <td>00:00:01.578910</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>10251</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.300139</td>\n",
       "      <td>0.021214</td>\n",
       "      <td>00:00:01.756695</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>10347</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.304058</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>00:00:02.247035</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>10179</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.304482</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>00:00:04.499265</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>10269</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.324340</td>\n",
       "      <td>0.031538</td>\n",
       "      <td>00:00:03.871488</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>10260</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.324450</td>\n",
       "      <td>0.038771</td>\n",
       "      <td>00:00:02.223354</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>10338</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.329523</td>\n",
       "      <td>0.018588</td>\n",
       "      <td>00:00:01.803531</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>10341</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.352657</td>\n",
       "      <td>0.037240</td>\n",
       "      <td>00:00:01.799615</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>10359</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.385437</td>\n",
       "      <td>0.022638</td>\n",
       "      <td>00:00:03.858064</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>10350</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.386425</td>\n",
       "      <td>0.056189</td>\n",
       "      <td>00:00:02.272963</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    kfold_id  cos_sim_mean  cos_sim_std  mse_mean   mse_std   training_time  \\\n",
       "12     10012      0.471428     0.033527  0.119496  0.007590 00:00:02.776895   \n",
       "6      10006      0.478173     0.023214  0.121481  0.009444 00:00:02.339812   \n",
       "7      10007      0.495860     0.029699  0.121579  0.006846 00:00:02.374343   \n",
       "3      10003      0.495852     0.032250  0.121822  0.005829 00:00:02.332175   \n",
       "15     10015      0.487075     0.045632  0.123566  0.006259 00:00:02.759178   \n",
       "9      10009      0.474861     0.035141  0.123858  0.007928 00:00:02.752835   \n",
       "4      10004      0.492404     0.035285  0.124025  0.005389 00:00:02.372637   \n",
       "96     10096      0.499427     0.042389  0.124102  0.007972 00:00:02.034347   \n",
       "1      10001      0.487240     0.049293  0.124253  0.004602 00:00:02.311457   \n",
       "99     10099      0.482479     0.087265  0.124325  0.008541 00:00:02.461758   \n",
       "108    10108      0.481940     0.038060  0.125155  0.007450 00:00:02.852311   \n",
       "10     10010      0.483625     0.042247  0.125501  0.006332 00:00:02.752064   \n",
       "13     10013      0.464122     0.040468  0.126458  0.006043 00:00:02.756576   \n",
       "0      10000      0.485516     0.048370  0.127527  0.004494 00:00:02.349765   \n",
       "105    10105      0.490858     0.047303  0.128041  0.005410 00:00:02.449894   \n",
       "21     10021      0.501098     0.029573  0.128145  0.009893 00:00:02.746670   \n",
       "24     10024      0.469530     0.048296  0.128473  0.005419 00:00:02.659641   \n",
       "16     10016      0.462347     0.032239  0.128970  0.002987 00:00:02.727548   \n",
       "111    10111      0.494397     0.053030  0.129134  0.008772 00:00:02.828990   \n",
       "102    10102      0.477050     0.068713  0.129698  0.012124 00:00:02.457363   \n",
       "18     10018      0.462581     0.040405  0.130716  0.014243 00:00:03.138777   \n",
       "100    10100      0.503119     0.041466  0.131058  0.005752 00:00:02.451948   \n",
       "90     10090      0.462630     0.038734  0.132295  0.008558 00:00:02.052961   \n",
       "93     10093      0.469466     0.044516  0.132849  0.013927 00:00:02.035426   \n",
       "97     10097      0.467807     0.020353  0.135170  0.011582 00:00:02.060106   \n",
       "189    10189      0.440000     0.039894  0.136301  0.005274 00:00:02.190545   \n",
       "103    10103      0.487586     0.065079  0.136333  0.006391 00:00:02.431068   \n",
       "8      10008      0.459228     0.052514  0.136558  0.010561 00:00:02.303672   \n",
       "114    10114      0.481922     0.064330  0.136619  0.007589 00:00:02.808650   \n",
       "19     10019      0.480066     0.035522  0.137073  0.010309 00:00:03.134635   \n",
       "..       ...           ...          ...       ...       ...             ...   \n",
       "344    10344      0.176925     0.011735  0.243205  0.012057 00:00:02.250594   \n",
       "317    10317      0.322778     0.138329  0.244763  0.010363 00:00:01.268464   \n",
       "236    10236      0.337772     0.025886  0.245450  0.009800 00:00:01.503165   \n",
       "356    10356      0.176925     0.011735  0.249948  0.014140 00:00:04.071719   \n",
       "349    10349      0.176925     0.011735  0.250458  0.030534 00:00:02.262464   \n",
       "320    10320      0.364109     0.033170  0.251334  0.011545 00:00:01.259226   \n",
       "331    10331      0.189206     0.033695  0.253468  0.019506 00:00:01.513200   \n",
       "323    10323      0.295657     0.050560  0.255427  0.017951 00:00:01.261026   \n",
       "158    10158      0.176925     0.011735  0.256254  0.005861 00:00:01.963997   \n",
       "245    10245      0.176925     0.011735  0.257338  0.018064 00:00:01.766380   \n",
       "242    10242      0.176925     0.011735  0.263137  0.015184 00:00:01.500409   \n",
       "239    10239      0.241586     0.043655  0.263537  0.011960 00:00:01.498799   \n",
       "257    10257      0.176925     0.011735  0.263629  0.010271 00:00:02.235384   \n",
       "161    10161      0.176925     0.011735  0.265012  0.013775 00:00:01.954496   \n",
       "326    10326      0.272383     0.088628  0.270548  0.007187 00:00:01.554852   \n",
       "340    10340      0.176925     0.011735  0.273546  0.023888 00:00:01.799169   \n",
       "170    10170      0.176925     0.011735  0.284370  0.022501 00:00:02.488476   \n",
       "335    10335      0.176925     0.011735  0.290580  0.018073 00:00:01.800232   \n",
       "329    10329      0.182129     0.012148  0.291903  0.010171 00:00:01.570644   \n",
       "248    10248      0.176925     0.011735  0.292731  0.012759 00:00:01.752396   \n",
       "332    10332      0.176925     0.011735  0.293376  0.019560 00:00:01.578910   \n",
       "251    10251      0.176925     0.011735  0.300139  0.021214 00:00:01.756695   \n",
       "347    10347      0.176925     0.011735  0.304058  0.012238 00:00:02.247035   \n",
       "179    10179      0.176925     0.011735  0.304482  0.014436 00:00:04.499265   \n",
       "269    10269      0.176925     0.011735  0.324340  0.031538 00:00:03.871488   \n",
       "260    10260      0.176925     0.011735  0.324450  0.038771 00:00:02.223354   \n",
       "338    10338      0.176925     0.011735  0.329523  0.018588 00:00:01.803531   \n",
       "341    10341      0.176925     0.011735  0.352657  0.037240 00:00:01.799615   \n",
       "359    10359      0.176925     0.011735  0.385437  0.022638 00:00:03.858064   \n",
       "350    10350      0.176925     0.011735  0.386425  0.056189 00:00:02.272963   \n",
       "\n",
       "    batch_size number_hidden num_dense  dropout  \n",
       "12          32             2       100      0.3  \n",
       "6           32             1        50      0.3  \n",
       "7           32             1        50      0.4  \n",
       "3           32             1       100      0.3  \n",
       "15          32             2        50      0.3  \n",
       "9           32             2       150      0.3  \n",
       "4           32             1       100      0.4  \n",
       "96          32             1        50      0.3  \n",
       "1           32             1       150      0.4  \n",
       "99          32             2       150      0.3  \n",
       "108         32             3       150      0.3  \n",
       "10          32             2       150      0.4  \n",
       "13          32             2       100      0.4  \n",
       "0           32             1       150      0.3  \n",
       "105         32             2        50      0.3  \n",
       "21          32             3       100      0.3  \n",
       "24          32             3        50      0.3  \n",
       "16          32             2        50      0.4  \n",
       "111         32             3       100      0.3  \n",
       "102         32             2       100      0.3  \n",
       "18          32             3       150      0.3  \n",
       "100         32             2       150      0.4  \n",
       "90          32             1       150      0.3  \n",
       "93          32             1       100      0.3  \n",
       "97          32             1        50      0.4  \n",
       "189         32             2       150      0.3  \n",
       "103         32             2       100      0.4  \n",
       "8           32             1        50      0.5  \n",
       "114         32             3        50      0.3  \n",
       "19          32             3       150      0.4  \n",
       "..         ...           ...       ...      ...  \n",
       "344         64             5       150      0.5  \n",
       "317         64             1       150      0.5  \n",
       "236         64             2       150      0.5  \n",
       "356         64            10       100      0.5  \n",
       "349         64             5        50      0.4  \n",
       "320         64             1       100      0.5  \n",
       "331         64             2        50      0.4  \n",
       "323         64             1        50      0.5  \n",
       "158         64             3       100      0.5  \n",
       "245         64             3       150      0.5  \n",
       "242         64             2        50      0.5  \n",
       "239         64             2       100      0.5  \n",
       "257         64             5       100      0.5  \n",
       "161         64             3        50      0.5  \n",
       "326         64             2       150      0.5  \n",
       "340         64             3        50      0.4  \n",
       "170         64             5        50      0.5  \n",
       "335         64             3       150      0.5  \n",
       "329         64             2       100      0.5  \n",
       "248         64             3       100      0.5  \n",
       "332         64             2        50      0.5  \n",
       "251         64             3        50      0.5  \n",
       "347         64             5       100      0.5  \n",
       "179         64            10        50      0.5  \n",
       "269         64            10        50      0.5  \n",
       "260         64             5        50      0.5  \n",
       "338         64             3       100      0.5  \n",
       "341         64             3        50      0.5  \n",
       "359         64            10        50      0.5  \n",
       "350         64             5        50      0.5  \n",
       "\n",
       "[360 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melhores = resumo.sort_values('mse_mean', ascending=True)\n",
    "melhores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ICvVLbG2ET2e"
   },
   "source": [
    "### Results Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVQEWgXy9A9H"
   },
   "outputs": [],
   "source": [
    "# specifying results filepath dest file\n",
    "results_filepath = 'results/ann/emb_vader-5-fold-v3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vqdWn_EYuowP"
   },
   "outputs": [],
   "source": [
    "# all_files = glob.glob(results_ann + \"*.csv\")\n",
    "# #   all_files = glob.glob(results_ann + \"kfoldid_10000-dim_300-bs_32-nf_384-sf_4-nd_150-dv_3.0.csv\")\n",
    "\n",
    "# li = []\n",
    "# for filename in all_files:\n",
    "#     # 1) we process the filename which has info in itself\n",
    "#   params_raw = filename.strip(results_ann).strip('.csv').split('-')\n",
    "  \n",
    "#   print(params_raw)\n",
    "    \n",
    "#   params_dict = dict()\n",
    "    \n",
    "#   for param in params_raw:\n",
    "#     key, value = param.split('_')\n",
    "#     if key == 'dv':\n",
    "#       params_dict[key] = float(value) * 0.1\n",
    "#     elif key == 'sf':\n",
    "#       continue\n",
    "#     else:\n",
    "#       params_dict[key] = int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Mgz7mWaEXOI"
   },
   "outputs": [],
   "source": [
    "# this function goes through all csv results process and group them together\n",
    "def process_raw_data(results_filepath):\n",
    "  all_files = glob.glob(results_ann + \"*.csv\")\n",
    "#   all_files = glob.glob(results_ann + \"kfoldid_10000-dim_300-bs_32-nf_384-sf_4-nd_150-dv_3.0.csv\")\n",
    "\n",
    "  li = []\n",
    "  \n",
    "  for filename in all_files:\n",
    "    # 1) we process the filename which has info in itself\n",
    "    params_raw = filename.strip(results_ann).strip('.csv').split('-')\n",
    "    \n",
    "    params_dict = dict()\n",
    "    \n",
    "#     for param in params_raw:\n",
    "#       key, value = param.split('_')\n",
    "#       if key == 'dv':\n",
    "#         params_dict[key] = float(value) * 0.1\n",
    "#       elif key == 'sf':\n",
    "#         continue\n",
    "#       else:\n",
    "#         params_dict[key] = int(value)\n",
    "\n",
    "    for param in params_raw:\n",
    "      key, value = param.split('_')\n",
    "      if key == 'dv':\n",
    "        params_dict[key] = float(value) / 10\n",
    "      else:\n",
    "        params_dict[key] = int(value)\n",
    "      \n",
    "    df_params = pd.DataFrame(params_dict, index=[0])\n",
    "    df_params.columns = ['kfold_id','emb_dim','batch_size','num_hidden','num_dense','dropout']\n",
    "\n",
    "    # 2) we process the content inside the file\n",
    "    df_results = pd.read_csv(filename, index_col=None, header=0, sep=';')\n",
    "    df_results = df_results.groupby(['epoch'], as_index=False).mean().join(df_results.groupby(['epoch']).std(), lsuffix='_mean', rsuffix='_std')\n",
    "    \n",
    "    # 2.1) Converting negative values to positives\n",
    "    df_results['cosine_proximity_mean'] = abs(df_results['cosine_proximity_mean'])\n",
    "    df_results['val_cosine_proximity_mean'] = abs(df_results['val_cosine_proximity_mean'])\n",
    "  \n",
    "    # 2.2) Defining row with best value\n",
    "    df_results['best_val_loss_mean'] = False\n",
    "    df_results['best_val_cosine_proximity_mean'] = False\n",
    "  \n",
    "    best_val_loss_mean = df_results['val_loss_mean'].min()\n",
    "    best_val_cosine_proximity_mean = df_results['val_cosine_proximity_mean'].max()\n",
    "  \n",
    "    df_results.loc[df_results['val_loss_mean'] == best_val_loss_mean, 'best_val_loss_mean'] = True\n",
    "    df_results.loc[df_results['val_cosine_proximity_mean'] == best_val_cosine_proximity_mean, 'best_val_cosine_proximity_mean'] = True\n",
    "\n",
    "    # 3) we join all info together\n",
    "    df_processed = df_params.join(df_results, how='right').ffill()\n",
    "    \n",
    "    # 4) changing some of the collumns to int\n",
    "    df_processed[['kfold_id','emb_dim','batch_size','num_hidden','num_dense']] = df_processed[['kfold_id','emb_dim','batch_size','num_hidden','num_dense']].astype('int64')\n",
    "    \n",
    "    li.append(df_processed)\n",
    "    \n",
    "  df_final = pd.concat(li, axis=0, ignore_index=True)\n",
    "  \n",
    "  df_final.to_csv(results_filepath, index=False, sep=',', encoding='utf-8')\n",
    "  \n",
    "process_raw_data(results_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S6T0i-OHwp8i"
   },
   "source": [
    "## Treinando em todo o conjunto de Treino e avaliando no conjunto de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5450902,
     "status": "ok",
     "timestamp": 1560549202152,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "uXYPn4A48h0R",
    "outputId": "456d9cf7-b1ff-4c37-ae14-e81acf4ba4d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kfold_id                               10012\n",
       "emb_dim                                  300\n",
       "batch_size                                32\n",
       "num_hidden                                 2\n",
       "num_dense                                100\n",
       "dropout                                  0.3\n",
       "epoch                                     29\n",
       "cosine_proximity_mean               0.748681\n",
       "loss_mean                          0.0688409\n",
       "time_passed_mean                   0.0643302\n",
       "val_cosine_proximity_mean           0.471428\n",
       "val_loss_mean                       0.119496\n",
       "cosine_proximity_std               0.0157621\n",
       "loss_std                          0.00386678\n",
       "time_passed_std                   0.00322523\n",
       "val_cosine_proximity_std           0.0374849\n",
       "val_loss_std                      0.00848581\n",
       "best_val_loss_mean                      True\n",
       "best_val_cosine_proximity_mean         False\n",
       "Name: 1409, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MSE(train)= loss_mean\n",
    "#MSE(val) = Val_loss_mean\n",
    "#MSE(test) = o at the bottom of the page\n",
    "#Time = time_passed_mean\n",
    "\n",
    "# selecting best models\n",
    "df_results = pd.read_csv(results_filepath)\n",
    "\n",
    "best_mse_model = df_results[df_results['best_val_loss_mean'] == True].sort_values(by=['val_loss_mean']).iloc[0]\n",
    "best_cos_model = df_results[df_results['best_val_cosine_proximity_mean'] == True].sort_values(by=['val_cosine_proximity_mean'], ascending=[False]).iloc[0]\n",
    "\n",
    "# best_cos_model[['emb_dim','num_hidden', 'num_dense', 'dropout', 'epoch', 'batch_size']]\n",
    "best_mse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fsY1wB0xwp8i"
   },
   "outputs": [],
   "source": [
    "def run_final_test(best_model_config, eval_type):\n",
    "\n",
    "  # fix random seed for reproducibility\n",
    "  seed = 42\n",
    "  np.random.seed(seed)\n",
    "\n",
    "  emb_dim, num_hidden, num_dense, dropout, epoch, batch_size = best_model_config[['emb_dim','num_hidden', 'num_dense', 'dropout', 'epoch', 'batch_size']]\n",
    "\n",
    "  embeddings_index_final = load_embedding(emb_dim)\n",
    "\n",
    "  sentences_train_final_pad, sentences_test_final_pad, tok_final = get_tok_sentences(df_train[\"new_title\"], df_test[\"new_title\"])\n",
    "\n",
    "  # X = {'Word_Seq': sentences_train_final_pad, 'Lexical': np.array(df_train['mean_VADER_LMD'].tolist())}\n",
    "  X = {'Word_Seq': sentences_train_final_pad, 'Lexical': np.array(df_train['mean_VADER'].tolist())}\n",
    "  # X = {'Word_Seq': sentences_train_final_pad}\n",
    "  Y = df_train['sentiment']\n",
    "\n",
    "  embedding_matrix = get_embedding_matrix(emb_dim, MAX_VOCAB_SIZE, MAX_SEQUENCE_LENGTH, tok_final, embeddings_index_final)\n",
    "\n",
    "  if number_hidden == 1:\n",
    "    ann = create_ANN_model_hidden_1(number_dense, dropout_value, embedding_matrix, True)\n",
    "  elif number_hidden == 2:\n",
    "    ann = create_ANN_model_hidden_2(number_dense, dropout_value, embedding_matrix, True)\n",
    "  elif number_hidden == 3:\n",
    "    ann = create_ANN_model_hidden_3(number_dense, dropout_value, embedding_matrix, True)\n",
    "  elif number_hidden == 5:\n",
    "    ann = create_ANN_model_hidden_5(number_dense, dropout_value, embedding_matrix, True)\n",
    "  else:\n",
    "    ann = create_ANN_model_hidden_10(number_dense, dropout_value, embedding_matrix, True)  \n",
    "  # ann = create_ANN_model(150, 0.4, embedding_matrix, True)\n",
    "  # ann = create_ANN_model(50, 0.5, embedding_matrix, True)\n",
    "#   ann = create_ANN_model(150, 0.3, embedding_matrix, True)\n",
    "#   ann = create_ANN_model(num_dense, dropout, embedding_matrix, True)\n",
    "  trained = train_model(ann, X, Y, batch_size, epoch, 'main_data_test', X, Y)\n",
    "#   trained = train_model(ann, X, Y, 32, 15, 'main_data_test', X, Y)\n",
    "  # ann = True\n",
    "  # trained =  True\n",
    "  \n",
    "  \n",
    "  # X_test = {'Word_Seq': sentences_seq_test, 'Lexical': np.array(df_test['mean_VADER_LMD'].tolist())}\n",
    "  X_test = {'Word_Seq': sentences_test_final_pad, 'Lexical': np.array(df_test['mean_VADER'].tolist())}\n",
    "  # X_test = {'Word_Seq': sentences_seq_test}\n",
    "\n",
    "  if eval_type == 'cos_sim':\n",
    "    y_pred = ann.predict(X_test)\n",
    "    return cosine_similarity(y_pred.reshape(1, -1), df_test['sentiment'].values.reshape(1, -1))\n",
    "  else:\n",
    "    return ann.evaluate(X_test, df_test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5450894,
     "status": "ok",
     "timestamp": 1560549202159,
     "user": {
      "displayName": "Angel Felipe Magnossao de Paula",
      "photoUrl": "",
      "userId": "13628264624700653838"
     },
     "user_tz": 180
    },
    "id": "7yTRTULqwp8p",
    "outputId": "90a56fe6-ec9e-4766-f8fa-683edd2844ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 55us/step\n",
      "[0.172680257961852, -0.14867615645140592]\n"
     ]
    }
   ],
   "source": [
    "final_mse_score = run_final_test(best_mse_model, 'mse')\n",
    "# final_cos_score = run_final_test(best_mse_model, 'cos_sim')\n",
    "\n",
    "print(final_mse_score)\n",
    "# print('Cos_sim: {}'.format(final_cos_score))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[oficial] ANN  Emb Vader.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
