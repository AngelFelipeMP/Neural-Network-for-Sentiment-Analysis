{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KWuNFSk8bPHA"
   },
   "source": [
    "# Imports and Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1218,
     "status": "ok",
     "timestamp": 1557926264544,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "qY6m8_IMNfAU",
    "outputId": "2b9a9689-3a2a-4d34-fff9-911ee9126a79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/xicocaio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/xicocaio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/xicocaio/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "\n",
    "# scikit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras import layers, regularizers, callbacks, utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk import word_tokenize, tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1396,
     "status": "ok",
     "timestamp": 1557926264733,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "l47G7mqPHlBA",
    "outputId": "8ea6c3de-83fc-4989-b486-4aa883dae5ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing if GPU available and if using CUDA\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=True,\n",
    "    min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1385,
     "status": "ok",
     "timestamp": 1557926264738,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "OQbtHrHUbgWQ",
    "outputId": "2c7527ec-fc29-40d3-96e8-65319c45b8d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_available_gpus():\n",
    "   local_device_protos = device_lib.list_local_devices()\n",
    "   return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "num_gpu = len(get_available_gpus())\n",
    "num_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lZweddAbcgq"
   },
   "outputs": [],
   "source": [
    "#folder setup\n",
    "\n",
    "results_cnn = 'results/cnn/raw/emb/'\n",
    "results_svr = 'results/svr/raw/'\n",
    "results_lstm = 'results/lstm/raw/emb_lmd/'\n",
    "\n",
    "resources = 'resources'\n",
    "\n",
    "if not os.path.isdir(results_lstm):\n",
    "    ! mkdir -p $results_cnn\n",
    "    ! mkdir -p $results_svr\n",
    "    ! mkdir -p $results_lstm\n",
    "    \n",
    "if not os.path.isdir(resources):\n",
    "    ! mkdir -p $resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OdHkxTFawp7b"
   },
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1817,
     "status": "ok",
     "timestamp": 1557926265186,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "c8ZQ9Xj0wp7c",
    "outputId": "b1fdc72b-5f78-4d9f-87c9-9e299e0ac116"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment                                              title\n",
       "0  Morrisons   2      0.430  Morrisons book second consecutive quarter of s...\n",
       "1        IMI   3     -0.344  IMI posts drop in first-quarter organic revenu...\n",
       "2   Glencore   4      0.340  Glencore to refinance its short-term debt earl...\n",
       "3    Ryanair   5      0.259  EasyJet attracts more passengers in June but s...\n",
       "4   Barclays   6     -0.231             Barclays 'bad bank' chief to step down"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading training data\n",
    "df_train = pd.read_json('Headline_Trainingdata.json')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1811,
     "status": "ok",
     "timestamp": 1557926265188,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "vb5O2ouj-BlX",
    "outputId": "7c2abc7a-f82f-4ec2-b3c1-7b6ec068618f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    131\n",
       "3    129\n",
       "8    128\n",
       "2    127\n",
       "1    127\n",
       "9    126\n",
       "5    126\n",
       "4    125\n",
       "7    123\n",
       "Name: quantile, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bins = 9\n",
    "# bins = df_train['sentiment'].quantile([0.1*q for q in range(0,n_bins)])\n",
    "# df_train['quantile'] = pd.cut(df_train['sentiment'], bins=bins, labels=range(1,n_bins+1))\n",
    "# df_train['quantile'] = pd.cut(df_train['sentiment'], bins=bins, include_lowest=True)\n",
    "\n",
    "df_train['quantile'] = pd.qcut(df_train['sentiment'], q=n_bins, labels=range(1,n_bins+1))\n",
    "df_train['quantile'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1801,
     "status": "ok",
     "timestamp": 1557926265189,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "XKTCXsWaD9RW",
    "outputId": "560898a7-02d2-4510-a359-853b7ce13235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.03104903677758319; std: 0.39360209451145045\n"
     ]
    }
   ],
   "source": [
    "print('mean: {}; std: {}'.format(np.mean(df_train['sentiment']), np.std(df_train['sentiment'])))\n",
    "# df_train['sentiment'].min()\n",
    "# df_train['sentiment'].idxmin()\n",
    "# df_train.iloc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1825,
     "status": "ok",
     "timestamp": 1557926265226,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "w619GiP9clF9",
    "outputId": "4fb9ab72-bf61-4671-ee9d-34daa0d62cda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train CV: mean: 0.03412017167381975; std: 0.38683983574619385\n",
      "df_train CV: mean: 0.028765217391304363; std: 0.4037852384500579\n",
      "df_train CV: mean: 0.029614035087719294; std: 0.3849741278336272\n",
      "df_train CV: mean: 0.02813274336283186; std: 0.4028562295301328\n",
      "df_train CV: mean: 0.03458666666666667; std: 0.3891696491534537\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "for fit_index, cv_index in skf.split(df_train, df_train['quantile']):\n",
    "#   print(\"TRAIN:\", train_index.size, \"TEST:\", test_index.size)\n",
    "#   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#   print(\"TRAIN:\", df_train.iloc[train_index], \"TEST:\", df_train.iloc[test_index])\n",
    "#   print('TRAIN: mean: {}; std: {}'.format(np.mean(df_train['sentiment'].iloc[train_index]), np.std(df_train['sentiment'].iloc[train_index])))\n",
    "  print('df_train CV: mean: {}; std: {}'.format(np.mean(df_train['sentiment'].iloc[cv_index]), np.std(df_train['sentiment'].iloc[cv_index])))\n",
    "#   df_train['sentiment'].iloc[test_index]\n",
    "#   df_train.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4615,
     "status": "ok",
     "timestamp": 1557926268022,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "sq_o9rsM08Mg",
    "outputId": "d256b8ee-5a96-43ee-bc45-2ce01e91ab37"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashtead</td>\n",
       "      <td>1144</td>\n",
       "      <td>0.588</td>\n",
       "      <td>Ashtead to buy back shares, full-year profit b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shell</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.276</td>\n",
       "      <td>EU regulators clear Shell's takeover of BG Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prudential</td>\n",
       "      <td>1146</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>UK's FTSE has worst day so far in 2015 as BG a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GlaxoSmithKline</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.390</td>\n",
       "      <td>GlaxoSmithKline acquires HIV assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>1148</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>Barclays faces another heavy forex fine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company    id  sentiment  \\\n",
       "0          Ashtead  1144      0.588   \n",
       "1            Shell  1145      0.276   \n",
       "2       Prudential  1146     -0.651   \n",
       "3  GlaxoSmithKline  1147      0.390   \n",
       "4         Barclays  1148     -0.834   \n",
       "\n",
       "                                               title  \n",
       "0  Ashtead to buy back shares, full-year profit b...  \n",
       "1   EU regulators clear Shell's takeover of BG Group  \n",
       "2  UK's FTSE has worst day so far in 2015 as BG a...  \n",
       "3                GlaxoSmithKline acquires HIV assets  \n",
       "4            Barclays faces another heavy forex fine  "
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading testing data, and removing normalizing collumns\n",
    "df_test = pd.read_json(\"Headlines_Testdata_withscores.json\")\n",
    "\n",
    "df_test.drop('UniqueID', axis=1, inplace=True)\n",
    "df_test.rename(columns={'sentiment score': 'sentiment'}, inplace=True)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4605,
     "status": "ok",
     "timestamp": 1557926268023,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "K9ufADTxblRd",
    "outputId": "04005073-6eea-4625-a09c-1143aeaa5f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test: mean: 0.014820773930753563; std: 0.4137897136769093\n"
     ]
    }
   ],
   "source": [
    "print('df_test: mean: {}; std: {}'.format(np.mean(df_test['sentiment']), np.std(df_test['sentiment'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-_1M_B-wp7k"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4598,
     "status": "ok",
     "timestamp": 1557926268024,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "2dpikgLywp7k",
    "outputId": "8ff8eacf-3f5e-4745-986c-aa83f73d4876"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashtead</td>\n",
       "      <td>1144</td>\n",
       "      <td>0.588</td>\n",
       "      <td>Ashtead to buy back shares, full-year profit b...</td>\n",
       "      <td>[company, buy, back, shares, ,, full-year, pro...</td>\n",
       "      <td>company buy back shares , full-year profit bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shell</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.276</td>\n",
       "      <td>EU regulators clear Shell's takeover of BG Group</td>\n",
       "      <td>[eu, regulators, clear, company, s, takeover, ...</td>\n",
       "      <td>eu regulators clear company s takeover bg group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prudential</td>\n",
       "      <td>1146</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>UK's FTSE has worst day so far in 2015 as BG a...</td>\n",
       "      <td>[uk, s, ftse, worst, day, far, 2015, bg, compa...</td>\n",
       "      <td>uk s ftse worst day far 2015 bg company fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GlaxoSmithKline</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.390</td>\n",
       "      <td>GlaxoSmithKline acquires HIV assets</td>\n",
       "      <td>[company, acquires, hiv, assets]</td>\n",
       "      <td>company acquires hiv assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>1148</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>Barclays faces another heavy forex fine</td>\n",
       "      <td>[company, faces, another, heavy, forex, fine]</td>\n",
       "      <td>company faces another heavy forex fine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company    id  sentiment  \\\n",
       "0          Ashtead  1144      0.588   \n",
       "1            Shell  1145      0.276   \n",
       "2       Prudential  1146     -0.651   \n",
       "3  GlaxoSmithKline  1147      0.390   \n",
       "4         Barclays  1148     -0.834   \n",
       "\n",
       "                                               title  \\\n",
       "0  Ashtead to buy back shares, full-year profit b...   \n",
       "1   EU regulators clear Shell's takeover of BG Group   \n",
       "2  UK's FTSE has worst day so far in 2015 as BG a...   \n",
       "3                GlaxoSmithKline acquires HIV assets   \n",
       "4            Barclays faces another heavy forex fine   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, buy, back, shares, ,, full-year, pro...   \n",
       "1  [eu, regulators, clear, company, s, takeover, ...   \n",
       "2  [uk, s, ftse, worst, day, far, 2015, bg, compa...   \n",
       "3                   [company, acquires, hiv, assets]   \n",
       "4      [company, faces, another, heavy, forex, fine]   \n",
       "\n",
       "                                           new_title  \n",
       "0  company buy back shares , full-year profit bea...  \n",
       "1    eu regulators clear company s takeover bg group  \n",
       "2       uk s ftse worst day far 2015 bg company fall  \n",
       "3                        company acquires hiv assets  \n",
       "4             company faces another heavy forex fine  "
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop words removal\n",
    "def run_preprocessing(df):\n",
    "  # replace company name by placeholder and remove double quotes that is not preprocessed well by word_tokenize\n",
    "  # also lower casing words for compatilbility with glove, which only has lower casing words\n",
    "  # be aware that some companies namies are not identical\n",
    "  # example: id = 10 Centrica PLC appears as just Centrica on title\n",
    "  title_company_replaced = df['title'].replace(df['company'], 'company', regex = True).replace('\"', '', regex = True).str.lower()\n",
    "#   title_company_replaced = df['title'].replace(df['company'], 'company', regex = True)\n",
    "\n",
    "  # tokenize headlines\n",
    "  tokenized_title = title_company_replaced.apply(word_tokenize)\n",
    "  \n",
    "  # removing stopwords and single quotes\n",
    "  # stop_words: {'does', 'under', 'own', 'at', 'of', 'don', 'hers', 'further', 're', \"you'll\", 'into', 'she', 'such', 'shan', 'you', \"haven't\", 'when', 'me', 'a', 'all', \"shan't\", 'mustn', \"should've\", \"didn't\", \"aren't\", \"weren't\", 'after', 'ain', 's', \"that'll\", 'just', 'am', 'the', 'too', 'before', \"wasn't\", 'what', 'haven', 'm', 'up', 'against', 'how', 'who', 'yourselves', 'nor', 'than', 've', 'between', 'being', 'are', 'and', \"don't\", 'themselves', 'were', 'itself', 'd', 'doesn', 'there', \"wouldn't\", 'both', 'we', 'why', 'needn', 'those', 'out', 'mightn', 'which', 'it', 'here', 'theirs', 'any', 'my', 'that', \"doesn't\", 'should', 'him', 'weren', 'from', 'no', 'wouldn', 'once', 'with', 'will', 'have', 'is', 'most', 'hasn', 'll', 'yours', 'himself', 'was', 'this', 'or', 'over', 'again', 'y', 'do', 'through', \"hasn't\", \"she's\", 'same', 'down', 'has', 'so', 'can', 'shouldn', \"hadn't\", 'while', 'for', 'but', 'whom', \"mustn't\", 'our', 'if', \"couldn't\", \"you've\", 'be', 'been', 'myself', 'did', 'few', 'hadn', 'other', \"you'd\", 'not', 'ma', 'their', 'off', \"shouldn't\", 'had', 'these', 'his', 'yourself', 'very', \"isn't\", 'aren', 'o', 'won', 'because', 'isn', 'wasn', 'herself', 'by', 'where', 'your', 'i', \"it's\", 'above', 'until', \"you're\", 'they', 'only', 'ours', 'below', \"mightn't\", 'some', \"won't\", 'about', 'couldn', 'ourselves', 'them', 'he', 'during', 'more', 't', 'as', 'now', 'didn', \"needn't\", 'an', 'to', 'each', 'its', 'her', 'doing', 'then', 'on', 'in', 'having'}  \n",
    "  # some of these word should probably not be removed like the word: won't\n",
    "  # also maybe consider using TweetTokenizer, that mayy deal better with contactions like: Glencore's \n",
    "  stopwords_english = stopwords.words('english')\n",
    "  stopwords_english.append('\\'')\n",
    "\n",
    "  df['clean_tokens'] = tokenized_title.apply(lambda x: [item.strip('\\'') for item in x if item not in stopwords_english])\n",
    "#   df['clean_tokens'] = tokenized_title.apply(lambda x: [item for item in x if item not in stopwords_english])\n",
    "  df['new_title'] =  df['clean_tokens'].apply(lambda x: ' '.join(x))\n",
    "  \n",
    "run_preprocessing(df_train)\n",
    "run_preprocessing(df_test)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NmyHJxUwp7x"
   },
   "source": [
    "## Tokenizing and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4592,
     "status": "ok",
     "timestamp": 1557926268026,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "iVc6F4_vj7Gx",
    "outputId": "12e8bbb8-199d-4f0b-ac72-1d50a35b849c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 16 | min: 3 | mean: 8.249562171628721 | std: 2.0743354560287957\n"
     ]
    }
   ],
   "source": [
    "clean_tokens_length = df_train[\"clean_tokens\"].apply(lambda x: len(x))\n",
    "\n",
    "max_sentence_length_train = np.max(clean_tokens_length)\n",
    "min_sentence_length_train = np.min(clean_tokens_length)\n",
    "mean_sentence_length_train = np.mean(clean_tokens_length)\n",
    "std_sentence_length_train = np.std(clean_tokens_length)\n",
    "\n",
    "\n",
    "print(\"max: {} | min: {} | mean: {} | std: {}\".format(max_sentence_length_train, min_sentence_length_train, mean_sentence_length_train, std_sentence_length_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9gLNeUqVnkmc"
   },
   "outputs": [],
   "source": [
    "# giving the max_sentence_length_train, we will use a number a little above\n",
    "# TODO: evaluate if this is too much of a leakage, because each fold may yield different sequence MAX\n",
    "MAX_SEQUENCE_LENGTH = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJXCYNGwowZS"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 10000\n",
    "\n",
    "# receives healines and returns tokenizer with vocab mappings and padded sentences read to use\n",
    "def get_tok_sentences(doc_fit, doc_cv):\n",
    "  tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='', lower=False)\n",
    "  tokenizer.fit_on_texts(doc_fit)\n",
    "\n",
    "  fit_sentences = tokenizer.texts_to_sequences(doc_fit)\n",
    "  cv_sentences = tokenizer.texts_to_sequences(doc_cv)\n",
    "  \n",
    "  fit_sentences_pad = pad_sequences(fit_sentences, padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "  cv_sentences_pad = pad_sequences(cv_sentences, padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "  return fit_sentences_pad, cv_sentences_pad, tokenizer\n",
    "\n",
    "# sentences_seq_train, vocab_size, tokenizer = prepare_tokenizer(df_train)\n",
    "# tokenizer.word_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QS3NZC6Zs0im"
   },
   "outputs": [],
   "source": [
    "# sentences_seq_train = pad_sequences(sentences_seq_train, padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "# print(sentences_seq_train[1134, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N54Xko65BOiq"
   },
   "outputs": [],
   "source": [
    "#TODO: may be a good idea: FROM: https://www.tensorflow.org/tutorials/keras/basic_text_classification\n",
    "\n",
    "# # A dictionary mapping words to an integer index\n",
    "# word_index = imdb.get_word_index()\n",
    "\n",
    "# # The first indices are reserved\n",
    "# word_index = {k:(v+3) for k,v in word_index.items()} \n",
    "# word_index[\"<PAD>\"] = 0\n",
    "# word_index[\"<START>\"] = 1\n",
    "# word_index[\"<UNK>\"] = 2  # unknown\n",
    "# word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "# reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# def decode_review(text):\n",
    "#     return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "# decode_review(train_data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83-K4yu5r9Gv"
   },
   "source": [
    "## Sentiment Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jocsyJfGwp7n"
   },
   "source": [
    "### Loughran McDonald Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXsRVyu6XLy_"
   },
   "outputs": [],
   "source": [
    "LMDDictionary = {}\n",
    "vetor = []\n",
    "\n",
    "# TODO: this can be done directly by converting to pandas and than calling the to_dict function\n",
    "with open('LoughranMcDonald_MasterDictionary_2016.csv', 'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        palavra = line.split(',')[0].lower()\n",
    "        vetor_char = line.split(',')[7:14]\n",
    "        vetor = [1 if x!='0' else 0 for x in vetor_char]\n",
    "\n",
    "        LMDDictionary[palavra] = np.asarray(vetor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4627,
     "status": "ok",
     "timestamp": 1557926268072,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "Ju9zpKQAwp7o",
    "outputId": "4075ceb4-3712-4d0e-c4ca-8325475f7dbf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>quantile</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "      <th>LMDVector</th>\n",
       "      <th>mean_LMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "      <td>8</td>\n",
       "      <td>[company, book, second, consecutive, quarter, ...</td>\n",
       "      <td>company book second consecutive quarter sales ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[company, posts, drop, first-quarter, organic,...</td>\n",
       "      <td>company posts drop first-quarter organic reven...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[company, refinance, short-term, debt, early, ...</td>\n",
       "      <td>company refinance short-term debt early , shar...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "      <td>6</td>\n",
       "      <td>[easyjet, attracts, passengers, june, still, l...</td>\n",
       "      <td>easyjet attracts passengers june still lags co...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "      <td>3</td>\n",
       "      <td>[company, bad, bank, chief, step]</td>\n",
       "      <td>company bad bank chief step</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment  \\\n",
       "0  Morrisons   2      0.430   \n",
       "1        IMI   3     -0.344   \n",
       "2   Glencore   4      0.340   \n",
       "3    Ryanair   5      0.259   \n",
       "4   Barclays   6     -0.231   \n",
       "\n",
       "                                               title quantile  \\\n",
       "0  Morrisons book second consecutive quarter of s...        8   \n",
       "1  IMI posts drop in first-quarter organic revenu...        2   \n",
       "2  Glencore to refinance its short-term debt earl...        7   \n",
       "3  EasyJet attracts more passengers in June but s...        6   \n",
       "4             Barclays 'bad bank' chief to step down        3   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, book, second, consecutive, quarter, ...   \n",
       "1  [company, posts, drop, first-quarter, organic,...   \n",
       "2  [company, refinance, short-term, debt, early, ...   \n",
       "3  [easyjet, attracts, passengers, june, still, l...   \n",
       "4                  [company, bad, bank, chief, step]   \n",
       "\n",
       "                                           new_title  \\\n",
       "0  company book second consecutive quarter sales ...   \n",
       "1  company posts drop first-quarter organic reven...   \n",
       "2  company refinance short-term debt early , shar...   \n",
       "3  easyjet attracts passengers june still lags co...   \n",
       "4                        company bad bank chief step   \n",
       "\n",
       "                                           LMDVector  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...   \n",
       "\n",
       "                                            mean_LMD  \n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1                [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]  \n",
       "2                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4                [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = [0, 0, 0, 0, 0, 0, 0]\n",
    "nan_list = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "def run_LMD(df):\n",
    "  df['LMDVector'] = df['clean_tokens'].apply(lambda x: [LMDDictionary.get(item, zeros) for item in x])\n",
    "  df['mean_LMD'] = df['LMDVector'].apply(lambda x: np.mean(x, axis=0, dtype=np.float64))\n",
    "  \n",
    "#   df['LMDVector'] = df['new_title'].apply(lambda x: [LMDDictionary.get(item, nan_list) for item in x]) #Taynan\n",
    "#   df['mean_LMD'] = df['LMDVector'].apply(lambda x: np.nanmean(x, axis=0, dtype=np.float64)) #Taynan\n",
    "  \n",
    "run_LMD(df_train)\n",
    "run_LMD(df_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbzybLUewp70"
   },
   "source": [
    "### VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4625,
     "status": "ok",
     "timestamp": 1557926268075,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "Rtd3NaKuznfJ",
    "outputId": "bf0b6252-0363-46ef-a9c4-0ef31545661d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>quantile</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "      <th>LMDVector</th>\n",
       "      <th>mean_LMD</th>\n",
       "      <th>neu_VADER</th>\n",
       "      <th>pos_VADER</th>\n",
       "      <th>neg_VADER</th>\n",
       "      <th>compound_VADER</th>\n",
       "      <th>mean_VADER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "      <td>8</td>\n",
       "      <td>[company, book, second, consecutive, quarter, ...</td>\n",
       "      <td>company book second consecutive quarter sales ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]</td>\n",
       "      <td>[0.0, 0.698, 0.302, 0.3818]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[company, posts, drop, first-quarter, organic,...</td>\n",
       "      <td>company posts drop first-quarter organic reven...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...</td>\n",
       "      <td>[0.333, 0.667, 0.0, -0.3612]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[company, refinance, short-term, debt, early, ...</td>\n",
       "      <td>company refinance short-term debt early , shar...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]</td>\n",
       "      <td>[0.258, 0.515, 0.227, -0.0772]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "      <td>6</td>\n",
       "      <td>[easyjet, attracts, passengers, june, still, l...</td>\n",
       "      <td>easyjet attracts passengers june still lags co...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]</td>\n",
       "      <td>[0.245, 0.49, 0.265, 0.0516]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "      <td>3</td>\n",
       "      <td>[company, bad, bank, chief, step]</td>\n",
       "      <td>company bad bank chief step</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, -0.5423, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.467, 0.533, 0.0, -0.5423]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment  \\\n",
       "0  Morrisons   2      0.430   \n",
       "1        IMI   3     -0.344   \n",
       "2   Glencore   4      0.340   \n",
       "3    Ryanair   5      0.259   \n",
       "4   Barclays   6     -0.231   \n",
       "\n",
       "                                               title quantile  \\\n",
       "0  Morrisons book second consecutive quarter of s...        8   \n",
       "1  IMI posts drop in first-quarter organic revenu...        2   \n",
       "2  Glencore to refinance its short-term debt earl...        7   \n",
       "3  EasyJet attracts more passengers in June but s...        6   \n",
       "4             Barclays 'bad bank' chief to step down        3   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, book, second, consecutive, quarter, ...   \n",
       "1  [company, posts, drop, first-quarter, organic,...   \n",
       "2  [company, refinance, short-term, debt, early, ...   \n",
       "3  [easyjet, attracts, passengers, june, still, l...   \n",
       "4                  [company, bad, bank, chief, step]   \n",
       "\n",
       "                                           new_title  \\\n",
       "0  company book second consecutive quarter sales ...   \n",
       "1  company posts drop first-quarter organic reven...   \n",
       "2  company refinance short-term debt early , shar...   \n",
       "3  easyjet attracts passengers june still lags co...   \n",
       "4                        company bad bank chief step   \n",
       "\n",
       "                                           LMDVector  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...   \n",
       "\n",
       "                                            mean_LMD  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1                [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]   \n",
       "2                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4                [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neu_VADER  \\\n",
       "0                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]   \n",
       "1  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...   \n",
       "2           [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]   \n",
       "3                [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]   \n",
       "4                          [1.0, 0.0, 1.0, 1.0, 1.0]   \n",
       "\n",
       "                                           pos_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "3                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "4                          [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neg_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "4                          [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                      compound_VADER  \\\n",
       "0             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]   \n",
       "1  [0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...   \n",
       "2     [0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]   \n",
       "3         [0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]   \n",
       "4                      [0.0, -0.5423, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                       mean_VADER  \n",
       "0     [0.0, 0.698, 0.302, 0.3818]  \n",
       "1    [0.333, 0.667, 0.0, -0.3612]  \n",
       "2  [0.258, 0.515, 0.227, -0.0772]  \n",
       "3    [0.245, 0.49, 0.265, 0.0516]  \n",
       "4    [0.467, 0.533, 0.0, -0.5423]  "
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_sid(df):\n",
    "  sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "  df['neu_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['neu'] for item in x])\n",
    "  df['pos_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['pos'] for item in x])\n",
    "  df['neg_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['neg'] for item in x])\n",
    "  df['compound_VADER'] = df['clean_tokens'].apply(lambda x: [sid.polarity_scores(item)['compound'] for item in x])\n",
    "  df['mean_VADER'] = df['new_title'].apply(lambda x: [v for k,v in sid.polarity_scores(x).items()])\n",
    "  \n",
    "#   df['neu_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['neu'] for item in x]))\n",
    "#   df['pos_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['pos'] for item in x]))\n",
    "#   df['neg_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['neg'] for item in x]))\n",
    "#   df['compound_VADER'] = df['clean_tokens'].apply(lambda x: np.mean([sid.polarity_scores(item)['compound'] for item in x]))\n",
    "#   df['mean_VADER'] = df[['neu_VADER', 'pos_VADER', 'neg_VADER', 'compound_VADER']].values.tolist()\n",
    "  \n",
    "                                 \n",
    "run_sid(df_train)\n",
    "run_sid(df_test)\n",
    "\n",
    "df_train.head()\n",
    "# np.mean(df_train['neu_VADER'])\n",
    "# [np.mean(item) for item in df_train['neu_VADER']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KwglgETsGV3"
   },
   "source": [
    "### Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4622,
     "status": "ok",
     "timestamp": 1557926268076,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "Cd30mr4hsLGe",
    "outputId": "70d77caf-5577-493c-b751-f6cfd99bf925"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>quantile</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>new_title</th>\n",
       "      <th>LMDVector</th>\n",
       "      <th>mean_LMD</th>\n",
       "      <th>neu_VADER</th>\n",
       "      <th>pos_VADER</th>\n",
       "      <th>neg_VADER</th>\n",
       "      <th>compound_VADER</th>\n",
       "      <th>mean_VADER</th>\n",
       "      <th>mean_VADER_LMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "      <td>8</td>\n",
       "      <td>[company, book, second, consecutive, quarter, ...</td>\n",
       "      <td>company book second consecutive quarter sales ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]</td>\n",
       "      <td>[0.0, 0.698, 0.302, 0.3818]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[company, posts, drop, first-quarter, organic,...</td>\n",
       "      <td>company posts drop first-quarter organic reven...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...</td>\n",
       "      <td>[0.333, 0.667, 0.0, -0.3612]</td>\n",
       "      <td>[0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.333, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[company, refinance, short-term, debt, early, ...</td>\n",
       "      <td>company refinance short-term debt early , shar...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]</td>\n",
       "      <td>[0.258, 0.515, 0.227, -0.0772]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.258, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "      <td>6</td>\n",
       "      <td>[easyjet, attracts, passengers, june, still, l...</td>\n",
       "      <td>easyjet attracts passengers june still lags co...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]</td>\n",
       "      <td>[0.245, 0.49, 0.265, 0.0516]</td>\n",
       "      <td>[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "      <td>3</td>\n",
       "      <td>[company, bad, bank, chief, step]</td>\n",
       "      <td>company bad bank chief step</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, -0.5423, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.467, 0.533, 0.0, -0.5423]</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.467, 0.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment  \\\n",
       "0  Morrisons   2      0.430   \n",
       "1        IMI   3     -0.344   \n",
       "2   Glencore   4      0.340   \n",
       "3    Ryanair   5      0.259   \n",
       "4   Barclays   6     -0.231   \n",
       "\n",
       "                                               title quantile  \\\n",
       "0  Morrisons book second consecutive quarter of s...        8   \n",
       "1  IMI posts drop in first-quarter organic revenu...        2   \n",
       "2  Glencore to refinance its short-term debt earl...        7   \n",
       "3  EasyJet attracts more passengers in June but s...        6   \n",
       "4             Barclays 'bad bank' chief to step down        3   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  [company, book, second, consecutive, quarter, ...   \n",
       "1  [company, posts, drop, first-quarter, organic,...   \n",
       "2  [company, refinance, short-term, debt, early, ...   \n",
       "3  [easyjet, attracts, passengers, june, still, l...   \n",
       "4                  [company, bad, bank, chief, step]   \n",
       "\n",
       "                                           new_title  \\\n",
       "0  company book second consecutive quarter sales ...   \n",
       "1  company posts drop first-quarter organic reven...   \n",
       "2  company refinance short-term debt early , shar...   \n",
       "3  easyjet attracts passengers june still lags co...   \n",
       "4                        company bad bank chief step   \n",
       "\n",
       "                                           LMDVector  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0],...   \n",
       "\n",
       "                                            mean_LMD  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1                [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1]   \n",
       "2                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4                [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neu_VADER  \\\n",
       "0                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]   \n",
       "1  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...   \n",
       "2           [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]   \n",
       "3                [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]   \n",
       "4                          [1.0, 0.0, 1.0, 1.0, 1.0]   \n",
       "\n",
       "                                           pos_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "3                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "4                          [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                           neg_VADER  \\\n",
       "0                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2           [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "4                          [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                      compound_VADER  \\\n",
       "0             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818]   \n",
       "1  [0.0, 0.0, -0.2732, 0.0, 0.0, 0.0, 0.0, -0.102...   \n",
       "2     [0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.296, 0.0]   \n",
       "3         [0.0, 0.4019, 0.0, 0.0, 0.0, -0.3612, 0.0]   \n",
       "4                      [0.0, -0.5423, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                       mean_VADER  \\\n",
       "0     [0.0, 0.698, 0.302, 0.3818]   \n",
       "1    [0.333, 0.667, 0.0, -0.3612]   \n",
       "2  [0.258, 0.515, 0.227, -0.0772]   \n",
       "3    [0.245, 0.49, 0.265, 0.0516]   \n",
       "4    [0.467, 0.533, 0.0, -0.5423]   \n",
       "\n",
       "                                      mean_VADER_LMD  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.698...  \n",
       "1  [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.333, 0.6...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.258, 0.5...  \n",
       "3  [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4  [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.467, 0.5...  "
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_vader_LMD(df):\n",
    "  df['mean_VADER_LMD'] = [np.hstack([x,y]) for x, y in zip(df['mean_LMD'], df['mean_VADER'])]\n",
    "\n",
    "join_vader_LMD(df_train)\n",
    "join_vader_LMD(df_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKNfykDiwp76"
   },
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsTrK_2z9b-i"
   },
   "outputs": [],
   "source": [
    "# EMBEDDING_DIM = 300\n",
    "\n",
    "# TODO: use: vocab_size = max(MAX_VOCAB_SIZE, len(word_index)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCkEUlw1DL2v"
   },
   "outputs": [],
   "source": [
    "def load_embedding(emb_dim):\n",
    "  \n",
    "  # load the whole embedding into memory\n",
    "  embeddings_index = dict()\n",
    "  \n",
    "  if not os.path.exists('resources/glove.6B.zip'):\n",
    "    ! wget http://nlp.stanford.edu/data/glove.6B.zip -P /resources/\n",
    "  if not os.path.exists('resources/glove.6B.' + str(emb_dim) + 'd.txt'):\n",
    "    ! unzip resources/glove.6B.zip -d resources\n",
    "  \n",
    "  f = open('resources/glove.6B.' + str(emb_dim) + 'd.txt', 'r', encoding=\"utf8\")\n",
    "  for line in f:\n",
    "      values = line.split()\n",
    "      word = values[0]\n",
    "      coefs = np.asarray(values[1:], dtype='float32')\n",
    "      embeddings_index[word] = coefs\n",
    "  f.close()\n",
    "  \n",
    "  return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tcmZ6KVgwp78"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "def get_embedding_matrix(emb_dim, vocab_size, input_length, tokenizer, embeddings_index):\n",
    "  vocab_size = min(MAX_VOCAB_SIZE, len(tokenizer.word_index)) + 1 # Adding 1 because of reserved 0 index\n",
    "  embedding_matrix = np.zeros((vocab_size, emb_dim))\n",
    "  for word, i in tokenizer.word_index.items():\n",
    "      embedding_vector = embeddings_index.get(word)\n",
    "      if (embedding_vector is not None):\n",
    "          embedding_matrix[i] = embedding_vector\n",
    "\n",
    "  return embedding_matrix\n",
    "\n",
    "\n",
    "# banna, maca, tokenizer = get_tok_sentences(df_train['new_title'], df_test['new_title'])\n",
    "# get_embedding_matrix(300, MAX_VOCAB_SIZE, True, MAX_SEQUENCE_LENGTH, tokenizer).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buH-SkpPpdPm"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DAqcBAvnwp8A"
   },
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRqZgB3-hY7t"
   },
   "outputs": [],
   "source": [
    "def cos_sim(y_true, y_pred):\n",
    "#   x = K.l2_normalize(y_true, axis=-1)\n",
    "#   y = K.l2_normalize(y_pred, axis=-1)\n",
    "#   return K.mean(x * y, axis=-1, keepdims=True)\n",
    "  return cosine_similarity(y_true, y_pred)\n",
    "\n",
    "metrics = ['cosine_proximity']\n",
    "# dropout = 0.3\n",
    "# loss = 'mse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2B9necCNwp8D"
   },
   "outputs": [],
   "source": [
    "# callback for time: https://stackoverflow.com/questions/43178668/record-the-computation-time-for-each-epoch-in-keras-during-model-fit\n",
    "# or maybe just use keras LambdaCallback\n",
    "\n",
    "class TimeHistory(callbacks.Callback):  \n",
    "  def on_epoch_begin(self, epoch, logs={}):\n",
    "    self.epoch_time_start = time.time()\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    logs['time_passed'] = time.time() - self.epoch_time_start\n",
    "\n",
    "def callback_functions(nome_log):\n",
    "  time_callback = TimeHistory()\n",
    "  csv_logger = callbacks.CSVLogger(results_lstm + nome_log + '.csv', separator=';', append=True)\n",
    "#     tensorboard_callback = callbacks.TensorBoard(nome_log, histogram_freq=1)\n",
    "#     best_model = callbacks.ModelCheckpoint(results_lstm + nome_log + '.h5', monitor='val_loss', verbose=0, save_best_only=True, mode='auto')\n",
    "\n",
    "  return [time_callback, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeUV9qR9wp8H"
   },
   "outputs": [],
   "source": [
    "def create_model_lstm(lstm_out, num_dense, dropout_value, embedding_matrix, emb_layer_trainable):\n",
    "    vocab_size = embedding_matrix.shape[0]\n",
    "    emb_dim = embedding_matrix.shape[1]\n",
    "    \n",
    "    # first input model\n",
    "    visible1 = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), name='Word_Seq')\n",
    "    embedding = layers.Embedding(vocab_size, emb_dim, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable)(visible1)\n",
    "    lstm_layer = layers.LSTM(lstm_out, activation='relu', dropout=dropout_value, recurrent_dropout=dropout_value)(embedding)\n",
    "    flat1 = lstm_layer\n",
    "    \n",
    "    # second input model\n",
    "    visible2 = layers.Input(shape=(np.array(df_train['mean_LMD'].tolist()).shape[1],), name='Lexical')\n",
    "    flat2 = visible2\n",
    "\n",
    "    # merge input models\n",
    "    merge = layers.concatenate([flat1, flat2])\n",
    "    \n",
    "    # interpretation model\n",
    "    hidden2 = layers.Dense(num_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(merge)\n",
    "    dropout2 = layers.Dropout(dropout_value)(hidden2)\n",
    "    output = layers.Dense(1, activation='tanh')(dropout2)\n",
    "    model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "\n",
    "    return model\n",
    "    \n",
    "#     # interpretation model\n",
    "#     dropout1 = layers.Dropout(dropout_value)(pool1)\n",
    "#     hidden1 = layers.Dense(number_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n",
    "#     dropout2 = layers.Dropout(dropout_value)(hidden1)\n",
    "#     output = layers.Dense(1, activation='tanh')(dropout2)\n",
    "#     model = Model(inputs=[visible1], outputs=output)\n",
    "\n",
    "#     return model\n",
    "  \n",
    "# def create_model_lstm(lstm_out, num_dense, dropout, embedding_matrix, emb_layer_trainable):\n",
    "#     lstm = Sequential()\n",
    "#     lstm.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=emb_layer_trainable))\n",
    "#     lstm.add(layers.LSTM(lstm_out, activation='relu', dropout=dropout, recurrent_dropout=dropout))\n",
    "#     lstm.add(layers.Dense(num_dense, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "#     lstm.add(layers.Dropout(dropout))\n",
    "#     lstm.add(layers.Dense(1, activation='tanh'))\n",
    "#     return lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XMj2FWnlwp8K"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X, Y, batch_size, epochs_value, nome_log, X_cv, Y_cv):\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=metrics)\n",
    "    \n",
    "    return model.fit(X, Y, batch_size,\n",
    "                     validation_data=(X_cv, Y_cv),\n",
    "                     epochs=epochs_value,\n",
    "                     verbose=0,\n",
    "                     callbacks=callback_functions(nome_log)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPhI1NJswp8N"
   },
   "outputs": [],
   "source": [
    "def save_model(model, trained_model_history, model_name):\n",
    "    \n",
    "#     model.save(model_name + '.h5')\n",
    "    trained_model = trained_model_history\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.plot([abs(v) for v in trained_model.history['loss']])\n",
    "    plt.plot([abs(v) for v in trained_model.history['val_loss']])\n",
    "    plt.plot([abs(v) for v in trained_model.history['cosine_proximity']])\n",
    "    plt.plot([abs(v) for v in trained_model.history['val_cosine_proximity']])\n",
    "    plt.title('model mean squared error')\n",
    "    plt.ylabel('mean squared error')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['mse_train', 'mse_test', 'cos_sim_train', 'cos_sim_test'], loc='upper left')\n",
    "    plt.savefig(results_lstm + model_name + '_mse.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqcHcjJOwp8R"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, Y_expected):\n",
    "    input = X\n",
    "    output = np.array(model.predict(input))\n",
    "    expected = np.array(Y_expected)\n",
    "\n",
    "    dot = np.dot(expected, output)\n",
    "    output_mod = np.linalg.norm(output)\n",
    "    expected_mod = np.linalg.norm(expected)\n",
    "    cos = dot / output_mod / expected_mod\n",
    "\n",
    "    final_score = cos\n",
    "    \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tP6QpoR77w2y"
   },
   "source": [
    "## K-fold on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3862
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15331411,
     "status": "ok",
     "timestamp": 1557941594885,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "aMRsC6M3wp8T",
    "outputId": "89147ac9-ff1b-44e1-d900-35f7fcf214eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/xicocaio/anaconda3/envs/gairts/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "ID: 16000, Cos Sim Mean: 0.5236790175050473, Cos Sim Std: 0.021309600965433207, MSE Mean: 0.08945438248893414, MSE Std: 0.007273069593286983, Training Time: 0:00:17.245069, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16001, Cos Sim Mean: 0.5252810822052787, Cos Sim Std: 0.03399412794919172, MSE Mean: 0.09215432127633749, MSE Std: 0.008039706789738664, Training Time: 0:00:17.651843, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16002, Cos Sim Mean: 0.5308436174219143, Cos Sim Std: 0.025792388652304744, MSE Mean: 0.09214662732750115, MSE Std: 0.00782259021277297, Training Time: 0:00:16.936088, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16003, Cos Sim Mean: 0.5026620171578405, Cos Sim Std: 0.02657958704548177, MSE Mean: 0.08829467391303855, MSE Std: 0.007229983784506615, Training Time: 0:00:16.913008, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16004, Cos Sim Mean: 0.521977804847135, Cos Sim Std: 0.024215726591561192, MSE Mean: 0.08902186169986777, MSE Std: 0.009159628327335908, Training Time: 0:00:16.948139, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16005, Cos Sim Mean: 0.5361756811715088, Cos Sim Std: 0.024452893252560857, MSE Mean: 0.09125455419551098, MSE Std: 0.006806472525853319, Training Time: 0:00:16.963433, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16006, Cos Sim Mean: 0.5078547473458841, Cos Sim Std: 0.032345239667754606, MSE Mean: 0.09151481687840868, MSE Std: 0.009352331376784458, Training Time: 0:00:16.951503, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16007, Cos Sim Mean: 0.5046415590388146, Cos Sim Std: 0.04481223367531865, MSE Mean: 0.09286601326815977, MSE Std: 0.006886909091768065, Training Time: 0:00:16.939984, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16008, Cos Sim Mean: 0.5258073454773771, Cos Sim Std: 0.0370606708808451, MSE Mean: 0.09282886980137237, MSE Std: 0.007381272856950141, Training Time: 0:00:16.958159, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16009, Cos Sim Mean: 0.5149434657826951, Cos Sim Std: 0.026196647882307276, MSE Mean: 0.09015281542741838, MSE Std: 0.009155445698009473, Training Time: 0:00:16.954529, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16010, Cos Sim Mean: 0.5219307685887158, Cos Sim Std: 0.03508853578520133, MSE Mean: 0.08853798471350416, MSE Std: 0.006025508984997305, Training Time: 0:00:16.966209, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16011, Cos Sim Mean: 0.5218234679726383, Cos Sim Std: 0.02776041838118879, MSE Mean: 0.08956669731576808, MSE Std: 0.008969822687945167, Training Time: 0:00:16.974116, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16012, Cos Sim Mean: 0.5167963313196452, Cos Sim Std: 0.030360891794698537, MSE Mean: 0.09160465084265647, MSE Std: 0.008682167408869432, Training Time: 0:00:16.995906, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16013, Cos Sim Mean: 0.5218801158772796, Cos Sim Std: 0.022846391959476894, MSE Mean: 0.0910473931445259, MSE Std: 0.00711356763187489, Training Time: 0:00:16.993622, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16014, Cos Sim Mean: 0.523594107120368, Cos Sim Std: 0.018496733869940045, MSE Mean: 0.0920254917921488, MSE Std: 0.008430469737319013, Training Time: 0:00:16.982638, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16015, Cos Sim Mean: 0.5220841969590561, Cos Sim Std: 0.030908061347837853, MSE Mean: 0.08955635999338976, MSE Std: 0.00975389409139443, Training Time: 0:00:17.010642, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16016, Cos Sim Mean: 0.5342506574470466, Cos Sim Std: 0.03541872769869087, MSE Mean: 0.08997733323210005, MSE Std: 0.010417668554381197, Training Time: 0:00:16.987629, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16017, Cos Sim Mean: 0.5219556822748007, Cos Sim Std: 0.027120846955587218, MSE Mean: 0.08763241453188798, MSE Std: 0.008162530590462642, Training Time: 0:00:16.987801, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16018, Cos Sim Mean: 0.5167420958914246, Cos Sim Std: 0.03474807622105488, MSE Mean: 0.0902523892949677, MSE Std: 0.010170358559368053, Training Time: 0:00:16.992047, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16019, Cos Sim Mean: 0.5237468605504063, Cos Sim Std: 0.038972309909530045, MSE Mean: 0.08991214453366021, MSE Std: 0.007444355816660906, Training Time: 0:00:17.019199, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16020, Cos Sim Mean: 0.5219013026591101, Cos Sim Std: 0.03214603960616884, MSE Mean: 0.09113569623448939, MSE Std: 0.006854388444051149, Training Time: 0:00:17.022494, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16021, Cos Sim Mean: 0.5288715400612541, Cos Sim Std: 0.03355739336278006, MSE Mean: 0.08986737419926334, MSE Std: 0.008611723052319348, Training Time: 0:00:16.973058, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16022, Cos Sim Mean: 0.5187040365303857, Cos Sim Std: 0.030950201484886797, MSE Mean: 0.0891589632527216, MSE Std: 0.0068092279251690735, Training Time: 0:00:17.032756, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16023, Cos Sim Mean: 0.5274521784310412, Cos Sim Std: 0.0447199702854316, MSE Mean: 0.0917800426495293, MSE Std: 0.007898523585299029, Training Time: 0:00:17.013719, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16024, Cos Sim Mean: 0.5271850584749517, Cos Sim Std: 0.03943719856338686, MSE Mean: 0.0908582568972757, MSE Std: 0.009009790462177196, Training Time: 0:00:17.041448, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16025, Cos Sim Mean: 0.5272101813806178, Cos Sim Std: 0.025134176870789657, MSE Mean: 0.08874157466194774, MSE Std: 0.00660600715470075, Training Time: 0:00:16.996255, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16026, Cos Sim Mean: 0.5348149193090032, Cos Sim Std: 0.032652677510776495, MSE Mean: 0.08983188224989813, MSE Std: 0.005303729925112455, Training Time: 0:00:17.030777, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16027, Cos Sim Mean: 0.5025389405432527, Cos Sim Std: 0.02828448268424047, MSE Mean: 0.09298710537211975, MSE Std: 0.007345639937424559, Training Time: 0:00:09.731939, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16028, Cos Sim Mean: 0.5184631661717622, Cos Sim Std: 0.02923785335355315, MSE Mean: 0.09179282214558118, MSE Std: 0.00725204961246518, Training Time: 0:00:09.738709, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16029, Cos Sim Mean: 0.5272180482874755, Cos Sim Std: 0.027097853947223596, MSE Mean: 0.09188484658412813, MSE Std: 0.0068632542883084145, Training Time: 0:00:09.729022, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16030, Cos Sim Mean: 0.514988043299442, Cos Sim Std: 0.03773174769432358, MSE Mean: 0.0898613570767656, MSE Std: 0.007760042984410146, Training Time: 0:00:09.751316, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16031, Cos Sim Mean: 0.5220986774132472, Cos Sim Std: 0.035777739252186865, MSE Mean: 0.0909740814634085, MSE Std: 0.005141793692101939, Training Time: 0:00:09.739759, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16032, Cos Sim Mean: 0.534049127989421, Cos Sim Std: 0.015109734528253824, MSE Mean: 0.09543590548477912, MSE Std: 0.009673320525360185, Training Time: 0:00:09.735075, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16033, Cos Sim Mean: 0.5203236465614114, Cos Sim Std: 0.04271205405025847, MSE Mean: 0.0882725140078032, MSE Std: 0.006228773537439755, Training Time: 0:00:09.740140, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16034, Cos Sim Mean: 0.5255151527029255, Cos Sim Std: 0.03506468782154561, MSE Mean: 0.09048227888590359, MSE Std: 0.006050512727774763, Training Time: 0:00:09.749595, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16035, Cos Sim Mean: 0.5240434899212577, Cos Sim Std: 0.04285451253140015, MSE Mean: 0.09368073987530808, MSE Std: 0.00826322371708356, Training Time: 0:00:09.751374, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16036, Cos Sim Mean: 0.5237686317397925, Cos Sim Std: 0.03253623879906493, MSE Mean: 0.08986845300359352, MSE Std: 0.008566013331933705, Training Time: 0:00:09.655086, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16037, Cos Sim Mean: 0.5394927556905981, Cos Sim Std: 0.03901620338753446, MSE Mean: 0.09128264477107696, MSE Std: 0.007850138252162677, Training Time: 0:00:09.658673, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16038, Cos Sim Mean: 0.5216042244614416, Cos Sim Std: 0.03530139085740639, MSE Mean: 0.09494430960035627, MSE Std: 0.011620475264764984, Training Time: 0:00:09.697272, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16039, Cos Sim Mean: 0.5291938502764063, Cos Sim Std: 0.046739077800488714, MSE Mean: 0.08985503023274681, MSE Std: 0.010087873175743845, Training Time: 0:00:09.659987, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16040, Cos Sim Mean: 0.5342954895655991, Cos Sim Std: 0.03979580439757926, MSE Mean: 0.08930226808887622, MSE Std: 0.00888929970215999, Training Time: 0:00:09.645283, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16041, Cos Sim Mean: 0.5095122378935905, Cos Sim Std: 0.02978826846291466, MSE Mean: 0.09474457602855607, MSE Std: 0.00886283525843169, Training Time: 0:00:09.647772, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16042, Cos Sim Mean: 0.541307434211755, Cos Sim Std: 0.03514458840788955, MSE Mean: 0.09004496515055371, MSE Std: 0.00998229695522867, Training Time: 0:00:09.683734, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16043, Cos Sim Mean: 0.5165831636845922, Cos Sim Std: 0.01918670999068056, MSE Mean: 0.08879120648036286, MSE Std: 0.007679417963514839, Training Time: 0:00:09.735642, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16044, Cos Sim Mean: 0.5339485229374775, Cos Sim Std: 0.040848568871517436, MSE Mean: 0.09127627980262518, MSE Std: 0.01071499051759301, Training Time: 0:00:09.650612, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16045, Cos Sim Mean: 0.5184539681532013, Cos Sim Std: 0.01800984166820101, MSE Mean: 0.08668173896269778, MSE Std: 0.006653250503525792, Training Time: 0:00:09.678368, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16046, Cos Sim Mean: 0.52727176099615, Cos Sim Std: 0.03711429107814064, MSE Mean: 0.08798732492007298, MSE Std: 0.0065121510398776835, Training Time: 0:00:09.693024, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16047, Cos Sim Mean: 0.5184588986871052, Cos Sim Std: 0.030115000410514896, MSE Mean: 0.08981056632565851, MSE Std: 0.00430707809829585, Training Time: 0:00:09.654695, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16048, Cos Sim Mean: 0.5187242423457301, Cos Sim Std: 0.053606600498929194, MSE Mean: 0.08882270492440074, MSE Std: 0.008522459495398012, Training Time: 0:00:09.670450, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16049, Cos Sim Mean: 0.5236760826267878, Cos Sim Std: 0.043527417008734005, MSE Mean: 0.09091514652619118, MSE Std: 0.009145880391541204, Training Time: 0:00:09.661412, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16050, Cos Sim Mean: 0.527293405803923, Cos Sim Std: 0.033010624495302066, MSE Mean: 0.09083067380392573, MSE Std: 0.004706020718070487, Training Time: 0:00:09.654272, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16051, Cos Sim Mean: 0.5201153269477339, Cos Sim Std: 0.017982012849540003, MSE Mean: 0.08867892648630141, MSE Std: 0.00943252178576634, Training Time: 0:00:09.655941, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16052, Cos Sim Mean: 0.5115926755109548, Cos Sim Std: 0.03345716009613691, MSE Mean: 0.08881773512843963, MSE Std: 0.006891302111455149, Training Time: 0:00:09.665255, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16053, Cos Sim Mean: 0.5359969712305641, Cos Sim Std: 0.040095483168643586, MSE Mean: 0.09046142032735431, MSE Std: 0.0059743770104029705, Training Time: 0:00:09.646002, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16054, Cos Sim Mean: 0.5236942729600175, Cos Sim Std: 0.017405375355590145, MSE Mean: 0.09262304911176414, MSE Std: 0.004488405231413167, Training Time: 0:00:17.592297, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16055, Cos Sim Mean: 0.5131275630707742, Cos Sim Std: 0.02189201891590264, MSE Mean: 0.09590109401673283, MSE Std: 0.009388980498813653, Training Time: 0:00:17.625766, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16056, Cos Sim Mean: 0.49578771961975915, Cos Sim Std: 0.03223255720144899, MSE Mean: 0.0970231789536556, MSE Std: 0.007028753301534206, Training Time: 0:00:17.677743, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16057, Cos Sim Mean: 0.5325801446856102, Cos Sim Std: 0.0316236781390613, MSE Mean: 0.08919033322047279, MSE Std: 0.0070219235498350865, Training Time: 0:00:17.655572, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16058, Cos Sim Mean: 0.5131119746891907, Cos Sim Std: 0.02463645538412384, MSE Mean: 0.08986678913110921, MSE Std: 0.007953182094685958, Training Time: 0:00:17.670958, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16059, Cos Sim Mean: 0.513729597096406, Cos Sim Std: 0.05107312246398966, MSE Mean: 0.09292313276866089, MSE Std: 0.00824626788379944, Training Time: 0:00:17.694725, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16060, Cos Sim Mean: 0.5115687581171287, Cos Sim Std: 0.04247322545808715, MSE Mean: 0.09037528121065334, MSE Std: 0.007897189233140516, Training Time: 0:00:17.703315, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16061, Cos Sim Mean: 0.5483269308612486, Cos Sim Std: 0.027500063197931603, MSE Mean: 0.09106976275045078, MSE Std: 0.00786956334815754, Training Time: 0:00:17.700704, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16062, Cos Sim Mean: 0.4957996610539503, Cos Sim Std: 0.04353843661442543, MSE Mean: 0.0950199672698558, MSE Std: 0.010649659668195213, Training Time: 0:00:17.794133, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16063, Cos Sim Mean: 0.5306055498168105, Cos Sim Std: 0.03525562836483585, MSE Mean: 0.09059874469078227, MSE Std: 0.006975591375311352, Training Time: 0:00:17.764874, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16064, Cos Sim Mean: 0.514925211452707, Cos Sim Std: 0.04478890946068338, MSE Mean: 0.08921700650064458, MSE Std: 0.00812266757153471, Training Time: 0:00:17.708779, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16065, Cos Sim Mean: 0.5306278626698533, Cos Sim Std: 0.024619795358900104, MSE Mean: 0.09166737614118167, MSE Std: 0.0064489410785527135, Training Time: 0:00:17.679577, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16066, Cos Sim Mean: 0.49741232202469765, Cos Sim Std: 0.030456300836344184, MSE Mean: 0.09013351178848414, MSE Std: 0.009443687809300865, Training Time: 0:00:17.697153, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16067, Cos Sim Mean: 0.534304623214646, Cos Sim Std: 0.03737036985658016, MSE Mean: 0.09258073253701019, MSE Std: 0.010596694959239497, Training Time: 0:00:17.722673, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16068, Cos Sim Mean: 0.5500604652715559, Cos Sim Std: 0.030436870146544476, MSE Mean: 0.09143225462490637, MSE Std: 0.0056593503271756855, Training Time: 0:00:17.707852, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16069, Cos Sim Mean: 0.5202755294052895, Cos Sim Std: 0.03066475872384367, MSE Mean: 0.0895080672281863, MSE Std: 0.008079850311636577, Training Time: 0:00:17.719199, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16070, Cos Sim Mean: 0.5169445318395002, Cos Sim Std: 0.03198199184656361, MSE Mean: 0.08830228140878985, MSE Std: 0.007191842129994613, Training Time: 0:00:17.699389, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16071, Cos Sim Mean: 0.5237085906847566, Cos Sim Std: 0.026178129699444695, MSE Mean: 0.09099040426570026, MSE Std: 0.006418446057261233, Training Time: 0:00:17.709284, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16072, Cos Sim Mean: 0.5395758542177227, Cos Sim Std: 0.03301880836915348, MSE Mean: 0.08889412089295455, MSE Std: 0.009844861159632663, Training Time: 0:00:17.744251, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16073, Cos Sim Mean: 0.5480807740626598, Cos Sim Std: 0.03431186957904154, MSE Mean: 0.08979322223920126, MSE Std: 0.009885998525028099, Training Time: 0:00:17.768897, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16074, Cos Sim Mean: 0.5165959582578108, Cos Sim Std: 0.04205524972146154, MSE Mean: 0.08858316505845702, MSE Std: 0.010379067970216054, Training Time: 0:00:17.747100, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16075, Cos Sim Mean: 0.5325161694429766, Cos Sim Std: 0.04604246008483978, MSE Mean: 0.08895731625176692, MSE Std: 0.01045250596364925, Training Time: 0:00:17.747504, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16076, Cos Sim Mean: 0.5270573212436258, Cos Sim Std: 0.026583716397662896, MSE Mean: 0.08906588101829914, MSE Std: 0.009000802018291097, Training Time: 0:00:17.730013, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16077, Cos Sim Mean: 0.5411315964398012, Cos Sim Std: 0.028547884593671663, MSE Mean: 0.0890281958557752, MSE Std: 0.007326094312902885, Training Time: 0:00:17.695011, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16078, Cos Sim Mean: 0.5448761825718259, Cos Sim Std: 0.03946495268085539, MSE Mean: 0.09021605187520701, MSE Std: 0.011128683233854478, Training Time: 0:00:17.709783, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16079, Cos Sim Mean: 0.5377741626058854, Cos Sim Std: 0.042521153025266156, MSE Mean: 0.08880211167332162, MSE Std: 0.00863353007142644, Training Time: 0:00:17.732014, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16080, Cos Sim Mean: 0.5342661830480266, Cos Sim Std: 0.03608017795378245, MSE Mean: 0.08946521931140305, MSE Std: 0.006073246361783327, Training Time: 0:00:17.756176, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16081, Cos Sim Mean: 0.5326432012811261, Cos Sim Std: 0.03322940350689016, MSE Mean: 0.09406233213682362, MSE Std: 0.005906347283782418, Training Time: 0:00:10.302525, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16082, Cos Sim Mean: 0.5275843326070344, Cos Sim Std: 0.04021098908547591, MSE Mean: 0.09596148675657318, MSE Std: 0.006965009144791849, Training Time: 0:00:10.339174, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16083, Cos Sim Mean: 0.5171626140022837, Cos Sim Std: 0.04873163761075737, MSE Mean: 0.09920875458801981, MSE Std: 0.008208524244111635, Training Time: 0:00:10.308853, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16084, Cos Sim Mean: 0.5465247640523831, Cos Sim Std: 0.03352174380285628, MSE Mean: 0.09223483038182959, MSE Std: 0.009180572420420278, Training Time: 0:00:10.318025, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16085, Cos Sim Mean: 0.5361732209415109, Cos Sim Std: 0.04273682538366183, MSE Mean: 0.09253777150567506, MSE Std: 0.009931545843374143, Training Time: 0:00:10.311506, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16086, Cos Sim Mean: 0.5552086165637251, Cos Sim Std: 0.02515050548367383, MSE Mean: 0.09317366432768931, MSE Std: 0.009300404301391606, Training Time: 0:00:10.324489, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16087, Cos Sim Mean: 0.5079325181373893, Cos Sim Std: 0.030978599224963398, MSE Mean: 0.09102089113514736, MSE Std: 0.0071564957432844675, Training Time: 0:00:10.317412, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16088, Cos Sim Mean: 0.5202824413879499, Cos Sim Std: 0.024681109020314805, MSE Mean: 0.09110058602869196, MSE Std: 0.007694223640510049, Training Time: 0:00:10.299614, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16089, Cos Sim Mean: 0.528995599514093, Cos Sim Std: 0.016356519929593822, MSE Mean: 0.09614852952541324, MSE Std: 0.008171648815418455, Training Time: 0:00:10.310660, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16090, Cos Sim Mean: 0.5273531933999085, Cos Sim Std: 0.05219442887662288, MSE Mean: 0.08964289072824318, MSE Std: 0.007703704817685943, Training Time: 0:00:10.258518, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16091, Cos Sim Mean: 0.5166424729575346, Cos Sim Std: 0.035264198236573195, MSE Mean: 0.09100355911970079, MSE Std: 0.007150306102749507, Training Time: 0:00:10.245142, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16092, Cos Sim Mean: 0.5218092143662985, Cos Sim Std: 0.026610254132755615, MSE Mean: 0.09431407814949155, MSE Std: 0.007923008068585475, Training Time: 0:00:10.230490, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16093, Cos Sim Mean: 0.5325967507706114, Cos Sim Std: 0.03501193527676902, MSE Mean: 0.09125798632771553, MSE Std: 0.01050229772296409, Training Time: 0:00:10.252034, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16094, Cos Sim Mean: 0.5343376290647313, Cos Sim Std: 0.04825197541564961, MSE Mean: 0.09172467397255983, MSE Std: 0.007479498146213863, Training Time: 0:00:10.249968, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16095, Cos Sim Mean: 0.5376928091616089, Cos Sim Std: 0.050130901401768645, MSE Mean: 0.093840576021546, MSE Std: 0.008031953441229488, Training Time: 0:00:10.230951, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16096, Cos Sim Mean: 0.5342213986214739, Cos Sim Std: 0.025607102015768678, MSE Mean: 0.08746976968702667, MSE Std: 0.009864488470430527, Training Time: 0:00:10.226533, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16097, Cos Sim Mean: 0.5256165864928971, Cos Sim Std: 0.03562066023411536, MSE Mean: 0.09048674513494691, MSE Std: 0.007922442771371488, Training Time: 0:00:10.259124, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16098, Cos Sim Mean: 0.5272730141643647, Cos Sim Std: 0.021800109370452684, MSE Mean: 0.0943548421296883, MSE Std: 0.008518157844704765, Training Time: 0:00:10.234576, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16099, Cos Sim Mean: 0.5077646564049368, Cos Sim Std: 0.02283164076765804, MSE Mean: 0.0878174554130646, MSE Std: 0.00934175697131819, Training Time: 0:00:10.240417, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16100, Cos Sim Mean: 0.5185517186238842, Cos Sim Std: 0.025267852037084596, MSE Mean: 0.08881697742211757, MSE Std: 0.009239123804528718, Training Time: 0:00:10.230828, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16101, Cos Sim Mean: 0.5254777131569148, Cos Sim Std: 0.027251590642177716, MSE Mean: 0.08964629731267923, MSE Std: 0.008038808350514737, Training Time: 0:00:10.274215, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16102, Cos Sim Mean: 0.5446714191859936, Cos Sim Std: 0.027028415415956537, MSE Mean: 0.08709568682385388, MSE Std: 0.009505384659671528, Training Time: 0:00:10.243855, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16103, Cos Sim Mean: 0.5289557019873788, Cos Sim Std: 0.031026942038850522, MSE Mean: 0.08918541084867555, MSE Std: 0.009535163642123461, Training Time: 0:00:10.239255, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16104, Cos Sim Mean: 0.5340537600428389, Cos Sim Std: 0.036743701211067646, MSE Mean: 0.08906104405742223, MSE Std: 0.006447421984292929, Training Time: 0:00:10.260731, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16105, Cos Sim Mean: 0.5271247511183864, Cos Sim Std: 0.03043606248566949, MSE Mean: 0.08730305760668353, MSE Std: 0.009081790899818871, Training Time: 0:00:10.246848, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16106, Cos Sim Mean: 0.5361583637706617, Cos Sim Std: 0.03342163370185312, MSE Mean: 0.08878108221874743, MSE Std: 0.008619671735422519, Training Time: 0:00:10.241481, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16107, Cos Sim Mean: 0.5308955235537285, Cos Sim Std: 0.02665396585995144, MSE Mean: 0.08770294153210015, MSE Std: 0.005627920752538856, Training Time: 0:00:10.233793, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16108, Cos Sim Mean: 0.5256015184651401, Cos Sim Std: 0.022948410017806207, MSE Mean: 0.09331070057099596, MSE Std: 0.006686269951315927, Training Time: 0:00:17.507624, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16109, Cos Sim Mean: 0.5290046733974427, Cos Sim Std: 0.024408851821987834, MSE Mean: 0.0946513566389981, MSE Std: 0.007074166727106856, Training Time: 0:00:17.433789, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16110, Cos Sim Mean: 0.5186981530638062, Cos Sim Std: 0.03367649190295063, MSE Mean: 0.09618517224356421, MSE Std: 0.008967104211564167, Training Time: 0:00:17.441327, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16111, Cos Sim Mean: 0.5322391090683695, Cos Sim Std: 0.021196058418855832, MSE Mean: 0.09149308679710852, MSE Std: 0.008154994967781354, Training Time: 0:00:17.502300, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16112, Cos Sim Mean: 0.5321774844734147, Cos Sim Std: 0.02719577911027506, MSE Mean: 0.09075127861586613, MSE Std: 0.0074532092760119665, Training Time: 0:00:17.531473, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16113, Cos Sim Mean: 0.530413692047311, Cos Sim Std: 0.03426217878563869, MSE Mean: 0.09498930593327168, MSE Std: 0.007665426027226091, Training Time: 0:00:17.506287, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16114, Cos Sim Mean: 0.5374234330607466, Cos Sim Std: 0.03546758182456683, MSE Mean: 0.09187193573791941, MSE Std: 0.008028874623687248, Training Time: 0:00:17.495126, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16115, Cos Sim Mean: 0.5098056972383864, Cos Sim Std: 0.048027560103751483, MSE Mean: 0.09292063572197637, MSE Std: 0.006787907775137234, Training Time: 0:00:17.514419, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16116, Cos Sim Mean: 0.5060331668525097, Cos Sim Std: 0.014972260449680908, MSE Mean: 0.0966897467332484, MSE Std: 0.011046894034283893, Training Time: 0:00:17.532596, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16117, Cos Sim Mean: 0.5149203432378046, Cos Sim Std: 0.029822845032734063, MSE Mean: 0.0929991047935371, MSE Std: 0.00927213871454712, Training Time: 0:00:17.479859, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16118, Cos Sim Mean: 0.5287679398443241, Cos Sim Std: 0.03289177330650955, MSE Mean: 0.09030471505691073, MSE Std: 0.00563203598654135, Training Time: 0:00:17.521456, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16119, Cos Sim Mean: 0.5164903413387552, Cos Sim Std: 0.030319521812627113, MSE Mean: 0.09479265357949154, MSE Std: 0.009991400022409887, Training Time: 0:00:17.503499, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16120, Cos Sim Mean: 0.5305927536419073, Cos Sim Std: 0.025384491404357543, MSE Mean: 0.08907245656647202, MSE Std: 0.008002846979572494, Training Time: 0:00:17.545505, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16121, Cos Sim Mean: 0.5285858205895722, Cos Sim Std: 0.0360031966809622, MSE Mean: 0.09140136695776088, MSE Std: 0.00727982089385417, Training Time: 0:00:17.503817, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16122, Cos Sim Mean: 0.5409561366534373, Cos Sim Std: 0.03157424039485128, MSE Mean: 0.09457349025097112, MSE Std: 0.008867724478919212, Training Time: 0:00:17.510924, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16123, Cos Sim Mean: 0.5216639015940577, Cos Sim Std: 0.04111932871900987, MSE Mean: 0.0906457091549575, MSE Std: 0.010159592275330986, Training Time: 0:00:17.533850, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16124, Cos Sim Mean: 0.5095431797655428, Cos Sim Std: 0.035122874332092296, MSE Mean: 0.09000451138828426, MSE Std: 0.0074242535438566026, Training Time: 0:00:17.519270, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16125, Cos Sim Mean: 0.5410507038750112, Cos Sim Std: 0.02237717725364687, MSE Mean: 0.09137587379175201, MSE Std: 0.00854476205907497, Training Time: 0:00:17.575525, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16126, Cos Sim Mean: 0.5184182509064087, Cos Sim Std: 0.047405047488053284, MSE Mean: 0.0898655752304158, MSE Std: 0.009758102251355207, Training Time: 0:00:17.547791, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16127, Cos Sim Mean: 0.5356224879243403, Cos Sim Std: 0.04297750372933943, MSE Mean: 0.08968037080828642, MSE Std: 0.006984828240357693, Training Time: 0:00:17.530914, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16128, Cos Sim Mean: 0.5200683522550358, Cos Sim Std: 0.03892315403394808, MSE Mean: 0.09073342174728681, MSE Std: 0.007135030499604564, Training Time: 0:00:17.535762, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16129, Cos Sim Mean: 0.5430617748384372, Cos Sim Std: 0.038014243506794505, MSE Mean: 0.08965049382056392, MSE Std: 0.007063008819346034, Training Time: 0:00:17.537667, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16130, Cos Sim Mean: 0.5409566137110546, Cos Sim Std: 0.030167988625485243, MSE Mean: 0.08955436169491375, MSE Std: 0.009480355815280117, Training Time: 0:00:17.578823, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16131, Cos Sim Mean: 0.5198244003141358, Cos Sim Std: 0.04013716575917326, MSE Mean: 0.09213585625726256, MSE Std: 0.006898409803075858, Training Time: 0:00:17.556248, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16132, Cos Sim Mean: 0.5220459801727162, Cos Sim Std: 0.03633447252645141, MSE Mean: 0.09138165292554298, MSE Std: 0.007978566255994163, Training Time: 0:00:17.521184, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16133, Cos Sim Mean: 0.5341980067441628, Cos Sim Std: 0.025130754032632235, MSE Mean: 0.08892662387849476, MSE Std: 0.00701646398420553, Training Time: 0:00:17.493061, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16134, Cos Sim Mean: 0.5216415732030834, Cos Sim Std: 0.0397947138135291, MSE Mean: 0.08969991497732577, MSE Std: 0.0062995098813178295, Training Time: 0:00:17.544943, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16135, Cos Sim Mean: 0.5236710724494877, Cos Sim Std: 0.027669098705489975, MSE Mean: 0.09644699562897371, MSE Std: 0.00756278621927642, Training Time: 0:00:10.190877, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16136, Cos Sim Mean: 0.5428165548177304, Cos Sim Std: 0.03789480583193748, MSE Mean: 0.09698846551196082, MSE Std: 0.007737535947495232, Training Time: 0:00:10.196914, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16137, Cos Sim Mean: 0.5255790812266574, Cos Sim Std: 0.03792803227187327, MSE Mean: 0.09936038126995514, MSE Std: 0.008538746463498857, Training Time: 0:00:10.166875, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16138, Cos Sim Mean: 0.5183525514379926, Cos Sim Std: 0.026715138952050833, MSE Mean: 0.09207343808071337, MSE Std: 0.0074585746644399535, Training Time: 0:00:10.199290, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16139, Cos Sim Mean: 0.5289341011572477, Cos Sim Std: 0.022933737141067483, MSE Mean: 0.09480575967457028, MSE Std: 0.01042937821121334, Training Time: 0:00:10.193150, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16140, Cos Sim Mean: 0.5170441396003677, Cos Sim Std: 0.04870805644726275, MSE Mean: 0.10103528566334741, MSE Std: 0.008546447635852798, Training Time: 0:00:10.162758, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16141, Cos Sim Mean: 0.5217267193262565, Cos Sim Std: 0.016913246443738237, MSE Mean: 0.09217150353271172, MSE Std: 0.0071189418201186025, Training Time: 0:00:10.181492, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16142, Cos Sim Mean: 0.5407838198326017, Cos Sim Std: 0.03218115197699585, MSE Mean: 0.09292327187123707, MSE Std: 0.007196088377549325, Training Time: 0:00:10.200136, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16143, Cos Sim Mean: 0.5218244040952396, Cos Sim Std: 0.019740418167804738, MSE Mean: 0.09986512426459966, MSE Std: 0.009119363058600337, Training Time: 0:00:10.189056, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16144, Cos Sim Mean: 0.5077957067847718, Cos Sim Std: 0.023474074926534166, MSE Mean: 0.09313429624572847, MSE Std: 0.008913372486746611, Training Time: 0:00:10.074306, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16145, Cos Sim Mean: 0.5235200386580269, Cos Sim Std: 0.034526095460702566, MSE Mean: 0.0937789473963571, MSE Std: 0.006925992569714505, Training Time: 0:00:10.115733, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16146, Cos Sim Mean: 0.5253405834784508, Cos Sim Std: 0.027830622964763855, MSE Mean: 0.09894843430450986, MSE Std: 0.008772082867643981, Training Time: 0:00:10.095368, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16147, Cos Sim Mean: 0.5253495134184952, Cos Sim Std: 0.02934340148890708, MSE Mean: 0.09307159191893467, MSE Std: 0.009690280585606403, Training Time: 0:00:10.110810, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16148, Cos Sim Mean: 0.5149589919032123, Cos Sim Std: 0.027065019902238866, MSE Mean: 0.09373579953065377, MSE Std: 0.008236410366093544, Training Time: 0:00:10.086529, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16149, Cos Sim Mean: 0.5147837393985896, Cos Sim Std: 0.023951634231871247, MSE Mean: 0.09591208231922826, MSE Std: 0.008405339942686928, Training Time: 0:00:10.088247, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16150, Cos Sim Mean: 0.5182240822095268, Cos Sim Std: 0.02689148721073087, MSE Mean: 0.09197764260966065, MSE Std: 0.009220238390298544, Training Time: 0:00:10.114083, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16151, Cos Sim Mean: 0.5078276967737096, Cos Sim Std: 0.02049446930256458, MSE Mean: 0.09195801935078343, MSE Std: 0.006148076306416206, Training Time: 0:00:10.105318, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16152, Cos Sim Mean: 0.5200463751144497, Cos Sim Std: 0.03113214921610774, MSE Mean: 0.09562230982691612, MSE Std: 0.008027995048923285, Training Time: 0:00:10.089290, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16153, Cos Sim Mean: 0.5322526360310933, Cos Sim Std: 0.03000701949200053, MSE Mean: 0.08822799203792463, MSE Std: 0.008695697926975944, Training Time: 0:00:10.165667, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16154, Cos Sim Mean: 0.5287476876199364, Cos Sim Std: 0.057072463683077036, MSE Mean: 0.08790403440661135, MSE Std: 0.005980541121967482, Training Time: 0:00:10.134451, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16155, Cos Sim Mean: 0.5238500024568357, Cos Sim Std: 0.04952359186919639, MSE Mean: 0.0929831610174324, MSE Std: 0.007499848822416474, Training Time: 0:00:10.134910, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16156, Cos Sim Mean: 0.5411176106958347, Cos Sim Std: 0.027684071809531124, MSE Mean: 0.08768290371574419, MSE Std: 0.0068956966780131185, Training Time: 0:00:10.147809, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16157, Cos Sim Mean: 0.5341211905006583, Cos Sim Std: 0.03596270548339926, MSE Mean: 0.08922877514453283, MSE Std: 0.005887373517142149, Training Time: 0:00:10.129757, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16158, Cos Sim Mean: 0.521748111482484, Cos Sim Std: 0.022224987272929736, MSE Mean: 0.09295820697593683, MSE Std: 0.0035851027616889365, Training Time: 0:00:10.132970, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16159, Cos Sim Mean: 0.5378901060344776, Cos Sim Std: 0.03793583161665888, MSE Mean: 0.08769381366434625, MSE Std: 0.006546787932453209, Training Time: 0:00:10.118092, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16160, Cos Sim Mean: 0.5238296718072892, Cos Sim Std: 0.03451074148878264, MSE Mean: 0.09117805059298631, MSE Std: 0.00728266917773934, Training Time: 0:00:10.147735, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16161, Cos Sim Mean: 0.5063579819079503, Cos Sim Std: 0.05165901288326598, MSE Mean: 0.09262106654929, MSE Std: 0.005622422100485075, Training Time: 0:00:10.156909, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16162, Cos Sim Mean: 0.5361130564360087, Cos Sim Std: 0.03448371368331675, MSE Mean: 0.09444000688763399, MSE Std: 0.008509820365694707, Training Time: 0:00:17.503079, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16163, Cos Sim Mean: 0.5397886920716033, Cos Sim Std: 0.05368142529040796, MSE Mean: 0.09798218686686219, MSE Std: 0.008643908482211483, Training Time: 0:00:17.405577, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16164, Cos Sim Mean: 0.5183357369316418, Cos Sim Std: 0.03889631990826795, MSE Mean: 0.10320843998036296, MSE Std: 0.009507407759451015, Training Time: 0:00:17.423603, Batch: 32, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16165, Cos Sim Mean: 0.5272458746392372, Cos Sim Std: 0.0369147259749137, MSE Mean: 0.09265908607713386, MSE Std: 0.009557454387999228, Training Time: 0:00:17.452685, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16166, Cos Sim Mean: 0.5342828971015008, Cos Sim Std: 0.01936810786272878, MSE Mean: 0.09530389759660696, MSE Std: 0.009746257153192335, Training Time: 0:00:17.426503, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16167, Cos Sim Mean: 0.5096080702738016, Cos Sim Std: 0.04074758285768749, MSE Mean: 0.10559457094073141, MSE Std: 0.010580186788757374, Training Time: 0:00:17.454584, Batch: 32, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16168, Cos Sim Mean: 0.5325794159716593, Cos Sim Std: 0.03310705435255148, MSE Mean: 0.09268349158209625, MSE Std: 0.006105720470767809, Training Time: 0:00:17.435757, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16169, Cos Sim Mean: 0.5203320761357674, Cos Sim Std: 0.05548365766695954, MSE Mean: 0.09637783169150721, MSE Std: 0.008452730880860555, Training Time: 0:00:17.461295, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16170, Cos Sim Mean: 0.5323952979339139, Cos Sim Std: 0.035666734134326465, MSE Mean: 0.10087792261706152, MSE Std: 0.007024110011383808, Training Time: 0:00:17.431592, Batch: 32, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16171, Cos Sim Mean: 0.5148720382018313, Cos Sim Std: 0.04338634823142087, MSE Mean: 0.09290706512173319, MSE Std: 0.007626346880557656, Training Time: 0:00:17.509159, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16172, Cos Sim Mean: 0.5397264457533925, Cos Sim Std: 0.048807598118875264, MSE Mean: 0.09496852699944544, MSE Std: 0.007347563340457601, Training Time: 0:00:17.503815, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16173, Cos Sim Mean: 0.5341976738933918, Cos Sim Std: 0.03029584567204044, MSE Mean: 0.09852385164936316, MSE Std: 0.006160068684220235, Training Time: 0:00:17.536674, Batch: 32, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16174, Cos Sim Mean: 0.5412515322889968, Cos Sim Std: 0.05280645930785137, MSE Mean: 0.09329057569150398, MSE Std: 0.007444894706464402, Training Time: 0:00:17.500744, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16175, Cos Sim Mean: 0.5447327290696957, Cos Sim Std: 0.030175011796191503, MSE Mean: 0.09624511860762755, MSE Std: 0.006537035033499654, Training Time: 0:00:17.543044, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16176, Cos Sim Mean: 0.5341831469026951, Cos Sim Std: 0.030685336557869754, MSE Mean: 0.10086613539594827, MSE Std: 0.008475080917228584, Training Time: 0:00:17.536844, Batch: 32, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16177, Cos Sim Mean: 0.5270490408636817, Cos Sim Std: 0.039745062103033614, MSE Mean: 0.09440394774451703, MSE Std: 0.008381335007710438, Training Time: 0:00:17.524850, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16178, Cos Sim Mean: 0.5411697840303726, Cos Sim Std: 0.034155142967005246, MSE Mean: 0.09565287332300047, MSE Std: 0.008079118337342392, Training Time: 0:00:17.549625, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16179, Cos Sim Mean: 0.5395475947219118, Cos Sim Std: 0.019383291216366373, MSE Mean: 0.1005816765235175, MSE Std: 0.005444355549339281, Training Time: 0:00:17.556746, Batch: 32, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16180, Cos Sim Mean: 0.5360823558903415, Cos Sim Std: 0.04771939543449644, MSE Mean: 0.09236370263522052, MSE Std: 0.01007319640547406, Training Time: 0:00:17.578116, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16181, Cos Sim Mean: 0.530710564725336, Cos Sim Std: 0.03500213022133513, MSE Mean: 0.09102927432519617, MSE Std: 0.007501023801604393, Training Time: 0:00:17.538428, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16182, Cos Sim Mean: 0.5271486018032554, Cos Sim Std: 0.02618774416688809, MSE Mean: 0.0950695193842257, MSE Std: 0.007137925824010177, Training Time: 0:00:17.637655, Batch: 32, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16183, Cos Sim Mean: 0.5238736624892818, Cos Sim Std: 0.04893824356088931, MSE Mean: 0.0917575233352759, MSE Std: 0.009390262868618476, Training Time: 0:00:17.607486, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16184, Cos Sim Mean: 0.5360867287564431, Cos Sim Std: 0.04701684203776309, MSE Mean: 0.09031954927325178, MSE Std: 0.008808645177176059, Training Time: 0:00:18.357518, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16185, Cos Sim Mean: 0.5481428134506042, Cos Sim Std: 0.027093623609274923, MSE Mean: 0.09314980695419874, MSE Std: 0.007916150184187927, Training Time: 0:00:18.085411, Batch: 32, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16186, Cos Sim Mean: 0.5378278731987101, Cos Sim Std: 0.04975574451898066, MSE Mean: 0.09122566304847582, MSE Std: 0.009784390393414411, Training Time: 0:00:18.073628, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16187, Cos Sim Mean: 0.5429689543221459, Cos Sim Std: 0.044545429014600756, MSE Mean: 0.08965932377009579, MSE Std: 0.007173452753088212, Training Time: 0:00:17.651814, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16188, Cos Sim Mean: 0.5183526931570168, Cos Sim Std: 0.04455117316825935, MSE Mean: 0.09403690430689686, MSE Std: 0.00879443057618375, Training Time: 0:00:17.607796, Batch: 32, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16189, Cos Sim Mean: 0.5186707805522897, Cos Sim Std: 0.0434345342868969, MSE Mean: 0.09852360135253616, MSE Std: 0.007814578916945335, Training Time: 0:00:10.255543, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16190, Cos Sim Mean: 0.528936769670163, Cos Sim Std: 0.01702709669658275, MSE Mean: 0.10247624083797499, MSE Std: 0.006813835322910545, Training Time: 0:00:10.330079, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16191, Cos Sim Mean: 0.5112027120493519, Cos Sim Std: 0.041505519110812975, MSE Mean: 0.11639221923707177, MSE Std: 0.006518378155479266, Training Time: 0:00:10.239078, Batch: 64, LSTM Out: 50, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16192, Cos Sim Mean: 0.5360869823896948, Cos Sim Std: 0.04352522943006927, MSE Mean: 0.09503227706388179, MSE Std: 0.00841156319246622, Training Time: 0:00:10.241987, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16193, Cos Sim Mean: 0.522273121519728, Cos Sim Std: 0.040691737580236684, MSE Mean: 0.09925799133668317, MSE Std: 0.006172882477684339, Training Time: 0:00:10.246449, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16194, Cos Sim Mean: 0.49702870407351635, Cos Sim Std: 0.050594821541906955, MSE Mean: 0.11529698275062591, MSE Std: 0.00743551304181533, Training Time: 0:00:10.341490, Batch: 64, LSTM Out: 50, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16195, Cos Sim Mean: 0.5395453729589125, Cos Sim Std: 0.027009440294559133, MSE Mean: 0.09411884766252432, MSE Std: 0.005132898905294617, Training Time: 0:00:10.236081, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16196, Cos Sim Mean: 0.5324822517484611, Cos Sim Std: 0.014163030209534418, MSE Mean: 0.09881718404362871, MSE Std: 0.006505849499003647, Training Time: 0:00:10.230656, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16197, Cos Sim Mean: 0.5077557260859954, Cos Sim Std: 0.03251081108865987, MSE Mean: 0.11112328197993486, MSE Std: 0.006648560027807338, Training Time: 0:00:10.249705, Batch: 64, LSTM Out: 50, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16198, Cos Sim Mean: 0.5236289670906636, Cos Sim Std: 0.04232718893348149, MSE Mean: 0.09422361695819392, MSE Std: 0.00811973046785934, Training Time: 0:00:10.167739, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16199, Cos Sim Mean: 0.5308166262089514, Cos Sim Std: 0.039455129525961564, MSE Mean: 0.0999709403202525, MSE Std: 0.007833696511552683, Training Time: 0:00:10.182667, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16200, Cos Sim Mean: 0.5287516062375845, Cos Sim Std: 0.03221993514795379, MSE Mean: 0.10770004202346703, MSE Std: 0.007400619911776663, Training Time: 0:00:10.182181, Batch: 64, LSTM Out: 100, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16201, Cos Sim Mean: 0.5183352985431506, Cos Sim Std: 0.04209793871441996, MSE Mean: 0.09729601914636124, MSE Std: 0.007774452814144995, Training Time: 0:00:10.211710, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16202, Cos Sim Mean: 0.5432812560956785, Cos Sim Std: 0.05135673599097987, MSE Mean: 0.09791010620334838, MSE Std: 0.008003326028380687, Training Time: 0:00:10.177137, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16203, Cos Sim Mean: 0.5063900174564608, Cos Sim Std: 0.03524474356903952, MSE Mean: 0.10327316220385714, MSE Std: 0.00695886285591805, Training Time: 0:00:10.186354, Batch: 64, LSTM Out: 100, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16204, Cos Sim Mean: 0.5428163483245502, Cos Sim Std: 0.03794363324232916, MSE Mean: 0.09655259966778165, MSE Std: 0.007349997946720968, Training Time: 0:00:10.186921, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16205, Cos Sim Mean: 0.5325501588914119, Cos Sim Std: 0.022249031917615448, MSE Mean: 0.0994972912628576, MSE Std: 0.007282597895977773, Training Time: 0:00:10.228609, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16206, Cos Sim Mean: 0.5025294868524354, Cos Sim Std: 0.036122817440014166, MSE Mean: 0.1058344267948835, MSE Std: 0.009037144252845025, Training Time: 0:00:10.165644, Batch: 64, LSTM Out: 100, Num Dense: 150, Dropout: 0.5\n",
      "ID: 16207, Cos Sim Mean: 0.5343877872544145, Cos Sim Std: 0.03949021565236224, MSE Mean: 0.09297867199556906, MSE Std: 0.0049885467829806195, Training Time: 0:00:10.182747, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.3\n",
      "ID: 16208, Cos Sim Mean: 0.5292219837159906, Cos Sim Std: 0.0485203492460019, MSE Mean: 0.09413991555305956, MSE Std: 0.006339266250413472, Training Time: 0:00:10.207119, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.4\n",
      "ID: 16209, Cos Sim Mean: 0.5290140792385778, Cos Sim Std: 0.026531707063590922, MSE Mean: 0.1007450543506053, MSE Std: 0.005595165048456278, Training Time: 0:00:10.195144, Batch: 64, LSTM Out: 150, Num Dense: 50, Dropout: 0.5\n",
      "ID: 16210, Cos Sim Mean: 0.5237604504582494, Cos Sim Std: 0.03805528392280718, MSE Mean: 0.0929042133635491, MSE Std: 0.006720352565946705, Training Time: 0:00:10.226575, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.3\n",
      "ID: 16211, Cos Sim Mean: 0.5188465105032899, Cos Sim Std: 0.052901640648951996, MSE Mean: 0.0936863955128556, MSE Std: 0.007423740546390095, Training Time: 0:00:10.191970, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.4\n",
      "ID: 16212, Cos Sim Mean: 0.5360085030374484, Cos Sim Std: 0.019663857402738214, MSE Mean: 0.09962271258927897, MSE Std: 0.005720826091815308, Training Time: 0:00:10.242499, Batch: 64, LSTM Out: 150, Num Dense: 100, Dropout: 0.5\n",
      "ID: 16213, Cos Sim Mean: 0.5290327257138886, Cos Sim Std: 0.027535341419673186, MSE Mean: 0.09438209385366875, MSE Std: 0.006254560037121696, Training Time: 0:00:10.195221, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.3\n",
      "ID: 16214, Cos Sim Mean: 0.5309704386344828, Cos Sim Std: 0.04908554585420437, MSE Mean: 0.09404235058966419, MSE Std: 0.007305983126610801, Training Time: 0:00:10.201725, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.4\n",
      "ID: 16215, Cos Sim Mean: 0.5187101746722377, Cos Sim Std: 0.039630908492084706, MSE Mean: 0.09838658403733075, MSE Std: 0.004774620874869303, Training Time: 0:00:10.195874, Batch: 64, LSTM Out: 150, Num Dense: 150, Dropout: 0.5\n"
     ]
    }
   ],
   "source": [
    "def run_kfold(kfold_id, number_epochs):\n",
    "  resumo = pd.DataFrame(columns=['kfold_id','cos_sim_mean','cos_sim_std','mse_mean','mse_std','training_time','batch_size','lstm_out','num_dense','dropout'])\n",
    "\n",
    "  for emb_dim in [300, 200, 100, 50]:\n",
    "\n",
    "    embeddings_index_kfold = load_embedding(emb_dim)\n",
    "\n",
    "    for batch_size in [32, 64]:\n",
    "        for lstm_out in [50, 100, 150]:\n",
    "            for num_dense in [50, 100, 150]:\n",
    "                for dropout in [0.3, 0.4, 0.5]:\n",
    "\n",
    "                        cvscores_mse = []\n",
    "                        cvscores_cos_sim = []\n",
    "                        time_list = []\n",
    "\n",
    "                        seed = 42\n",
    "                        np.random.seed(seed)\n",
    "\n",
    "                        for train, val in skf.split(df_train, df_train['quantile']):\n",
    "    #                         print(train)\n",
    "                            X_train = df_train.iloc[train]\n",
    "                            X_val = df_train.iloc[val]\n",
    "\n",
    "                            Y_train = df_train['sentiment'].iloc[train]\n",
    "                            Y_val = df_train['sentiment'].iloc[val]\n",
    "\n",
    "                            # get sentences ready for usage\n",
    "                            sentences_train_pad, sentences_val_pad, tok_kfold = get_tok_sentences(X_train[\"new_title\"], X_val[\"new_title\"])\n",
    "\n",
    "                            embedding_matrix = get_embedding_matrix(emb_dim, MAX_VOCAB_SIZE, MAX_SEQUENCE_LENGTH, tok_kfold, embeddings_index_kfold)\n",
    "\n",
    "    #                         nn_input_train = {'Word_Seq': sentences_train_pad, 'Lexical': np.array(X_train['mean_VADER_LMD'].tolist())}\n",
    "    #                         nn_input_val = {'Word_Seq': sentences_val_pad, 'Lexical': np.array(X_val['mean_VADER_LMD'].tolist())}\n",
    "                            nn_input_train = {'Word_Seq': sentences_train_pad, 'Lexical': np.array(X_train['mean_LMD'].tolist())}\n",
    "                            nn_input_val = {'Word_Seq': sentences_val_pad, 'Lexical': np.array(X_val['mean_LMD'].tolist())}\n",
    "\n",
    "                            model_name = 'kfoldid_' + str(kfold_id) + '-dim_' + str(emb_dim) + '-bs_' + str(batch_size) + '-lo_' + str(lstm_out) + '-nd_' + str(num_dense) + '-dv_' + str(10*dropout)\n",
    "\n",
    "                            lstm = create_model_lstm(lstm_out, num_dense, dropout, embedding_matrix, True)\n",
    "\n",
    "                            init = datetime.datetime.now()\n",
    "                            trained = train_model(lstm, nn_input_train, Y_train, batch_size, number_epochs, model_name, nn_input_val, Y_val)\n",
    "                            training_time = (datetime.datetime.now() - init)\n",
    "                            cvscores_mse.append(trained.history['val_loss'][-1])\n",
    "                            cvscores_cos_sim.append(-trained.history['val_cosine_proximity'][-1])\n",
    "                            time_list.append(training_time)\n",
    "                            # save_model(lstm, trained, model_name)\n",
    "\n",
    "                            if K.backend() == 'tensorflow':\n",
    "                              K.clear_session()\n",
    "\n",
    "                        result = [kfold_id, np.mean(cvscores_cos_sim), np.std(cvscores_cos_sim), np.mean(cvscores_mse), np.std(cvscores_mse), np.mean(time_list), batch_size, lstm_out, num_dense, dropout]\n",
    "                        resumo = resumo.append(pd.Series(result, index=resumo.columns), ignore_index=True)\n",
    "\n",
    "                        print('ID: {}, Cos Sim Mean: {}, Cos Sim Std: {}, MSE Mean: {}, MSE Std: {}, Training Time: {}, Batch: {}, LSTM Out: {}, Num Dense: {}, Dropout: {}'.format(*result))\n",
    "\n",
    "                        kfold_id = kfold_id + 1\n",
    "                        \n",
    "  return resumo\n",
    "      \n",
    "kfold_id = 16000\n",
    "number_epochs = 30\n",
    "      \n",
    "resumo = run_kfold(kfold_id, number_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1969
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15331415,
     "status": "ok",
     "timestamp": 1557941594890,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "2uxkO9P3wp8W",
    "outputId": "2744314e-69ff-4667-b9ee-f7ae5ed6a0cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kfold_id</th>\n",
       "      <th>cos_sim_mean</th>\n",
       "      <th>cos_sim_std</th>\n",
       "      <th>mse_mean</th>\n",
       "      <th>mse_std</th>\n",
       "      <th>training_time</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lstm_out</th>\n",
       "      <th>num_dense</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>16045</td>\n",
       "      <td>0.518454</td>\n",
       "      <td>0.018010</td>\n",
       "      <td>0.086682</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>00:00:09.678368</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>16102</td>\n",
       "      <td>0.544671</td>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.087096</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>00:00:10.243855</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>16105</td>\n",
       "      <td>0.527125</td>\n",
       "      <td>0.030436</td>\n",
       "      <td>0.087303</td>\n",
       "      <td>0.009082</td>\n",
       "      <td>00:00:10.246848</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>16096</td>\n",
       "      <td>0.534221</td>\n",
       "      <td>0.025607</td>\n",
       "      <td>0.087470</td>\n",
       "      <td>0.009864</td>\n",
       "      <td>00:00:10.226533</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16017</td>\n",
       "      <td>0.521956</td>\n",
       "      <td>0.027121</td>\n",
       "      <td>0.087632</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>00:00:16.987801</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>16156</td>\n",
       "      <td>0.541118</td>\n",
       "      <td>0.027684</td>\n",
       "      <td>0.087683</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>00:00:10.147809</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>16159</td>\n",
       "      <td>0.537890</td>\n",
       "      <td>0.037936</td>\n",
       "      <td>0.087694</td>\n",
       "      <td>0.006547</td>\n",
       "      <td>00:00:10.118092</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>16107</td>\n",
       "      <td>0.530896</td>\n",
       "      <td>0.026654</td>\n",
       "      <td>0.087703</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>00:00:10.233793</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>16099</td>\n",
       "      <td>0.507765</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>00:00:10.240417</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>16154</td>\n",
       "      <td>0.528748</td>\n",
       "      <td>0.057072</td>\n",
       "      <td>0.087904</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>00:00:10.134451</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>16046</td>\n",
       "      <td>0.527272</td>\n",
       "      <td>0.037114</td>\n",
       "      <td>0.087987</td>\n",
       "      <td>0.006512</td>\n",
       "      <td>00:00:09.693024</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>16153</td>\n",
       "      <td>0.532253</td>\n",
       "      <td>0.030007</td>\n",
       "      <td>0.088228</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>00:00:10.165667</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16033</td>\n",
       "      <td>0.520324</td>\n",
       "      <td>0.042712</td>\n",
       "      <td>0.088273</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>00:00:09.740140</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16003</td>\n",
       "      <td>0.502662</td>\n",
       "      <td>0.026580</td>\n",
       "      <td>0.088295</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>00:00:16.913008</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>16070</td>\n",
       "      <td>0.516945</td>\n",
       "      <td>0.031982</td>\n",
       "      <td>0.088302</td>\n",
       "      <td>0.007192</td>\n",
       "      <td>00:00:17.699389</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16010</td>\n",
       "      <td>0.521931</td>\n",
       "      <td>0.035089</td>\n",
       "      <td>0.088538</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>00:00:16.966209</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>16074</td>\n",
       "      <td>0.516596</td>\n",
       "      <td>0.042055</td>\n",
       "      <td>0.088583</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>00:00:17.747100</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>16051</td>\n",
       "      <td>0.520115</td>\n",
       "      <td>0.017982</td>\n",
       "      <td>0.088679</td>\n",
       "      <td>0.009433</td>\n",
       "      <td>00:00:09.655941</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16025</td>\n",
       "      <td>0.527210</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.088742</td>\n",
       "      <td>0.006606</td>\n",
       "      <td>00:00:16.996255</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>16106</td>\n",
       "      <td>0.536158</td>\n",
       "      <td>0.033422</td>\n",
       "      <td>0.088781</td>\n",
       "      <td>0.008620</td>\n",
       "      <td>00:00:10.241481</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>16043</td>\n",
       "      <td>0.516583</td>\n",
       "      <td>0.019187</td>\n",
       "      <td>0.088791</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>00:00:09.735642</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>16079</td>\n",
       "      <td>0.537774</td>\n",
       "      <td>0.042521</td>\n",
       "      <td>0.088802</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>00:00:17.732014</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>16100</td>\n",
       "      <td>0.518552</td>\n",
       "      <td>0.025268</td>\n",
       "      <td>0.088817</td>\n",
       "      <td>0.009239</td>\n",
       "      <td>00:00:10.230828</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>16052</td>\n",
       "      <td>0.511593</td>\n",
       "      <td>0.033457</td>\n",
       "      <td>0.088818</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>00:00:09.665255</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>16048</td>\n",
       "      <td>0.518724</td>\n",
       "      <td>0.053607</td>\n",
       "      <td>0.088823</td>\n",
       "      <td>0.008522</td>\n",
       "      <td>00:00:09.670450</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>16072</td>\n",
       "      <td>0.539576</td>\n",
       "      <td>0.033019</td>\n",
       "      <td>0.088894</td>\n",
       "      <td>0.009845</td>\n",
       "      <td>00:00:17.744251</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>16133</td>\n",
       "      <td>0.534198</td>\n",
       "      <td>0.025131</td>\n",
       "      <td>0.088927</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>00:00:17.493061</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>16075</td>\n",
       "      <td>0.532516</td>\n",
       "      <td>0.046042</td>\n",
       "      <td>0.088957</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>00:00:17.747504</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16004</td>\n",
       "      <td>0.521978</td>\n",
       "      <td>0.024216</td>\n",
       "      <td>0.089022</td>\n",
       "      <td>0.009160</td>\n",
       "      <td>00:00:16.948139</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>16077</td>\n",
       "      <td>0.541132</td>\n",
       "      <td>0.028548</td>\n",
       "      <td>0.089028</td>\n",
       "      <td>0.007326</td>\n",
       "      <td>00:00:17.695011</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>16056</td>\n",
       "      <td>0.495788</td>\n",
       "      <td>0.032233</td>\n",
       "      <td>0.097023</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>00:00:17.677743</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>16201</td>\n",
       "      <td>0.518335</td>\n",
       "      <td>0.042098</td>\n",
       "      <td>0.097296</td>\n",
       "      <td>0.007774</td>\n",
       "      <td>00:00:10.211710</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>16202</td>\n",
       "      <td>0.543281</td>\n",
       "      <td>0.051357</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>00:00:10.177137</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>16163</td>\n",
       "      <td>0.539789</td>\n",
       "      <td>0.053681</td>\n",
       "      <td>0.097982</td>\n",
       "      <td>0.008644</td>\n",
       "      <td>00:00:17.405577</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>16215</td>\n",
       "      <td>0.518710</td>\n",
       "      <td>0.039631</td>\n",
       "      <td>0.098387</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>00:00:10.195874</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>16189</td>\n",
       "      <td>0.518671</td>\n",
       "      <td>0.043435</td>\n",
       "      <td>0.098524</td>\n",
       "      <td>0.007815</td>\n",
       "      <td>00:00:10.255543</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>16173</td>\n",
       "      <td>0.534198</td>\n",
       "      <td>0.030296</td>\n",
       "      <td>0.098524</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>00:00:17.536674</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>16196</td>\n",
       "      <td>0.532482</td>\n",
       "      <td>0.014163</td>\n",
       "      <td>0.098817</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>00:00:10.230656</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>16146</td>\n",
       "      <td>0.525341</td>\n",
       "      <td>0.027831</td>\n",
       "      <td>0.098948</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>00:00:10.095368</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>16083</td>\n",
       "      <td>0.517163</td>\n",
       "      <td>0.048732</td>\n",
       "      <td>0.099209</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>00:00:10.308853</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>16193</td>\n",
       "      <td>0.522273</td>\n",
       "      <td>0.040692</td>\n",
       "      <td>0.099258</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>00:00:10.246449</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>16137</td>\n",
       "      <td>0.525579</td>\n",
       "      <td>0.037928</td>\n",
       "      <td>0.099360</td>\n",
       "      <td>0.008539</td>\n",
       "      <td>00:00:10.166875</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>16205</td>\n",
       "      <td>0.532550</td>\n",
       "      <td>0.022249</td>\n",
       "      <td>0.099497</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>00:00:10.228609</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>16212</td>\n",
       "      <td>0.536009</td>\n",
       "      <td>0.019664</td>\n",
       "      <td>0.099623</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>00:00:10.242499</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>16143</td>\n",
       "      <td>0.521824</td>\n",
       "      <td>0.019740</td>\n",
       "      <td>0.099865</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>00:00:10.189056</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>16199</td>\n",
       "      <td>0.530817</td>\n",
       "      <td>0.039455</td>\n",
       "      <td>0.099971</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>00:00:10.182667</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>16179</td>\n",
       "      <td>0.539548</td>\n",
       "      <td>0.019383</td>\n",
       "      <td>0.100582</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>00:00:17.556746</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>16209</td>\n",
       "      <td>0.529014</td>\n",
       "      <td>0.026532</td>\n",
       "      <td>0.100745</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>00:00:10.195144</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>16176</td>\n",
       "      <td>0.534183</td>\n",
       "      <td>0.030685</td>\n",
       "      <td>0.100866</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>00:00:17.536844</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>16170</td>\n",
       "      <td>0.532395</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.100878</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>00:00:17.431592</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>16140</td>\n",
       "      <td>0.517044</td>\n",
       "      <td>0.048708</td>\n",
       "      <td>0.101035</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>00:00:10.162758</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>16190</td>\n",
       "      <td>0.528937</td>\n",
       "      <td>0.017027</td>\n",
       "      <td>0.102476</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>00:00:10.330079</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>16164</td>\n",
       "      <td>0.518336</td>\n",
       "      <td>0.038896</td>\n",
       "      <td>0.103208</td>\n",
       "      <td>0.009507</td>\n",
       "      <td>00:00:17.423603</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>16203</td>\n",
       "      <td>0.506390</td>\n",
       "      <td>0.035245</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>00:00:10.186354</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>16167</td>\n",
       "      <td>0.509608</td>\n",
       "      <td>0.040748</td>\n",
       "      <td>0.105595</td>\n",
       "      <td>0.010580</td>\n",
       "      <td>00:00:17.454584</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>16206</td>\n",
       "      <td>0.502529</td>\n",
       "      <td>0.036123</td>\n",
       "      <td>0.105834</td>\n",
       "      <td>0.009037</td>\n",
       "      <td>00:00:10.165644</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>16200</td>\n",
       "      <td>0.528752</td>\n",
       "      <td>0.032220</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>0.007401</td>\n",
       "      <td>00:00:10.182181</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>16197</td>\n",
       "      <td>0.507756</td>\n",
       "      <td>0.032511</td>\n",
       "      <td>0.111123</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>00:00:10.249705</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>16194</td>\n",
       "      <td>0.497029</td>\n",
       "      <td>0.050595</td>\n",
       "      <td>0.115297</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>00:00:10.341490</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>16191</td>\n",
       "      <td>0.511203</td>\n",
       "      <td>0.041506</td>\n",
       "      <td>0.116392</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>00:00:10.239078</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    kfold_id  cos_sim_mean  cos_sim_std  mse_mean   mse_std   training_time  \\\n",
       "45     16045      0.518454     0.018010  0.086682  0.006653 00:00:09.678368   \n",
       "102    16102      0.544671     0.027028  0.087096  0.009505 00:00:10.243855   \n",
       "105    16105      0.527125     0.030436  0.087303  0.009082 00:00:10.246848   \n",
       "96     16096      0.534221     0.025607  0.087470  0.009864 00:00:10.226533   \n",
       "17     16017      0.521956     0.027121  0.087632  0.008163 00:00:16.987801   \n",
       "156    16156      0.541118     0.027684  0.087683  0.006896 00:00:10.147809   \n",
       "159    16159      0.537890     0.037936  0.087694  0.006547 00:00:10.118092   \n",
       "107    16107      0.530896     0.026654  0.087703  0.005628 00:00:10.233793   \n",
       "99     16099      0.507765     0.022832  0.087817  0.009342 00:00:10.240417   \n",
       "154    16154      0.528748     0.057072  0.087904  0.005981 00:00:10.134451   \n",
       "46     16046      0.527272     0.037114  0.087987  0.006512 00:00:09.693024   \n",
       "153    16153      0.532253     0.030007  0.088228  0.008696 00:00:10.165667   \n",
       "33     16033      0.520324     0.042712  0.088273  0.006229 00:00:09.740140   \n",
       "3      16003      0.502662     0.026580  0.088295  0.007230 00:00:16.913008   \n",
       "70     16070      0.516945     0.031982  0.088302  0.007192 00:00:17.699389   \n",
       "10     16010      0.521931     0.035089  0.088538  0.006026 00:00:16.966209   \n",
       "74     16074      0.516596     0.042055  0.088583  0.010379 00:00:17.747100   \n",
       "51     16051      0.520115     0.017982  0.088679  0.009433 00:00:09.655941   \n",
       "25     16025      0.527210     0.025134  0.088742  0.006606 00:00:16.996255   \n",
       "106    16106      0.536158     0.033422  0.088781  0.008620 00:00:10.241481   \n",
       "43     16043      0.516583     0.019187  0.088791  0.007679 00:00:09.735642   \n",
       "79     16079      0.537774     0.042521  0.088802  0.008634 00:00:17.732014   \n",
       "100    16100      0.518552     0.025268  0.088817  0.009239 00:00:10.230828   \n",
       "52     16052      0.511593     0.033457  0.088818  0.006891 00:00:09.665255   \n",
       "48     16048      0.518724     0.053607  0.088823  0.008522 00:00:09.670450   \n",
       "72     16072      0.539576     0.033019  0.088894  0.009845 00:00:17.744251   \n",
       "133    16133      0.534198     0.025131  0.088927  0.007016 00:00:17.493061   \n",
       "75     16075      0.532516     0.046042  0.088957  0.010453 00:00:17.747504   \n",
       "4      16004      0.521978     0.024216  0.089022  0.009160 00:00:16.948139   \n",
       "77     16077      0.541132     0.028548  0.089028  0.007326 00:00:17.695011   \n",
       "..       ...           ...          ...       ...       ...             ...   \n",
       "56     16056      0.495788     0.032233  0.097023  0.007029 00:00:17.677743   \n",
       "201    16201      0.518335     0.042098  0.097296  0.007774 00:00:10.211710   \n",
       "202    16202      0.543281     0.051357  0.097910  0.008003 00:00:10.177137   \n",
       "163    16163      0.539789     0.053681  0.097982  0.008644 00:00:17.405577   \n",
       "215    16215      0.518710     0.039631  0.098387  0.004775 00:00:10.195874   \n",
       "189    16189      0.518671     0.043435  0.098524  0.007815 00:00:10.255543   \n",
       "173    16173      0.534198     0.030296  0.098524  0.006160 00:00:17.536674   \n",
       "196    16196      0.532482     0.014163  0.098817  0.006506 00:00:10.230656   \n",
       "146    16146      0.525341     0.027831  0.098948  0.008772 00:00:10.095368   \n",
       "83     16083      0.517163     0.048732  0.099209  0.008209 00:00:10.308853   \n",
       "193    16193      0.522273     0.040692  0.099258  0.006173 00:00:10.246449   \n",
       "137    16137      0.525579     0.037928  0.099360  0.008539 00:00:10.166875   \n",
       "205    16205      0.532550     0.022249  0.099497  0.007283 00:00:10.228609   \n",
       "212    16212      0.536009     0.019664  0.099623  0.005721 00:00:10.242499   \n",
       "143    16143      0.521824     0.019740  0.099865  0.009119 00:00:10.189056   \n",
       "199    16199      0.530817     0.039455  0.099971  0.007834 00:00:10.182667   \n",
       "179    16179      0.539548     0.019383  0.100582  0.005444 00:00:17.556746   \n",
       "209    16209      0.529014     0.026532  0.100745  0.005595 00:00:10.195144   \n",
       "176    16176      0.534183     0.030685  0.100866  0.008475 00:00:17.536844   \n",
       "170    16170      0.532395     0.035667  0.100878  0.007024 00:00:17.431592   \n",
       "140    16140      0.517044     0.048708  0.101035  0.008546 00:00:10.162758   \n",
       "190    16190      0.528937     0.017027  0.102476  0.006814 00:00:10.330079   \n",
       "164    16164      0.518336     0.038896  0.103208  0.009507 00:00:17.423603   \n",
       "203    16203      0.506390     0.035245  0.103273  0.006959 00:00:10.186354   \n",
       "167    16167      0.509608     0.040748  0.105595  0.010580 00:00:17.454584   \n",
       "206    16206      0.502529     0.036123  0.105834  0.009037 00:00:10.165644   \n",
       "200    16200      0.528752     0.032220  0.107700  0.007401 00:00:10.182181   \n",
       "197    16197      0.507756     0.032511  0.111123  0.006649 00:00:10.249705   \n",
       "194    16194      0.497029     0.050595  0.115297  0.007436 00:00:10.341490   \n",
       "191    16191      0.511203     0.041506  0.116392  0.006518 00:00:10.239078   \n",
       "\n",
       "    batch_size lstm_out num_dense  dropout  \n",
       "45          64      150        50      0.3  \n",
       "102         64      150       100      0.3  \n",
       "105         64      150       150      0.3  \n",
       "96          64      100       150      0.3  \n",
       "17          32      100       150      0.5  \n",
       "156         64      150       100      0.3  \n",
       "159         64      150       150      0.3  \n",
       "107         64      150       150      0.5  \n",
       "99          64      150        50      0.3  \n",
       "154         64      150        50      0.4  \n",
       "46          64      150        50      0.4  \n",
       "153         64      150        50      0.3  \n",
       "33          64       50       150      0.3  \n",
       "3           32       50       100      0.3  \n",
       "70          32      100       150      0.4  \n",
       "10          32      100        50      0.4  \n",
       "74          32      150        50      0.5  \n",
       "51          64      150       150      0.3  \n",
       "25          32      150       150      0.4  \n",
       "106         64      150       150      0.4  \n",
       "43          64      100       150      0.4  \n",
       "79          32      150       150      0.4  \n",
       "100         64      150        50      0.4  \n",
       "52          64      150       150      0.4  \n",
       "48          64      150       100      0.3  \n",
       "72          32      150        50      0.3  \n",
       "133         32      150       150      0.4  \n",
       "75          32      150       100      0.3  \n",
       "4           32       50       100      0.4  \n",
       "77          32      150       100      0.5  \n",
       "..         ...      ...       ...      ...  \n",
       "56          32       50        50      0.5  \n",
       "201         64      100       100      0.3  \n",
       "202         64      100       100      0.4  \n",
       "163         32       50        50      0.4  \n",
       "215         64      150       150      0.5  \n",
       "189         64       50        50      0.3  \n",
       "173         32      100        50      0.5  \n",
       "196         64       50       150      0.4  \n",
       "146         64      100        50      0.5  \n",
       "83          64       50        50      0.5  \n",
       "193         64       50       100      0.4  \n",
       "137         64       50        50      0.5  \n",
       "205         64      100       150      0.4  \n",
       "212         64      150       100      0.5  \n",
       "143         64       50       150      0.5  \n",
       "199         64      100        50      0.4  \n",
       "179         32      100       150      0.5  \n",
       "209         64      150        50      0.5  \n",
       "176         32      100       100      0.5  \n",
       "170         32       50       150      0.5  \n",
       "140         64       50       100      0.5  \n",
       "190         64       50        50      0.4  \n",
       "164         32       50        50      0.5  \n",
       "203         64      100       100      0.5  \n",
       "167         32       50       100      0.5  \n",
       "206         64      100       150      0.5  \n",
       "200         64      100        50      0.5  \n",
       "197         64       50       150      0.5  \n",
       "194         64       50       100      0.5  \n",
       "191         64       50        50      0.5  \n",
       "\n",
       "[216 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melhores = resumo.sort_values('mse_mean', ascending=True)\n",
    "melhores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HIS50lITwp8Y"
   },
   "outputs": [],
   "source": [
    "# melhores.to_csv(results_lstm + 'resumo/' + 'Resultados10.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOYAEG4dwp8c"
   },
   "outputs": [],
   "source": [
    "# melhores = resumo.sort_values('Score Mean', ascending=False)\n",
    "# melhores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3ubm-0ewp8e"
   },
   "outputs": [],
   "source": [
    "# melhores.to_csv('Resultados3.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ICvVLbG2ET2e"
   },
   "source": [
    "### Results Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVQEWgXy9A9H"
   },
   "outputs": [],
   "source": [
    "# specifying results filepath dest file\n",
    "results_filepath = 'results/lstm/lstm-emb_lmd-5-fold-v0.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Mgz7mWaEXOI"
   },
   "outputs": [],
   "source": [
    "# this function goes through all csv results process and group them together\n",
    "def process_raw_data(results_filepath):\n",
    "  all_files = glob.glob(results_lstm + \"*.csv\")\n",
    "#   all_files = glob.glob(results_lstm + \"kfoldid_10000-dim_300-bs_32-nf_384-sf_4-nd_150-dv_3.0.csv\")\n",
    "\n",
    "  li = []\n",
    "  \n",
    "  for filename in all_files:\n",
    "    # 1) we process the filename which has info in itself\n",
    "    params_raw = filename.strip(results_lstm).strip('.csv').split('-')\n",
    "    \n",
    "    params_dict = dict()\n",
    "\n",
    "    for param in params_raw:\n",
    "      key, value = param.split('_')\n",
    "      if key == 'dv':\n",
    "        params_dict[key] = float(value) / 10 \n",
    "      else:\n",
    "        params_dict[key] = int(value)\n",
    "      \n",
    "    df_params = pd.DataFrame(params_dict, index=[0])\n",
    "    df_params.columns = ['kfold_id','emb_dim','batch_size','lstm_out','num_dense','dropout']\n",
    "\n",
    "    # 2) we process the content inside the file\n",
    "    df_results = pd.read_csv(filename, index_col=None, header=0, sep=';')\n",
    "    df_results = df_results.groupby(['epoch'], as_index=False).mean().join(df_results.groupby(['epoch']).std(), lsuffix='_mean', rsuffix='_std')\n",
    "    \n",
    "    # 2.1) Converting negative values to positives\n",
    "    df_results['cosine_proximity_mean'] = abs(df_results['cosine_proximity_mean'])\n",
    "    df_results['val_cosine_proximity_mean'] = abs(df_results['val_cosine_proximity_mean'])\n",
    "  \n",
    "    # 2.2) Defining row with best value\n",
    "    df_results['best_val_loss_mean'] = False\n",
    "    df_results['best_val_cosine_proximity_mean'] = False\n",
    "  \n",
    "    best_val_loss_mean = df_results['val_loss_mean'].min()\n",
    "    best_val_cosine_proximity_mean = df_results['val_cosine_proximity_mean'].max()\n",
    "  \n",
    "    df_results.loc[df_results['val_loss_mean'] == best_val_loss_mean, 'best_val_loss_mean'] = True\n",
    "    df_results.loc[df_results['val_cosine_proximity_mean'] == best_val_cosine_proximity_mean, 'best_val_cosine_proximity_mean'] = True\n",
    "\n",
    "    # 3) we join all info together\n",
    "    df_processed = df_params.join(df_results, how='right').ffill()\n",
    "    \n",
    "    # 4) changing some of the collumns to int\n",
    "    df_processed[['kfold_id','emb_dim','batch_size','lstm_out','num_dense']] = df_processed[['kfold_id','emb_dim','batch_size','lstm_out','num_dense']].astype('int64')\n",
    "    \n",
    "    li.append(df_processed)\n",
    "    \n",
    "  df_final = pd.concat(li, axis=0, ignore_index=True)\n",
    "  \n",
    "  df_final.to_csv(results_filepath, index=False, sep=',', encoding='utf-8')\n",
    "  \n",
    "process_raw_data(results_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S6T0i-OHwp8i"
   },
   "source": [
    "## Treinando em todo o conjunto de Treino e avaliando no conjunto de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15331439,
     "status": "ok",
     "timestamp": 1557941594919,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "uXYPn4A48h0R",
    "outputId": "d18df1aa-cd96-44b0-f884-728d2d2e0e97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kfold_id                               16051\n",
       "emb_dim                                  300\n",
       "batch_size                                64\n",
       "lstm_out                                 150\n",
       "num_dense                                150\n",
       "dropout                                  0.3\n",
       "epoch                                     22\n",
       "cosine_proximity_mean               0.867369\n",
       "loss_mean                          0.0194162\n",
       "time_passed_mean                    0.263041\n",
       "val_cosine_proximity_mean           0.530719\n",
       "val_loss_mean                      0.0860817\n",
       "cosine_proximity_std               0.0180472\n",
       "loss_std                           0.0010322\n",
       "time_passed_std                    0.0016695\n",
       "val_cosine_proximity_std           0.0330405\n",
       "val_loss_std                      0.00853572\n",
       "best_val_loss_mean                      True\n",
       "best_val_cosine_proximity_mean         False\n",
       "Name: 562, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting best models\n",
    "df_results = pd.read_csv(results_filepath)\n",
    "\n",
    "best_mse_model = df_results[df_results['best_val_loss_mean'] == True].sort_values(by=['val_loss_mean']).iloc[0]\n",
    "best_cos_model = df_results[df_results['best_val_cosine_proximity_mean'] == True].sort_values(by=['val_cosine_proximity_mean'], ascending=[False]).iloc[0]\n",
    "\n",
    "# best_cos_model[['emb_dim', 'lstm_out', 'size_filters', 'num_dense', 'dropout', 'epoch', 'batch_size']]\n",
    "best_mse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fsY1wB0xwp8i"
   },
   "outputs": [],
   "source": [
    "def run_final_test(best_model_config, eval_type):\n",
    "\n",
    "  # fix random seed for reproducibility\n",
    "  seed = 42\n",
    "  np.random.seed(seed)\n",
    "\n",
    "  emb_dim, lstm_out, num_dense, dropout, epoch, batch_size = best_model_config[['emb_dim', 'lstm_out', 'num_dense', 'dropout', 'epoch', 'batch_size']]\n",
    "\n",
    "#   emb_dim, lstm_out, num_dense, dropout, epoch, batch_size = 300, 150, 50, 0.3, 30, 32\n",
    "\n",
    "  embeddings_index_final = load_embedding(emb_dim)\n",
    "\n",
    "  sentences_train_final_pad, sentences_test_final_pad, tok_final = get_tok_sentences(df_train[\"new_title\"], df_test[\"new_title\"])\n",
    "\n",
    "  # X = {'Word_Seq': sentences_train_final_pad, 'Lexical': np.array(df_train['mean_VADER_LMD'].tolist())}\n",
    "  X = {'Word_Seq': sentences_train_final_pad, 'Lexical': np.array(df_train['mean_LMD'].tolist())}\n",
    "#   X = {'Word_Seq': sentences_train_final_pad}\n",
    "  Y = df_train['sentiment']\n",
    "\n",
    "  embedding_matrix = get_embedding_matrix(emb_dim, MAX_VOCAB_SIZE, MAX_SEQUENCE_LENGTH, tok_final, embeddings_index_final)\n",
    "\n",
    "  # lstm = create_model_lstm(256, 256, 2, 2, 150, 0.4, embedding_matrix, True)\n",
    "  # lstm = create_model_lstm(128, 128, 3, 3, 50, 0.5, embedding_matrix, True)\n",
    "#   lstm = create_model_lstm(384, 384, 3, 3, 150, 0.3, embedding_matrix, True)\n",
    "  lstm = create_model_lstm(lstm_out, num_dense, dropout, embedding_matrix, True)\n",
    "  trained = train_model(lstm, X, Y, batch_size, epoch, 'main_data_test', X, Y)\n",
    "#   trained = train_model(lstm, X, Y, 32, 15, 'main_data_test', X, Y)\n",
    "  # lstm = True\n",
    "  # trained =  True\n",
    "  \n",
    "  \n",
    "  # X_test = {'Word_Seq': sentences_seq_test, 'Lexical': np.array(df_test['mean_VADER_LMD'].tolist())}\n",
    "  X_test = {'Word_Seq': sentences_test_final_pad, 'Lexical': np.array(df_test['mean_LMD'].tolist())}\n",
    "#   X_test = {'Word_Seq': sentences_test_final_pad}\n",
    "\n",
    "  if eval_type == 'cos_sim':\n",
    "    y_pred = lstm.predict(X_test)\n",
    "    return cosine_similarity(y_pred.reshape(1, -1), df_test['sentiment'].values.reshape(1, -1))\n",
    "  else:\n",
    "    return lstm.evaluate(X_test, df_test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15331443,
     "status": "ok",
     "timestamp": 1557941594924,
     "user": {
      "displayName": "Francisco Caio Lima Paiva",
      "photoUrl": "https://lh6.googleusercontent.com/-rObDy5lU2zU/AAAAAAAAAAI/AAAAAAAAAAs/BoY-YI-rQ1A/s64/photo.jpg",
      "userId": "17697619239460268820"
     },
     "user_tz": 180
    },
    "id": "7yTRTULqwp8p",
    "outputId": "d6af192d-abc4-410e-9c62-8069ea8a09d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 203us/step\n",
      "MSE with best params: 0.09973717919435132 \n",
      "Cos_sim with best params: [[0.67600733]]\n"
     ]
    }
   ],
   "source": [
    "# best_params_testing = np.array([[300, 150, 150, 15, 32]])\n",
    "# best_mse_model = pd.DataFrame(best_params_testing, columns=['emb_dim', 'lstm_out', 'num_dense', 'epoch', 'batch_size'], dtype=np.int64)\n",
    "\n",
    "# best_mse_model['dropout'] = pd.Series([0.5]).astype('float64')\n",
    "# best_mse_model.iloc[0]['dropout'] = pd.Series([0.5]).astype('float64')\n",
    "# best_mse_model.iloc[0]\n",
    "\n",
    "\n",
    "final_mse_score = run_final_test(best_mse_model, 'mse')\n",
    "final_cos_score = run_final_test(best_cos_model, 'cos_sim')\n",
    "# final_cos_score = run_final_test(best_mse_model, 'cos_sim')\n",
    "\n",
    "print('MSE with best params: {} \\nCos_sim with best params: {}'.format(final_mse_score[0], final_cos_score))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[Oficial] LSTM Emb Loughran.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
